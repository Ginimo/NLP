{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyN6lycxS56gyQ/2m6Fvncym"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["#Exercise 03: Usage of Deep Learning and Transfer Learning Model for Named Entity Recognition (NER) on the Ontonotes5 dataset"],"metadata":{"id":"CaILAvx2w25s"}},{"cell_type":"markdown","source":["Name: Daniel Podolecki\n","\\\n","Date: 13.01.2023"],"metadata":{"id":"kWu4YKHtxKH6"}},{"cell_type":"markdown","source":["![Example_for_NER.jpg](data:image/jpeg;base64,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)"],"metadata":{"id":"i-eLSFwlr0f2"}},{"cell_type":"markdown","source":["Picture: Symbolic picture for Named Entity Recognition  (NER) - -> [Source](https://www.shaip.com/wp-content/uploads/2022/02/Blog_Named-Entity-Recognition-%E2%80%93-The-Concept-Types-Applications.jpg)"],"metadata":{"id":"zAQtmVHFsQVr"}},{"cell_type":"markdown","source":["## Setup\n"],"metadata":{"id":"K3qCHKJpxEMk"}},{"cell_type":"markdown","source":["Change the runtime to GPU! Otherwise it will take much more time to compute the model!!!! I tried this out and it took more than 1 hour with CPU (I stopped at batch 100 so it would be even longer)!!! "],"metadata":{"id":"NtV8bDd-3j2Q"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rlwGYwzP3jJc","executionInfo":{"status":"ok","timestamp":1673195129812,"user_tz":-60,"elapsed":578,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"24a3b60a-c378-4eba-a40b-af9691fc5a8c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Jan  8 16:25:28 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   29C    P0    51W / 400W |  40458MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W6Svx8iKv5CS","executionInfo":{"status":"ok","timestamp":1673195133922,"user_tz":-60,"elapsed":3610,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"ec487cf9-38b6-4ebe-dc35-61eba0b7abe5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.8.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.13)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}]},{"cell_type":"code","source":["!pip install transformers[sentencepiece]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ly1SpSZirVNS","executionInfo":{"status":"ok","timestamp":1673195137686,"user_tz":-60,"elapsed":3085,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"2739b375-6a98-4967-988d-335708a9d4b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.8/dist-packages (4.25.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (1.21.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.11.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.13.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (3.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (2.25.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (21.3)\n","Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (0.1.97)\n","Requirement already satisfied: protobuf<=3.20.2 in /usr/local/lib/python3.8/dist-packages (from transformers[sentencepiece]) (3.19.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers[sentencepiece]) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (1.26.13)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers[sentencepiece]) (2022.12.7)\n"]}]},{"cell_type":"code","source":["# Import packages needed (or might be needed)\n","\n","from google.colab import drive\n","from pathlib import Path\n","import os\n","\n","import json\n","from itertools import chain\n","import datasets\n","\n","import math\n","import random\n","import copy\n","import tqdm\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","import transformers\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt \n","from pprint import pprint\n","\n","from gensim.scripts.glove2word2vec import glove2word2vec\n","from gensim.models import KeyedVectors\n","\n","from sklearn.metrics import f1_score\n","from torch.nn.utils.rnn import pad_sequence\n","\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"],"metadata":{"id":"UHvIuHtaGpR1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y4fMZJMFGgw8","executionInfo":{"status":"ok","timestamp":1673195139227,"user_tz":-60,"elapsed":1545,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"24480658-cefd-452e-a28b-5953fca2e2fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## Read and Preprocess the Dataset"],"metadata":{"id":"cIN1BJU0xEGF"}},{"cell_type":"markdown","source":["Ontonotes5 dataset comes in a part of the [TNER](https://github.com/asahi417/tner) project.\n","It consists of a large collection of news articles, transcribed radio and television broadcasts, and weblogs annotated with entity, event, and relation information. The dataset is annotated in the framework of the PropBank, NomBank, and FrameNet projects, with additional annotation for coreference and entity linking. \n","\n","This dataset contains a sequence of tokens and tags for each split.\n","\n","The dataset has the following Entity Types: \n","CARDINAL, DATE, PERSON, NORP, GPE, LAW, PERCENT, ORDINAL, MONEY, WORK_OF_ART, FAC, TIME, QUANTITY, PRODUCT, LANGUAGE, ORG, LOC, EVENT"],"metadata":{"id":"aQjpbHvJBlZp"}},{"cell_type":"code","source":["# Overview of the Dataset:\n","\n","\"\"\" NER dataset compiled by T-NER library https://github.com/asahi417/tner/tree/master/tner \"\"\"\n","\n","logger = datasets.logging.get_logger(__name__)\n","_DESCRIPTION = \"\"\"[ontonotes5 NER dataset](https://aclanthology.org/N06-2015/)\"\"\"\n","_NAME = \"ontonotes5\"\n","_VERSION = \"1.0.0\"\n","_CITATION = \"\"\"\n","@inproceedings{hovy-etal-2006-ontonotes,\n","    title = \"{O}nto{N}otes: The 90{\\%} Solution\",\n","    author = \"Hovy, Eduard  and\n","      Marcus, Mitchell  and\n","      Palmer, Martha  and\n","      Ramshaw, Lance  and\n","      Weischedel, Ralph\",\n","    booktitle = \"Proceedings of the Human Language Technology Conference of the {NAACL}, Companion Volume: Short Papers\",\n","    month = jun,\n","    year = \"2006\",\n","    address = \"New York City, USA\",\n","    publisher = \"Association for Computational Linguistics\",\n","    url = \"https://aclanthology.org/N06-2015\",\n","    pages = \"57--60\",\n","}\n","\"\"\"\n","\n","_HOME_PAGE = \"https://github.com/asahi417/tner\"\n","_URL = f'https://huggingface.co/datasets/tner/{_NAME}/raw/main/dataset'\n","_URLS = {\n","    str(datasets.Split.TEST): [f'{_URL}/test.json'],\n","    str(datasets.Split.TRAIN): [f'{_URL}/train{i:02d}.json' for i in range(4)],\n","    str(datasets.Split.VALIDATION): [f'{_URL}/valid.json'],\n","}\n"],"metadata":{"id":"l938-bZeoE1b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_URLS"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SREGPSMwxR3F","executionInfo":{"status":"ok","timestamp":1673195139227,"user_tz":-60,"elapsed":6,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"ec6a7f0c-37b4-42a8-d881-90f02a377162"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'test': ['https://huggingface.co/datasets/tner/ontonotes5/raw/main/dataset/test.json'],\n"," 'train': ['https://huggingface.co/datasets/tner/ontonotes5/raw/main/dataset/train00.json',\n","  'https://huggingface.co/datasets/tner/ontonotes5/raw/main/dataset/train01.json',\n","  'https://huggingface.co/datasets/tner/ontonotes5/raw/main/dataset/train02.json',\n","  'https://huggingface.co/datasets/tner/ontonotes5/raw/main/dataset/train03.json'],\n"," 'validation': ['https://huggingface.co/datasets/tner/ontonotes5/raw/main/dataset/valid.json']}"]},"metadata":{},"execution_count":210}]},{"cell_type":"code","source":["!wget https://huggingface.co/datasets/tner/ontonotes5/raw/main/dataset/train00.json #there a multiple train sets. another option is train01, train02 or train03\n","!wget https://huggingface.co/datasets/tner/ontonotes5/raw/main/dataset/test.json\n","!wget https://huggingface.co/datasets/tner/ontonotes5/raw/main/dataset/valid.json"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_-gRRiHEytdP","executionInfo":{"status":"ok","timestamp":1673195143249,"user_tz":-60,"elapsed":3503,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"3064bb26-bf42-465d-f5e5-14c215bcdadf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-01-08 16:25:38--  https://huggingface.co/datasets/tner/ontonotes5/raw/main/dataset/train00.json\n","Resolving huggingface.co (huggingface.co)... 34.236.220.178, 34.198.93.197, 3.231.67.228, ...\n","Connecting to huggingface.co (huggingface.co)|34.236.220.178|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4744562 (4.5M) [text/plain]\n","Saving to: train00.json.3\n","\n","train00.json.3      100%[===================>]   4.52M  6.59MB/s    in 0.7s    \n","\n","2023-01-08 16:25:39 (6.59 MB/s) - train00.json.3 saved [4744562/4744562]\n","\n","--2023-01-08 16:25:39--  https://huggingface.co/datasets/tner/ontonotes5/raw/main/dataset/test.json\n","Resolving huggingface.co (huggingface.co)... 34.236.220.178, 34.198.93.197, 3.231.67.228, ...\n","Connecting to huggingface.co (huggingface.co)|34.236.220.178|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1915230 (1.8M) [text/plain]\n","Saving to: test.json.3\n","\n","test.json.3         100%[===================>]   1.83M  3.05MB/s    in 0.6s    \n","\n","2023-01-08 16:25:40 (3.05 MB/s) - test.json.3 saved [1915230/1915230]\n","\n","--2023-01-08 16:25:40--  https://huggingface.co/datasets/tner/ontonotes5/raw/main/dataset/valid.json\n","Resolving huggingface.co (huggingface.co)... 34.236.220.178, 34.198.93.197, 3.231.67.228, ...\n","Connecting to huggingface.co (huggingface.co)|34.236.220.178|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1863311 (1.8M) [text/plain]\n","Saving to: valid.json.3\n","\n","valid.json.3        100%[===================>]   1.78M  2.97MB/s    in 0.6s    \n","\n","2023-01-08 16:25:41 (2.97 MB/s) - valid.json.3 saved [1863311/1863311]\n","\n"]}]},{"cell_type":"markdown","source":["To read and preprocess the dataset in order to use the model according to the lecture I have to create a Class which has a similar logic:"],"metadata":{"id":"r8ofJ_YlVA0c"}},{"cell_type":"code","source":["class Ontonotes5Dataset(Dataset):\n","\n","    MAPPING_Y_NER_LABELS ={\n","      0: \"O\",\n","      1: \"B-CARDINAL\",\n","      2: \"B-DATE\",\n","      3: \"I-DATE\",\n","      4: \"B-PERSON\",\n","      5: \"I-PERSON\",\n","      6: \"B-NORP\",\n","      7: \"B-GPE\",\n","      8: \"I-GPE\",\n","      9: \"B-LAW\",\n","      10: \"I-LAW\",\n","      11: \"B-ORG\",\n","      12: \"I-ORG\",\n","      13: \"B-PERCENT\",\n","      14: \"I-PERCENT\",\n","      15: \"B-ORDINAL\",\n","      16: \"B-MONEY\",\n","      17: \"I-MONEY\",\n","      18: \"B-WORK_OF_ART\",\n","      19: \"I-WORK_OF_ART\",\n","      20: \"B-FAC\",\n","      21: \"B-TIME\",\n","      22: \"I-CARDINAL\",\n","      23: \"B-LOC\",\n","      24: \"B-QUANTITY\",\n","      25: \"I-QUANTITY\",\n","      26: \"I-NORP\",\n","      27: \"I-LOC\",\n","      28: \"B-PRODUCT\",\n","      29: \"I-TIME\",\n","      30: \"B-EVENT\",\n","      31: \"I-EVENT\",\n","      32: \"I-FAC\",\n","      33: \"B-LANGUAGE\",\n","      34: \"I-PRODUCT\",\n","      35: \"I-ORDINAL\",\n","      36: \"I-LANGUAGE\"\n","    }\n","\n","          \n","\n","    def __init__(self, filepaths,max_seq_len):\n","        self.data = [] #as list\n","        self.max_seq_len = max_seq_len\n","\n","        for filepath in filepaths:\n","          with open(filepath, encoding=\"utf-8\") as f:\n","                _list = [i for i in f.read().split('\\n') if len(i) > 0] #take one sentence, splitted by \\n\n","                # The data is already tokenized. Each row contains maximum one sentence. \n","                for i in _list:\n","                    #print(i)\n","                    data = json.loads(i)\n","                    idx = len(self.data)\n","                    tokens = data['tokens']\n","                    labels = data['tags']\n","\n","                    self.data.append({\n","                        'tokens': tokens,\n","                        'ners': labels, #note that this is different to the code the lecturer gave us, because the ners are in the dataset, and not the y_ners\n","                        'idx': idx,\n","                        'y_ners': [Ontonotes5Dataset.MAPPING_Y_NER_LABELS[label] for label in labels], # Reverse Mapping 0-36 classes to Y_Ner\n","                         'word_idx': [] # Later for word embeddings\n","                    })\n","\n","    def __len__(self):  #this is needed for the DataLoader later!\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):  #this is needed for the DataLoader later!\n","    \n","        return {\n","            'idx': idx,\n","            'word_idx': torch.tensor(self.data[idx]['word_idx']).long(), \n","            'ners': torch.tensor(self.data[idx]['ners']).long()\n","        }"],"metadata":{"id":"t-2jYt7KNWSu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check if it is downloaded\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBTAjvMrznJ6","executionInfo":{"status":"ok","timestamp":1673195143616,"user_tz":-60,"elapsed":371,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"29fe5319-cead-4a8a-dd97-704540a16bb4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["drive\t\t       glove.6B.zip    test.json.2     valid.json\n","glove.6B.100d.txt      glove.6B.zip.1  test.json.3     valid.json.1\n","glove.6B.100d_w2v.txt  glove.6B.zip.2  train00.json    valid.json.2\n","glove.6B.200d.txt      sample_data     train00.json.1  valid.json.3\n","glove.6B.300d.txt      test.json       train00.json.2\n","glove.6B.50d.txt       test.json.1     train00.json.3\n"]}]},{"cell_type":"code","source":["# get the current directory - check where it is downloaded\n","current_dir = os.getcwd()\n","print(current_dir)\n","\n","# construct the file paths to the dataset files\n","train_filepath = os.path.join(current_dir, \"train00.json\")\n","validation_filepath = os.path.join(current_dir, \"valid.json\")\n","test_filepath = os.path.join(current_dir\n","                             , \"test.json\")\n","\n","# create the file paths list\n","filepaths = [train_filepath, validation_filepath, test_filepath]\n","\n","# create the dataset\n","dataset = Ontonotes5Dataset(filepaths, max_seq_len=210)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RRGWmAAGzvkZ","executionInfo":{"status":"ok","timestamp":1673195144570,"user_tz":-60,"elapsed":958,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"eee50dbe-da1d-40e6-bbbb-09682dbbe7ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["#Example: One row/sample\n","dataset.data[6]"],"metadata":{"id":"ptgNE--w07Wv","executionInfo":{"status":"ok","timestamp":1673195144572,"user_tz":-60,"elapsed":6,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9fe3c550-c329-468b-b4a7-a33147b3365e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'tokens': ['Last',\n","  'week',\n","  ',',\n","  'Sen.',\n","  'Malcolm',\n","  'Wallop',\n","  '-LRB-',\n","  'R.',\n","  ',',\n","  'Wyo',\n","  '.',\n","  '-RRB-',\n","  'held',\n","  'hearings',\n","  'on',\n","  'a',\n","  'bill',\n","  'to',\n","  'strengthen',\n","  'an',\n","  'existing',\n","  'law',\n","  'designed',\n","  'to',\n","  'reduce',\n","  'regulatory',\n","  'hassles',\n","  'for',\n","  'small',\n","  'businesses',\n","  '.'],\n"," 'ners': [2,\n","  3,\n","  0,\n","  0,\n","  4,\n","  5,\n","  0,\n","  6,\n","  0,\n","  7,\n","  8,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0],\n"," 'idx': 6,\n"," 'y_ners': ['B-DATE',\n","  'I-DATE',\n","  'O',\n","  'O',\n","  'B-PERSON',\n","  'I-PERSON',\n","  'O',\n","  'B-NORP',\n","  'O',\n","  'B-GPE',\n","  'I-GPE',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O'],\n"," 'word_idx': []}"]},"metadata":{},"execution_count":215}]},{"cell_type":"code","source":["# Test-Val-Train Split\n","train_data = Ontonotes5Dataset([train_filepath], max_seq_len=210)\n","val_data = Ontonotes5Dataset([validation_filepath], max_seq_len=210)\n","test_data = Ontonotes5Dataset([test_filepath], max_seq_len=210)"],"metadata":{"id":"EpFqC90t2hul"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example: Train Data\n","train_data.data[1]"],"metadata":{"id":"MwvFkaiE3eI0","executionInfo":{"status":"ok","timestamp":1673195145260,"user_tz":-60,"elapsed":24,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c8981421-0a03-41cb-8e1c-3cbe12833781"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'tokens': ['But',\n","  'a',\n","  'chance',\n","  'to',\n","  'fill',\n","  'out',\n","  'sales',\n","  '-',\n","  'tax',\n","  'records',\n","  'is',\n","  'rarely',\n","  'one',\n","  'of',\n","  'them',\n","  '.'],\n"," 'ners': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n"," 'idx': 1,\n"," 'y_ners': ['O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-CARDINAL',\n","  'O',\n","  'O',\n","  'O'],\n"," 'word_idx': []}"]},"metadata":{},"execution_count":217}]},{"cell_type":"code","source":["# Example: Train Data\n","print(len(train_data.data[1][\"ners\"]))\n","print(len(train_data.data[1][\"word_idx\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rNjXzyjRiAlH","executionInfo":{"status":"ok","timestamp":1673195145260,"user_tz":-60,"elapsed":23,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"7d665a13-9ec9-4f36-bb6b-e0449d981f04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["16\n","0\n"]}]},{"cell_type":"code","source":["# Set seeds for reproducibility\n","SEED = 42\n","torch.manual_seed(SEED)\n","random.seed(SEED)\n","np.random.seed(SEED)"],"metadata":{"id":"JG7miMVL3wMG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the lenghts\n","len(train_data), len(val_data), len(test_data) "],"metadata":{"id":"ZEgkWgpg3x-Q","executionInfo":{"status":"ok","timestamp":1673195145261,"user_tz":-60,"elapsed":20,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ec8b2a6d-fc22-4b71-dee7-b2c990365c58"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(15000, 8528, 8262)"]},"metadata":{},"execution_count":220}]},{"cell_type":"markdown","source":["## Build the vocabulary and word embedding matrix\n"],"metadata":{"id":"2FKJrMaqyNry"}},{"cell_type":"markdown","source":["At the begin it is necessary to build a vocabulary of all tokens which are mentioned in the text/list of tokens. Since it is a set each token will be unique (appears only one time)."],"metadata":{"id":"c2rk2gQGYDlv"}},{"cell_type":"code","source":["# Initialization of the vocabulary set\n","vocabulary = set()\n","\n","# loop through the train dataset and add the tokens to the vocabulary set\n","for sample in train_data.data:\n","    for token in sample['tokens']:\n","        vocabulary.add(token)\n","\n","# print the vocabulary size\n","print(len(vocabulary))"],"metadata":{"id":"ptnCZDxOySn0","executionInfo":{"status":"ok","timestamp":1673195145261,"user_tz":-60,"elapsed":19,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d9b465ef-eed1-4aea-eb79-f92f7a524df4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["25503\n"]}]},{"cell_type":"markdown","source":["**Interpretation**: Not too many words so there is no need to filter/reduce the vocabulary (< 30k). "],"metadata":{"id":"EYQU5TBzCGix"}},{"cell_type":"markdown","source":["Next each vocabulary receives an index (and vice versa). For that the Vocabulary based set is the basis. For that an index is created by calculating the length of the word2idx set. Since there are two items already in the set (_PAD_ and _UNK_) the length of the set is intially on 2. For the first vocab is mapped to the initial index. Beginning from the vocab the word2idx set will naturally grow +1 each iteration, because it is a for loop."],"metadata":{"id":"xgMAiEvYX2GG"}},{"cell_type":"code","source":["# Assign an index to each vocabulary entry:\n","word2idx = {'_PAD_': 0, '_UNK_': 1}#\n","\n","print(\"Initial Index = \", len(word2idx))\n","print(30*\"*\")\n","\n","for word in vocabulary:\n","  word2idx[word] = len(word2idx) \n","idx2word = {idx:word for word, idx in word2idx.items()}\n","word2idx"],"metadata":{"id":"Mt7dZ8n_Tkp4","executionInfo":{"status":"ok","timestamp":1673195145262,"user_tz":-60,"elapsed":18,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"06a9ee5d-e556-4a6e-97a2-20ec983b352d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial Index =  2\n","******************************\n"]},{"output_type":"execute_result","data":{"text/plain":["{'_PAD_': 0,\n"," '_UNK_': 1,\n"," 'certainly': 2,\n"," 'Ukrainian': 3,\n"," 'notwithstanding': 4,\n"," 'swindled': 5,\n"," '225': 6,\n"," 'resignations': 7,\n"," 'your': 8,\n"," 'pro-family': 9,\n"," 'Parental': 10,\n"," 'demolishing': 11,\n"," 'clippings': 12,\n"," 'Vaclav': 13,\n"," 'Mountain': 14,\n"," 'DeVillars': 15,\n"," 'trafficking': 16,\n"," 'masses': 17,\n"," 'state': 18,\n"," 'aftermath': 19,\n"," 'Brussels': 20,\n"," 'atomic': 21,\n"," 'haven': 22,\n"," 'Marcel': 23,\n"," \"'50s\": 24,\n"," 'Lorin': 25,\n"," 'dropouts': 26,\n"," 'R.I': 27,\n"," 'anti-apartheid': 28,\n"," 'wrack': 29,\n"," 'Autry': 30,\n"," 'friends': 31,\n"," 'Itochu': 32,\n"," '39,000': 33,\n"," 'merge': 34,\n"," 'Relief': 35,\n"," 'tenth': 36,\n"," 'brother': 37,\n"," 'condensers': 38,\n"," 'code': 39,\n"," 'ABCs': 40,\n"," '1,000': 41,\n"," 'dictatorship': 42,\n"," 'institutes': 43,\n"," 'recovery': 44,\n"," 'McCarthy': 45,\n"," 'Close': 46,\n"," 'rural': 47,\n"," 'Referring': 48,\n"," 'brunt': 49,\n"," 'palladium': 50,\n"," 'Guard': 51,\n"," 'redemptions': 52,\n"," 'doubt': 53,\n"," 'ruptured': 54,\n"," 'indicate': 55,\n"," 'Longman': 56,\n"," 'formulating': 57,\n"," 'innovative': 58,\n"," 'workstation': 59,\n"," 'contractor': 60,\n"," 'N.C': 61,\n"," 'Alter': 62,\n"," 'sorts': 63,\n"," 'co-editor': 64,\n"," 'Human': 65,\n"," 'contacted': 66,\n"," 'change': 67,\n"," 'Potter': 68,\n"," '1271': 69,\n"," 'utilities': 70,\n"," 'Jan.': 71,\n"," 'projects': 72,\n"," 'overpriced': 73,\n"," 'idealistic': 74,\n"," '134': 75,\n"," 'willing': 76,\n"," 'airline': 77,\n"," '6.25': 78,\n"," 'Cayman': 79,\n"," 'eating': 80,\n"," 'workweek': 81,\n"," 'plaque': 82,\n"," 'rush': 83,\n"," 'occurring': 84,\n"," 'Brawer': 85,\n"," 'emphasizes': 86,\n"," 'underpinned': 87,\n"," 'limbs': 88,\n"," 'Adlai': 89,\n"," 'homicide': 90,\n"," 'uncomfortable': 91,\n"," 'portrayed': 92,\n"," 'Mayor': 93,\n"," 'TIMES': 94,\n"," 'selecting': 95,\n"," 'Pulkova': 96,\n"," 'tourist': 97,\n"," 'biennial': 98,\n"," 'McCollum': 99,\n"," 'Verne': 100,\n"," 'Guarantee': 101,\n"," 'prohibitions': 102,\n"," 'food': 103,\n"," 'specifies': 104,\n"," 're-enactment': 105,\n"," 'tragedy': 106,\n"," 'disappeared': 107,\n"," 'Anita': 108,\n"," 'proposal': 109,\n"," 'accused': 110,\n"," 'streamline': 111,\n"," 'Semmelman': 112,\n"," 'easiest': 113,\n"," 'manufacturers': 114,\n"," '91.07': 115,\n"," 'domination': 116,\n"," 'strips': 117,\n"," 'severely': 118,\n"," 'irreparable': 119,\n"," 'creed': 120,\n"," 'shortest': 121,\n"," 'simple': 122,\n"," 'exonerating': 123,\n"," '730,000': 124,\n"," 'bet': 125,\n"," 'defend': 126,\n"," 'matching': 127,\n"," 'additions': 128,\n"," 'decline': 129,\n"," 'Rubicam': 130,\n"," 'Bowl': 131,\n"," 'Surveying': 132,\n"," 'conjecture': 133,\n"," 'camps': 134,\n"," 'memos': 135,\n"," 'vigor': 136,\n"," 'longed': 137,\n"," 'Corporate': 138,\n"," 'salt': 139,\n"," 'Zaishuo': 140,\n"," 'principally': 141,\n"," 'walks': 142,\n"," 'Albertville': 143,\n"," 'base': 144,\n"," 'photo': 145,\n"," 'Civil': 146,\n"," 'positions': 147,\n"," 'Muskegon': 148,\n"," 'Fares': 149,\n"," 'Reins': 150,\n"," 'sure': 151,\n"," 'infrared': 152,\n"," 'Probably': 153,\n"," 'own': 154,\n"," 'appeals': 155,\n"," 'Ximei': 156,\n"," 'civilised': 157,\n"," 'annals': 158,\n"," '2917': 159,\n"," 'likes': 160,\n"," '16.95': 161,\n"," 'sealed': 162,\n"," 'west': 163,\n"," 'prosecutor': 164,\n"," '3.86': 165,\n"," 'lumped': 166,\n"," 'owes': 167,\n"," 'agendas': 168,\n"," 'mailings': 169,\n"," 'clients': 170,\n"," 'Congressional': 171,\n"," 'Bierbower': 172,\n"," 'athletes': 173,\n"," 'struggling': 174,\n"," 'Beker': 175,\n"," '5,100': 176,\n"," 'deemed': 177,\n"," 'enforcing': 178,\n"," 'Lang': 179,\n"," 'pouring': 180,\n"," 'aspects': 181,\n"," 'tailspin': 182,\n"," 'Jones': 183,\n"," 'merits': 184,\n"," 'bite': 185,\n"," 'Wilmer': 186,\n"," 'Charlene': 187,\n"," 'lithography': 188,\n"," 'Mosbacher': 189,\n"," 'telex': 190,\n"," 'Autozam': 191,\n"," 'Croatian': 192,\n"," 'Shen': 193,\n"," 'Defaults': 194,\n"," 'Roger': 195,\n"," 'resells': 196,\n"," 'videoconferencing': 197,\n"," 'nightclub': 198,\n"," 'prototype': 199,\n"," 'Child': 200,\n"," 'Carolina': 201,\n"," 'sized': 202,\n"," 'Cafe': 203,\n"," 'Bulgarians': 204,\n"," 'ramps': 205,\n"," 'staphylococcus': 206,\n"," 'pensions': 207,\n"," 'likewise': 208,\n"," 'lapse': 209,\n"," 'Kingston': 210,\n"," 'killing': 211,\n"," 'hesitantly': 212,\n"," 'Peoples': 213,\n"," 'implanting': 214,\n"," 'boldest': 215,\n"," 'Aaron': 216,\n"," 'deadline': 217,\n"," 'Orange': 218,\n"," 'Resolutely': 219,\n"," 'member': 220,\n"," 'pie': 221,\n"," 'tourism': 222,\n"," 'Packaged': 223,\n"," 'reassert': 224,\n"," 'were': 225,\n"," '554': 226,\n"," 'Colson': 227,\n"," 'flags': 228,\n"," 'Bulls': 229,\n"," \"'T-\": 230,\n"," '1,275,000': 231,\n"," 'forty': 232,\n"," 'Rambo': 233,\n"," 'sent': 234,\n"," 'biologists': 235,\n"," 'Thought': 236,\n"," 'Kraft': 237,\n"," 'pre-register': 238,\n"," 'retrieved': 239,\n"," 'firms': 240,\n"," 'Rolodex': 241,\n"," 'handlers': 242,\n"," 'Premier': 243,\n"," 'flood': 244,\n"," 'escaped': 245,\n"," 'Term': 246,\n"," 'Avoidance': 247,\n"," 'Lucas': 248,\n"," 'constructing': 249,\n"," 'Replacing': 250,\n"," 'Dar': 251,\n"," 'Fresenius': 252,\n"," 'yaks': 253,\n"," 'Angela': 254,\n"," 'Urgent': 255,\n"," 'Winster': 256,\n"," 'apparat': 257,\n"," 'Burk': 258,\n"," 'Azem': 259,\n"," 'Billings': 260,\n"," 'Transportation': 261,\n"," 'habitation': 262,\n"," 'Rhine': 263,\n"," 'bark': 264,\n"," 'Mass': 265,\n"," 'Delta': 266,\n"," 'effective': 267,\n"," 'Orlando': 268,\n"," 'ISRAEL': 269,\n"," 'folders': 270,\n"," 'immediate': 271,\n"," 'wireless': 272,\n"," 'portraying': 273,\n"," 'Stern': 274,\n"," 'Plain': 275,\n"," 'Lonbado': 276,\n"," 'shopper': 277,\n"," 'Right': 278,\n"," 'knowledge': 279,\n"," 'satisfies': 280,\n"," 'cleansing': 281,\n"," 'ENGRAPH': 282,\n"," 'Throughout': 283,\n"," 'characters': 284,\n"," 'inflow': 285,\n"," 'Kim': 286,\n"," 'Hershey': 287,\n"," 'Sons': 288,\n"," 'floats': 289,\n"," 'Schantz': 290,\n"," 'commitment': 291,\n"," 'talks': 292,\n"," 'please': 293,\n"," '37.6': 294,\n"," 'creative': 295,\n"," 'annum': 296,\n"," 'Tucson': 297,\n"," 'February': 298,\n"," 'philosophers': 299,\n"," 'ACCEPTANCES': 300,\n"," 'pre-trial': 301,\n"," 'civilian': 302,\n"," 'applied': 303,\n"," 'Wenceslas': 304,\n"," 'versions': 305,\n"," 'grandmaster': 306,\n"," 'stucco': 307,\n"," 'Profits': 308,\n"," 'Rongheng': 309,\n"," '1.13': 310,\n"," 'inflation': 311,\n"," 'until': 312,\n"," 'hamstrung': 313,\n"," '1970s': 314,\n"," 'shoreline': 315,\n"," 'Richeng': 316,\n"," 'Baby': 317,\n"," 'Feilibeiqiu': 318,\n"," 'foaming': 319,\n"," 'brushed': 320,\n"," 'with': 321,\n"," 'chirpy': 322,\n"," 'depreciation': 323,\n"," 'Zongmin': 324,\n"," 'husband': 325,\n"," 'SPAN': 326,\n"," 'Cox': 327,\n"," 'rusting': 328,\n"," 'Bleus': 329,\n"," 'ordered': 330,\n"," 'similar': 331,\n"," 'Contestants': 332,\n"," 'specifications': 333,\n"," 'Zunjing': 334,\n"," 'recordkeeping': 335,\n"," 'Trimmer': 336,\n"," 'Runkel': 337,\n"," '128.19': 338,\n"," 'inside': 339,\n"," 'drinking': 340,\n"," 'Worried': 341,\n"," 'spheres': 342,\n"," 'Lebanese': 343,\n"," 'Armstrong': 344,\n"," '18.75': 345,\n"," 'benefited': 346,\n"," 'basketball': 347,\n"," 'trumpet': 348,\n"," 'Bets': 349,\n"," 'sluggish': 350,\n"," 'Adults': 351,\n"," 'recital': 352,\n"," 'unknowingly': 353,\n"," 'shaped': 354,\n"," '9000': 355,\n"," 'pits': 356,\n"," 'alluvial': 357,\n"," 'Soap': 358,\n"," 'Cronkite': 359,\n"," 'sensibility': 360,\n"," 'adjustment': 361,\n"," 'Broward': 362,\n"," 'Taste': 363,\n"," 'alleges': 364,\n"," 'midlevel': 365,\n"," 'domino': 366,\n"," 'Defu': 367,\n"," 'consecutive': 368,\n"," 'mark': 369,\n"," 'croissants': 370,\n"," 'Bible': 371,\n"," 'speedily': 372,\n"," 'Manchuria': 373,\n"," 'Khalifa': 374,\n"," '366.79': 375,\n"," 'Matamoros': 376,\n"," 'links': 377,\n"," 'commanding': 378,\n"," 'Grasso': 379,\n"," 'crow': 380,\n"," 'compared': 381,\n"," '158,300': 382,\n"," 'Vicks': 383,\n"," 'Quezon': 384,\n"," 'Bogart': 385,\n"," 'amuse': 386,\n"," 'scales': 387,\n"," 'finger': 388,\n"," '105': 389,\n"," 'molecule': 390,\n"," 'folk': 391,\n"," 'adjustable': 392,\n"," 'underwent': 393,\n"," 'steelmakers': 394,\n"," 'route': 395,\n"," 'Pictures': 396,\n"," '5.94': 397,\n"," 'percent': 398,\n"," 'mechanics': 399,\n"," 'PACs': 400,\n"," 'stretched': 401,\n"," 'equilibrium': 402,\n"," 'dual': 403,\n"," 'clump': 404,\n"," 'expressing': 405,\n"," 'Marie': 406,\n"," 'embellish': 407,\n"," 'judicious': 408,\n"," 'sternly': 409,\n"," 'registered': 410,\n"," '605': 411,\n"," 'formed': 412,\n"," 'Buha': 413,\n"," '41.5': 414,\n"," 'canceling': 415,\n"," 'taught': 416,\n"," 'Afghans': 417,\n"," 'blazing': 418,\n"," '36.3': 419,\n"," 'surpass': 420,\n"," 'sanctioning': 421,\n"," 'edging': 422,\n"," 'resulting': 423,\n"," 'NT&SA': 424,\n"," 'Too': 425,\n"," 'damper': 426,\n"," 'sociology': 427,\n"," 'outfly': 428,\n"," 'hitches': 429,\n"," 'both': 430,\n"," 'formulations': 431,\n"," 'flocked': 432,\n"," 'Hayes': 433,\n"," '221': 434,\n"," 'Elliott': 435,\n"," 'Vicky': 436,\n"," 'Drogoul': 437,\n"," '1993': 438,\n"," 'contingency': 439,\n"," 'Philippine': 440,\n"," 'requires': 441,\n"," 'amass': 442,\n"," 'disclosure': 443,\n"," 'precipitated': 444,\n"," 'deepwater': 445,\n"," 'tripped': 446,\n"," '11,586': 447,\n"," 'product': 448,\n"," 'swine': 449,\n"," 'Durable': 450,\n"," 'warehouse': 451,\n"," '152.62': 452,\n"," 'donating': 453,\n"," 'defective': 454,\n"," 'feature': 455,\n"," '465,000': 456,\n"," 'hinders': 457,\n"," 'fell': 458,\n"," 'trembling': 459,\n"," 'prosper': 460,\n"," 'corporate': 461,\n"," 'sentiment': 462,\n"," 'whooper': 463,\n"," 'obstructing': 464,\n"," 'Banxquote': 465,\n"," 'Miller': 466,\n"," 'drunkenness': 467,\n"," 'contractors': 468,\n"," 'equation': 469,\n"," 'Xuzhou': 470,\n"," 'ammonia': 471,\n"," 'Vic': 472,\n"," 'shields': 473,\n"," 'Crowe': 474,\n"," 'demurs': 475,\n"," '3717.46': 476,\n"," 'herds': 477,\n"," 'Daniel': 478,\n"," '135': 479,\n"," 'notoriously': 480,\n"," 'Fruit': 481,\n"," 'utopia': 482,\n"," 'grouped': 483,\n"," 'crept': 484,\n"," 'Guoxian': 485,\n"," 'seminar': 486,\n"," 'zag': 487,\n"," '5,651': 488,\n"," 'chart': 489,\n"," 'hens': 490,\n"," 'tempting': 491,\n"," 'floating': 492,\n"," '135.9': 493,\n"," 'noting': 494,\n"," 'kettle': 495,\n"," 'regards': 496,\n"," '12:00': 497,\n"," 'lifetime': 498,\n"," '9.39': 499,\n"," 'superconductors': 500,\n"," 'reputations': 501,\n"," 'Kleinwort': 502,\n"," 'schizophrenic': 503,\n"," 'A&M': 504,\n"," 'weary': 505,\n"," 'information': 506,\n"," 'innovation': 507,\n"," 'plummet': 508,\n"," 'Loess': 509,\n"," '70.2': 510,\n"," 'earnestly': 511,\n"," 'rings': 512,\n"," 'policing': 513,\n"," 'collapsed': 514,\n"," 'turban': 515,\n"," 'videotape': 516,\n"," 'intermittent': 517,\n"," 'Applications': 518,\n"," 'Sargent': 519,\n"," 'receipt': 520,\n"," 'miscommunication': 521,\n"," 'affect': 522,\n"," 'granting': 523,\n"," 'Fortunately': 524,\n"," 'Zhenhua': 525,\n"," 'throw': 526,\n"," 'Lamle': 527,\n"," 'productions': 528,\n"," 'magazined': 529,\n"," 'Maynen': 530,\n"," 'licensing': 531,\n"," 'TCL': 532,\n"," 'Hallucigenia': 533,\n"," 'management': 534,\n"," 'assuage': 535,\n"," 'drying': 536,\n"," 'Eavesdropping': 537,\n"," 'refrigerators': 538,\n"," 'whiner': 539,\n"," 'unknown': 540,\n"," 'Inc.': 541,\n"," '12.3': 542,\n"," 'Oversight': 543,\n"," 'vacated': 544,\n"," 'patents': 545,\n"," 'Symposium': 546,\n"," 'default': 547,\n"," 'Skeptics': 548,\n"," 'Kobayashi': 549,\n"," '1,848,000': 550,\n"," 'Tire': 551,\n"," 'Zhuhai': 552,\n"," 'HyperCard': 553,\n"," 'garden': 554,\n"," 'EPA': 555,\n"," 'paneling': 556,\n"," 'Herring': 557,\n"," 'ferroelectric': 558,\n"," 'Bishkek': 559,\n"," 'scoops': 560,\n"," 'averages': 561,\n"," 'Shlenker': 562,\n"," 'colonies': 563,\n"," 'Markese': 564,\n"," 'furnishings': 565,\n"," 'anti-foreigner': 566,\n"," 'rivals': 567,\n"," 'toured': 568,\n"," 'yesterday': 569,\n"," 'quieted': 570,\n"," 'astronomy': 571,\n"," 'cigarettes': 572,\n"," 'Tillery': 573,\n"," 'reply': 574,\n"," 'inexpensively': 575,\n"," 'businesspeople': 576,\n"," '10.45': 577,\n"," 'Fengzhen': 578,\n"," 'nurtured': 579,\n"," '716': 580,\n"," '28th': 581,\n"," 'salaried': 582,\n"," 'strict': 583,\n"," 'realization': 584,\n"," 'Mingxia': 585,\n"," 'severity': 586,\n"," 'Sultan': 587,\n"," 'Literary': 588,\n"," 'Lean': 589,\n"," 'Erich': 590,\n"," 'Bradstreet': 591,\n"," 'Ark': 592,\n"," 'fauna': 593,\n"," 'liberals': 594,\n"," 'joblessness': 595,\n"," 'sub-station': 596,\n"," 'accuses': 597,\n"," 'Principles': 598,\n"," 'Bebear': 599,\n"," 'accelerates': 600,\n"," 'Museum': 601,\n"," 'confirmation': 602,\n"," 'genetically': 603,\n"," 'reality': 604,\n"," 'Military': 605,\n"," 'occupancy': 606,\n"," 'Barnard': 607,\n"," 'restated': 608,\n"," 'SOYBEANS': 609,\n"," '2.85': 610,\n"," 'Christians': 611,\n"," 'retiree': 612,\n"," 'boxes': 613,\n"," 'movie': 614,\n"," 'Gill': 615,\n"," 'Immunex': 616,\n"," 'key': 617,\n"," 'benefits': 618,\n"," 'impetus': 619,\n"," 'disdaining': 620,\n"," '1.09': 621,\n"," 'meteorological': 622,\n"," 'salesparson': 623,\n"," 'Boulder': 624,\n"," 'OTIS': 625,\n"," 'plurality': 626,\n"," 'anti-outsider': 627,\n"," 'bluebloods': 628,\n"," '46.8': 629,\n"," 'artists': 630,\n"," 'Published': 631,\n"," 'Clean': 632,\n"," '875': 633,\n"," 'debugged': 634,\n"," 'Lu': 635,\n"," 'Father': 636,\n"," 'Lavoro': 637,\n"," 'performance': 638,\n"," 'crimes': 639,\n"," 'infuse': 640,\n"," 'poohbah': 641,\n"," '94,543': 642,\n"," 'bartered': 643,\n"," 'hurtling': 644,\n"," 'arena': 645,\n"," 'unification': 646,\n"," 'Stephen': 647,\n"," 'direction': 648,\n"," 'Likewise': 649,\n"," 'Kiko': 650,\n"," 'asses': 651,\n"," 'bloc': 652,\n"," 'real': 653,\n"," 'Minwax': 654,\n"," 'stimuli': 655,\n"," 'caricatures': 656,\n"," 'Broderick': 657,\n"," 'Handoger': 658,\n"," 'worthier': 659,\n"," 'Nashville': 660,\n"," 'baseline': 661,\n"," 'arteries': 662,\n"," 'flatout': 663,\n"," 'Louisiana': 664,\n"," 'murdered': 665,\n"," 'offend': 666,\n"," 'updated': 667,\n"," 'sought': 668,\n"," '5': 669,\n"," 'Treaty': 670,\n"," 'Naguib': 671,\n"," 'Sharfman': 672,\n"," 'Mochida': 673,\n"," 'Vt': 674,\n"," 'Gotlieb': 675,\n"," '28.3': 676,\n"," 'ethical': 677,\n"," 'preventing': 678,\n"," 'tower': 679,\n"," 'milk': 680,\n"," 'Bolling': 681,\n"," 'partnerships': 682,\n"," 'bitch': 683,\n"," 'commemoration': 684,\n"," 'bookings': 685,\n"," 'Harbin': 686,\n"," 'Sudan': 687,\n"," 'Combined': 688,\n"," 'outgoing': 689,\n"," 'miscreant': 690,\n"," 'Jewish': 691,\n"," 'art': 692,\n"," 'Garland': 693,\n"," 'imposed': 694,\n"," 'Youhao': 695,\n"," 'miscalculated': 696,\n"," 'pens': 697,\n"," 'superiority': 698,\n"," 'GDR': 699,\n"," 'offerings': 700,\n"," 'paradox': 701,\n"," 'e': 702,\n"," 'matryoshka': 703,\n"," 'Operations': 704,\n"," 'dimension': 705,\n"," 'reassured': 706,\n"," 'Wiesenthal': 707,\n"," 'glacial': 708,\n"," 'splinter': 709,\n"," 'swimming': 710,\n"," 'softening': 711,\n"," 'enactment': 712,\n"," 'Siemienas': 713,\n"," 'outbreaks': 714,\n"," 'Taiwanese': 715,\n"," 'warehousing': 716,\n"," 'streets': 717,\n"," 'Manufacturing': 718,\n"," 'charging': 719,\n"," 'Scrap': 720,\n"," 'placid': 721,\n"," 'bitter': 722,\n"," '52': 723,\n"," 'EC': 724,\n"," 'Tories': 725,\n"," 'Wildlife': 726,\n"," '58.97': 727,\n"," 'horse': 728,\n"," 'Ciporkin': 729,\n"," '1,770': 730,\n"," 'gains': 731,\n"," 'Gary': 732,\n"," 'flavors': 733,\n"," 'flair': 734,\n"," 'picking': 735,\n"," 'assistant': 736,\n"," 'whiskery': 737,\n"," 'traveler': 738,\n"," 'Principals': 739,\n"," 'FDIC': 740,\n"," 'accelerated': 741,\n"," 'forerunner': 742,\n"," 'Ames': 743,\n"," 'San': 744,\n"," 'Dec.': 745,\n"," 'paced': 746,\n"," 'transplant': 747,\n"," 'Non-Proliferation': 748,\n"," 'G.': 749,\n"," 'Indiana': 750,\n"," 'telescopes': 751,\n"," 'Flamply': 752,\n"," 'friend': 753,\n"," 'her': 754,\n"," 'Chevrolet': 755,\n"," 'merely': 756,\n"," 'employs': 757,\n"," 'LAMBERT': 758,\n"," 'loading': 759,\n"," 'capacities': 760,\n"," 'Michigan': 761,\n"," 'irritates': 762,\n"," 'centenary': 763,\n"," 'Sasha': 764,\n"," 'disclosed': 765,\n"," 'polled': 766,\n"," 'Qu': 767,\n"," 'Quality': 768,\n"," 'buoy': 769,\n"," 'president': 770,\n"," 'subsidy': 771,\n"," 'appease': 772,\n"," 'piglet': 773,\n"," 'squashed': 774,\n"," 'matched': 775,\n"," 'provided': 776,\n"," 'instructor': 777,\n"," 'room': 778,\n"," 'Riepe': 779,\n"," 'unpopular': 780,\n"," 'stabilizes': 781,\n"," 'boundary': 782,\n"," 'products': 783,\n"," 'Aviacion': 784,\n"," 'Baghdad': 785,\n"," 'fingered': 786,\n"," 'indoctrinated': 787,\n"," '31st': 788,\n"," 'fanatic': 789,\n"," 'colliding': 790,\n"," 'Breeden': 791,\n"," 'Ningguo': 792,\n"," 'boosters': 793,\n"," 'Aldus': 794,\n"," 'Now': 795,\n"," 'fights': 796,\n"," 'orbital': 797,\n"," 'exporter': 798,\n"," 'Tiantong': 799,\n"," 'dropping': 800,\n"," 'van': 801,\n"," 'Medicare': 802,\n"," 'can': 803,\n"," 'remains': 804,\n"," 'Companies': 805,\n"," 'Cote': 806,\n"," 'scorecard': 807,\n"," '238.15': 808,\n"," 'Americans': 809,\n"," 'ranking': 810,\n"," 'Repertory': 811,\n"," 'repercussions': 812,\n"," 'Hutchinson': 813,\n"," '1080': 814,\n"," 'Hubei': 815,\n"," 'wildlife': 816,\n"," 'united': 817,\n"," 'extremists': 818,\n"," 'Sixth': 819,\n"," 'yuppie': 820,\n"," 'Khieu': 821,\n"," '72': 822,\n"," 'concrete': 823,\n"," 'Particularly': 824,\n"," 'request': 825,\n"," 'financing': 826,\n"," 'exceeds': 827,\n"," '1,859': 828,\n"," 'Nasser': 829,\n"," 'Politburo': 830,\n"," 'Gamble': 831,\n"," 'unexpectedly': 832,\n"," 'Sam': 833,\n"," 'portions': 834,\n"," '147': 835,\n"," '37,820': 836,\n"," 'Somali': 837,\n"," 'bode': 838,\n"," 'allow': 839,\n"," 'Lawrenson': 840,\n"," 'clutter': 841,\n"," 'unplanned': 842,\n"," '770': 843,\n"," 'allows': 844,\n"," 'Ladenburg': 845,\n"," 'seed': 846,\n"," 'eligible': 847,\n"," 'Eskenazi': 848,\n"," 'sells': 849,\n"," 'Earlier': 850,\n"," 'conceal': 851,\n"," 'Kean': 852,\n"," 'judgment': 853,\n"," 'sniped': 854,\n"," 'GTE': 855,\n"," 'gripped': 856,\n"," 'Fishkill': 857,\n"," 'Herbig': 858,\n"," 'Taking': 859,\n"," 'ennumerated': 860,\n"," '7.60': 861,\n"," '9': 862,\n"," 'regulators': 863,\n"," 'Adds': 864,\n"," 'freshness': 865,\n"," 'rape': 866,\n"," 'how': 867,\n"," 'shattered': 868,\n"," 'withdrawn': 869,\n"," 'Have': 870,\n"," 'exceed': 871,\n"," '137.6': 872,\n"," 'Klein': 873,\n"," '144.584': 874,\n"," 'underworld': 875,\n"," 'Spy': 876,\n"," 'exhibits': 877,\n"," 'Charles': 878,\n"," 'sits': 879,\n"," 'Suo': 880,\n"," 'Tribe': 881,\n"," '1,828,000': 882,\n"," 'student': 883,\n"," 'Ling': 884,\n"," 'Handholding': 885,\n"," 'jurors': 886,\n"," '82,000': 887,\n"," 'Vegas': 888,\n"," 'fluid': 889,\n"," 'Times': 890,\n"," 'coat': 891,\n"," 'Backer': 892,\n"," 'redeem': 893,\n"," 'Dan': 894,\n"," 'damped': 895,\n"," 'Ventspils': 896,\n"," 'sleep': 897,\n"," 'income': 898,\n"," 'Braeuer': 899,\n"," 'niche': 900,\n"," 'Against': 901,\n"," 'symbol': 902,\n"," 'malls': 903,\n"," 'reigning': 904,\n"," '230': 905,\n"," 'Leumi': 906,\n"," 'eluding': 907,\n"," 'necessary': 908,\n"," 'Issuing': 909,\n"," 'pressuring': 910,\n"," '1,200': 911,\n"," 'preparation': 912,\n"," 'Barcelona': 913,\n"," 'Nakamura': 914,\n"," 'Boston': 915,\n"," 'Pfizer': 916,\n"," 'NavforJapan': 917,\n"," 'quit': 918,\n"," 'worked': 919,\n"," 'Increased': 920,\n"," 'trained': 921,\n"," 'but': 922,\n"," '4th': 923,\n"," '664': 924,\n"," 'Yangzhou': 925,\n"," 'brigades': 926,\n"," 'them': 927,\n"," 'programmatic': 928,\n"," 'Erasing': 929,\n"," 'depleted': 930,\n"," 'payouts': 931,\n"," '1.78': 932,\n"," 'topics': 933,\n"," 'encouraging': 934,\n"," '27.2': 935,\n"," 'artifical': 936,\n"," '7.51': 937,\n"," 'famously': 938,\n"," 'No.': 939,\n"," 'confuse': 940,\n"," 'BRACED': 941,\n"," 'reckless': 942,\n"," 'contrast': 943,\n"," 'Chen': 944,\n"," 'Thai': 945,\n"," 'aided': 946,\n"," 'stifling': 947,\n"," 'reeled': 948,\n"," 'undoubtedly': 949,\n"," 'fanfare': 950,\n"," 'Spectrum': 951,\n"," 'pigsty': 952,\n"," 'seacoast': 953,\n"," 'testify': 954,\n"," 'prominent': 955,\n"," 'physics': 956,\n"," 'Bundesbank': 957,\n"," 'Faberge': 958,\n"," 'descended': 959,\n"," 'fooled': 960,\n"," '6,000': 961,\n"," 'Two': 962,\n"," 'revved': 963,\n"," 'Uniroyal': 964,\n"," 'peril': 965,\n"," 'Weekend': 966,\n"," 'NEW': 967,\n"," 'Feldman': 968,\n"," '1,534': 969,\n"," '61.98': 970,\n"," 'honed': 971,\n"," 'non-State-owned': 972,\n"," 'Fridays': 973,\n"," 'frequent': 974,\n"," 'cleared': 975,\n"," 'yanked': 976,\n"," 'ensure': 977,\n"," 'Fatalities': 978,\n"," 'refers': 979,\n"," 'kingpins': 980,\n"," 'Until': 981,\n"," 'proving': 982,\n"," 'birthday': 983,\n"," 'opponent': 984,\n"," 'disposable': 985,\n"," 'teachers': 986,\n"," 'transferred': 987,\n"," 'fibers': 988,\n"," 'listed': 989,\n"," '9,360': 990,\n"," 'Banc': 991,\n"," 'Renzhi': 992,\n"," 'knocking': 993,\n"," 'vs.': 994,\n"," 'rented': 995,\n"," 'USSR': 996,\n"," 'Changcai': 997,\n"," 'Passport': 998,\n"," 'elements': 999,\n"," ...}"]},"metadata":{},"execution_count":222}]},{"cell_type":"markdown","source":["The idx2word is simply the reverse set of the word2idx set. "],"metadata":{"id":"jmOMDKZ1bZx4"}},{"cell_type":"code","source":["idx2word"],"metadata":{"id":"vSeqPlfbTpWj","executionInfo":{"status":"ok","timestamp":1673195145262,"user_tz":-60,"elapsed":15,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"outputId":"b9932352-474c-4075-d98d-9b8b512cfd59"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: '_PAD_',\n"," 1: '_UNK_',\n"," 2: 'certainly',\n"," 3: 'Ukrainian',\n"," 4: 'notwithstanding',\n"," 5: 'swindled',\n"," 6: '225',\n"," 7: 'resignations',\n"," 8: 'your',\n"," 9: 'pro-family',\n"," 10: 'Parental',\n"," 11: 'demolishing',\n"," 12: 'clippings',\n"," 13: 'Vaclav',\n"," 14: 'Mountain',\n"," 15: 'DeVillars',\n"," 16: 'trafficking',\n"," 17: 'masses',\n"," 18: 'state',\n"," 19: 'aftermath',\n"," 20: 'Brussels',\n"," 21: 'atomic',\n"," 22: 'haven',\n"," 23: 'Marcel',\n"," 24: \"'50s\",\n"," 25: 'Lorin',\n"," 26: 'dropouts',\n"," 27: 'R.I',\n"," 28: 'anti-apartheid',\n"," 29: 'wrack',\n"," 30: 'Autry',\n"," 31: 'friends',\n"," 32: 'Itochu',\n"," 33: '39,000',\n"," 34: 'merge',\n"," 35: 'Relief',\n"," 36: 'tenth',\n"," 37: 'brother',\n"," 38: 'condensers',\n"," 39: 'code',\n"," 40: 'ABCs',\n"," 41: '1,000',\n"," 42: 'dictatorship',\n"," 43: 'institutes',\n"," 44: 'recovery',\n"," 45: 'McCarthy',\n"," 46: 'Close',\n"," 47: 'rural',\n"," 48: 'Referring',\n"," 49: 'brunt',\n"," 50: 'palladium',\n"," 51: 'Guard',\n"," 52: 'redemptions',\n"," 53: 'doubt',\n"," 54: 'ruptured',\n"," 55: 'indicate',\n"," 56: 'Longman',\n"," 57: 'formulating',\n"," 58: 'innovative',\n"," 59: 'workstation',\n"," 60: 'contractor',\n"," 61: 'N.C',\n"," 62: 'Alter',\n"," 63: 'sorts',\n"," 64: 'co-editor',\n"," 65: 'Human',\n"," 66: 'contacted',\n"," 67: 'change',\n"," 68: 'Potter',\n"," 69: '1271',\n"," 70: 'utilities',\n"," 71: 'Jan.',\n"," 72: 'projects',\n"," 73: 'overpriced',\n"," 74: 'idealistic',\n"," 75: '134',\n"," 76: 'willing',\n"," 77: 'airline',\n"," 78: '6.25',\n"," 79: 'Cayman',\n"," 80: 'eating',\n"," 81: 'workweek',\n"," 82: 'plaque',\n"," 83: 'rush',\n"," 84: 'occurring',\n"," 85: 'Brawer',\n"," 86: 'emphasizes',\n"," 87: 'underpinned',\n"," 88: 'limbs',\n"," 89: 'Adlai',\n"," 90: 'homicide',\n"," 91: 'uncomfortable',\n"," 92: 'portrayed',\n"," 93: 'Mayor',\n"," 94: 'TIMES',\n"," 95: 'selecting',\n"," 96: 'Pulkova',\n"," 97: 'tourist',\n"," 98: 'biennial',\n"," 99: 'McCollum',\n"," 100: 'Verne',\n"," 101: 'Guarantee',\n"," 102: 'prohibitions',\n"," 103: 'food',\n"," 104: 'specifies',\n"," 105: 're-enactment',\n"," 106: 'tragedy',\n"," 107: 'disappeared',\n"," 108: 'Anita',\n"," 109: 'proposal',\n"," 110: 'accused',\n"," 111: 'streamline',\n"," 112: 'Semmelman',\n"," 113: 'easiest',\n"," 114: 'manufacturers',\n"," 115: '91.07',\n"," 116: 'domination',\n"," 117: 'strips',\n"," 118: 'severely',\n"," 119: 'irreparable',\n"," 120: 'creed',\n"," 121: 'shortest',\n"," 122: 'simple',\n"," 123: 'exonerating',\n"," 124: '730,000',\n"," 125: 'bet',\n"," 126: 'defend',\n"," 127: 'matching',\n"," 128: 'additions',\n"," 129: 'decline',\n"," 130: 'Rubicam',\n"," 131: 'Bowl',\n"," 132: 'Surveying',\n"," 133: 'conjecture',\n"," 134: 'camps',\n"," 135: 'memos',\n"," 136: 'vigor',\n"," 137: 'longed',\n"," 138: 'Corporate',\n"," 139: 'salt',\n"," 140: 'Zaishuo',\n"," 141: 'principally',\n"," 142: 'walks',\n"," 143: 'Albertville',\n"," 144: 'base',\n"," 145: 'photo',\n"," 146: 'Civil',\n"," 147: 'positions',\n"," 148: 'Muskegon',\n"," 149: 'Fares',\n"," 150: 'Reins',\n"," 151: 'sure',\n"," 152: 'infrared',\n"," 153: 'Probably',\n"," 154: 'own',\n"," 155: 'appeals',\n"," 156: 'Ximei',\n"," 157: 'civilised',\n"," 158: 'annals',\n"," 159: '2917',\n"," 160: 'likes',\n"," 161: '16.95',\n"," 162: 'sealed',\n"," 163: 'west',\n"," 164: 'prosecutor',\n"," 165: '3.86',\n"," 166: 'lumped',\n"," 167: 'owes',\n"," 168: 'agendas',\n"," 169: 'mailings',\n"," 170: 'clients',\n"," 171: 'Congressional',\n"," 172: 'Bierbower',\n"," 173: 'athletes',\n"," 174: 'struggling',\n"," 175: 'Beker',\n"," 176: '5,100',\n"," 177: 'deemed',\n"," 178: 'enforcing',\n"," 179: 'Lang',\n"," 180: 'pouring',\n"," 181: 'aspects',\n"," 182: 'tailspin',\n"," 183: 'Jones',\n"," 184: 'merits',\n"," 185: 'bite',\n"," 186: 'Wilmer',\n"," 187: 'Charlene',\n"," 188: 'lithography',\n"," 189: 'Mosbacher',\n"," 190: 'telex',\n"," 191: 'Autozam',\n"," 192: 'Croatian',\n"," 193: 'Shen',\n"," 194: 'Defaults',\n"," 195: 'Roger',\n"," 196: 'resells',\n"," 197: 'videoconferencing',\n"," 198: 'nightclub',\n"," 199: 'prototype',\n"," 200: 'Child',\n"," 201: 'Carolina',\n"," 202: 'sized',\n"," 203: 'Cafe',\n"," 204: 'Bulgarians',\n"," 205: 'ramps',\n"," 206: 'staphylococcus',\n"," 207: 'pensions',\n"," 208: 'likewise',\n"," 209: 'lapse',\n"," 210: 'Kingston',\n"," 211: 'killing',\n"," 212: 'hesitantly',\n"," 213: 'Peoples',\n"," 214: 'implanting',\n"," 215: 'boldest',\n"," 216: 'Aaron',\n"," 217: 'deadline',\n"," 218: 'Orange',\n"," 219: 'Resolutely',\n"," 220: 'member',\n"," 221: 'pie',\n"," 222: 'tourism',\n"," 223: 'Packaged',\n"," 224: 'reassert',\n"," 225: 'were',\n"," 226: '554',\n"," 227: 'Colson',\n"," 228: 'flags',\n"," 229: 'Bulls',\n"," 230: \"'T-\",\n"," 231: '1,275,000',\n"," 232: 'forty',\n"," 233: 'Rambo',\n"," 234: 'sent',\n"," 235: 'biologists',\n"," 236: 'Thought',\n"," 237: 'Kraft',\n"," 238: 'pre-register',\n"," 239: 'retrieved',\n"," 240: 'firms',\n"," 241: 'Rolodex',\n"," 242: 'handlers',\n"," 243: 'Premier',\n"," 244: 'flood',\n"," 245: 'escaped',\n"," 246: 'Term',\n"," 247: 'Avoidance',\n"," 248: 'Lucas',\n"," 249: 'constructing',\n"," 250: 'Replacing',\n"," 251: 'Dar',\n"," 252: 'Fresenius',\n"," 253: 'yaks',\n"," 254: 'Angela',\n"," 255: 'Urgent',\n"," 256: 'Winster',\n"," 257: 'apparat',\n"," 258: 'Burk',\n"," 259: 'Azem',\n"," 260: 'Billings',\n"," 261: 'Transportation',\n"," 262: 'habitation',\n"," 263: 'Rhine',\n"," 264: 'bark',\n"," 265: 'Mass',\n"," 266: 'Delta',\n"," 267: 'effective',\n"," 268: 'Orlando',\n"," 269: 'ISRAEL',\n"," 270: 'folders',\n"," 271: 'immediate',\n"," 272: 'wireless',\n"," 273: 'portraying',\n"," 274: 'Stern',\n"," 275: 'Plain',\n"," 276: 'Lonbado',\n"," 277: 'shopper',\n"," 278: 'Right',\n"," 279: 'knowledge',\n"," 280: 'satisfies',\n"," 281: 'cleansing',\n"," 282: 'ENGRAPH',\n"," 283: 'Throughout',\n"," 284: 'characters',\n"," 285: 'inflow',\n"," 286: 'Kim',\n"," 287: 'Hershey',\n"," 288: 'Sons',\n"," 289: 'floats',\n"," 290: 'Schantz',\n"," 291: 'commitment',\n"," 292: 'talks',\n"," 293: 'please',\n"," 294: '37.6',\n"," 295: 'creative',\n"," 296: 'annum',\n"," 297: 'Tucson',\n"," 298: 'February',\n"," 299: 'philosophers',\n"," 300: 'ACCEPTANCES',\n"," 301: 'pre-trial',\n"," 302: 'civilian',\n"," 303: 'applied',\n"," 304: 'Wenceslas',\n"," 305: 'versions',\n"," 306: 'grandmaster',\n"," 307: 'stucco',\n"," 308: 'Profits',\n"," 309: 'Rongheng',\n"," 310: '1.13',\n"," 311: 'inflation',\n"," 312: 'until',\n"," 313: 'hamstrung',\n"," 314: '1970s',\n"," 315: 'shoreline',\n"," 316: 'Richeng',\n"," 317: 'Baby',\n"," 318: 'Feilibeiqiu',\n"," 319: 'foaming',\n"," 320: 'brushed',\n"," 321: 'with',\n"," 322: 'chirpy',\n"," 323: 'depreciation',\n"," 324: 'Zongmin',\n"," 325: 'husband',\n"," 326: 'SPAN',\n"," 327: 'Cox',\n"," 328: 'rusting',\n"," 329: 'Bleus',\n"," 330: 'ordered',\n"," 331: 'similar',\n"," 332: 'Contestants',\n"," 333: 'specifications',\n"," 334: 'Zunjing',\n"," 335: 'recordkeeping',\n"," 336: 'Trimmer',\n"," 337: 'Runkel',\n"," 338: '128.19',\n"," 339: 'inside',\n"," 340: 'drinking',\n"," 341: 'Worried',\n"," 342: 'spheres',\n"," 343: 'Lebanese',\n"," 344: 'Armstrong',\n"," 345: '18.75',\n"," 346: 'benefited',\n"," 347: 'basketball',\n"," 348: 'trumpet',\n"," 349: 'Bets',\n"," 350: 'sluggish',\n"," 351: 'Adults',\n"," 352: 'recital',\n"," 353: 'unknowingly',\n"," 354: 'shaped',\n"," 355: '9000',\n"," 356: 'pits',\n"," 357: 'alluvial',\n"," 358: 'Soap',\n"," 359: 'Cronkite',\n"," 360: 'sensibility',\n"," 361: 'adjustment',\n"," 362: 'Broward',\n"," 363: 'Taste',\n"," 364: 'alleges',\n"," 365: 'midlevel',\n"," 366: 'domino',\n"," 367: 'Defu',\n"," 368: 'consecutive',\n"," 369: 'mark',\n"," 370: 'croissants',\n"," 371: 'Bible',\n"," 372: 'speedily',\n"," 373: 'Manchuria',\n"," 374: 'Khalifa',\n"," 375: '366.79',\n"," 376: 'Matamoros',\n"," 377: 'links',\n"," 378: 'commanding',\n"," 379: 'Grasso',\n"," 380: 'crow',\n"," 381: 'compared',\n"," 382: '158,300',\n"," 383: 'Vicks',\n"," 384: 'Quezon',\n"," 385: 'Bogart',\n"," 386: 'amuse',\n"," 387: 'scales',\n"," 388: 'finger',\n"," 389: '105',\n"," 390: 'molecule',\n"," 391: 'folk',\n"," 392: 'adjustable',\n"," 393: 'underwent',\n"," 394: 'steelmakers',\n"," 395: 'route',\n"," 396: 'Pictures',\n"," 397: '5.94',\n"," 398: 'percent',\n"," 399: 'mechanics',\n"," 400: 'PACs',\n"," 401: 'stretched',\n"," 402: 'equilibrium',\n"," 403: 'dual',\n"," 404: 'clump',\n"," 405: 'expressing',\n"," 406: 'Marie',\n"," 407: 'embellish',\n"," 408: 'judicious',\n"," 409: 'sternly',\n"," 410: 'registered',\n"," 411: '605',\n"," 412: 'formed',\n"," 413: 'Buha',\n"," 414: '41.5',\n"," 415: 'canceling',\n"," 416: 'taught',\n"," 417: 'Afghans',\n"," 418: 'blazing',\n"," 419: '36.3',\n"," 420: 'surpass',\n"," 421: 'sanctioning',\n"," 422: 'edging',\n"," 423: 'resulting',\n"," 424: 'NT&SA',\n"," 425: 'Too',\n"," 426: 'damper',\n"," 427: 'sociology',\n"," 428: 'outfly',\n"," 429: 'hitches',\n"," 430: 'both',\n"," 431: 'formulations',\n"," 432: 'flocked',\n"," 433: 'Hayes',\n"," 434: '221',\n"," 435: 'Elliott',\n"," 436: 'Vicky',\n"," 437: 'Drogoul',\n"," 438: '1993',\n"," 439: 'contingency',\n"," 440: 'Philippine',\n"," 441: 'requires',\n"," 442: 'amass',\n"," 443: 'disclosure',\n"," 444: 'precipitated',\n"," 445: 'deepwater',\n"," 446: 'tripped',\n"," 447: '11,586',\n"," 448: 'product',\n"," 449: 'swine',\n"," 450: 'Durable',\n"," 451: 'warehouse',\n"," 452: '152.62',\n"," 453: 'donating',\n"," 454: 'defective',\n"," 455: 'feature',\n"," 456: '465,000',\n"," 457: 'hinders',\n"," 458: 'fell',\n"," 459: 'trembling',\n"," 460: 'prosper',\n"," 461: 'corporate',\n"," 462: 'sentiment',\n"," 463: 'whooper',\n"," 464: 'obstructing',\n"," 465: 'Banxquote',\n"," 466: 'Miller',\n"," 467: 'drunkenness',\n"," 468: 'contractors',\n"," 469: 'equation',\n"," 470: 'Xuzhou',\n"," 471: 'ammonia',\n"," 472: 'Vic',\n"," 473: 'shields',\n"," 474: 'Crowe',\n"," 475: 'demurs',\n"," 476: '3717.46',\n"," 477: 'herds',\n"," 478: 'Daniel',\n"," 479: '135',\n"," 480: 'notoriously',\n"," 481: 'Fruit',\n"," 482: 'utopia',\n"," 483: 'grouped',\n"," 484: 'crept',\n"," 485: 'Guoxian',\n"," 486: 'seminar',\n"," 487: 'zag',\n"," 488: '5,651',\n"," 489: 'chart',\n"," 490: 'hens',\n"," 491: 'tempting',\n"," 492: 'floating',\n"," 493: '135.9',\n"," 494: 'noting',\n"," 495: 'kettle',\n"," 496: 'regards',\n"," 497: '12:00',\n"," 498: 'lifetime',\n"," 499: '9.39',\n"," 500: 'superconductors',\n"," 501: 'reputations',\n"," 502: 'Kleinwort',\n"," 503: 'schizophrenic',\n"," 504: 'A&M',\n"," 505: 'weary',\n"," 506: 'information',\n"," 507: 'innovation',\n"," 508: 'plummet',\n"," 509: 'Loess',\n"," 510: '70.2',\n"," 511: 'earnestly',\n"," 512: 'rings',\n"," 513: 'policing',\n"," 514: 'collapsed',\n"," 515: 'turban',\n"," 516: 'videotape',\n"," 517: 'intermittent',\n"," 518: 'Applications',\n"," 519: 'Sargent',\n"," 520: 'receipt',\n"," 521: 'miscommunication',\n"," 522: 'affect',\n"," 523: 'granting',\n"," 524: 'Fortunately',\n"," 525: 'Zhenhua',\n"," 526: 'throw',\n"," 527: 'Lamle',\n"," 528: 'productions',\n"," 529: 'magazined',\n"," 530: 'Maynen',\n"," 531: 'licensing',\n"," 532: 'TCL',\n"," 533: 'Hallucigenia',\n"," 534: 'management',\n"," 535: 'assuage',\n"," 536: 'drying',\n"," 537: 'Eavesdropping',\n"," 538: 'refrigerators',\n"," 539: 'whiner',\n"," 540: 'unknown',\n"," 541: 'Inc.',\n"," 542: '12.3',\n"," 543: 'Oversight',\n"," 544: 'vacated',\n"," 545: 'patents',\n"," 546: 'Symposium',\n"," 547: 'default',\n"," 548: 'Skeptics',\n"," 549: 'Kobayashi',\n"," 550: '1,848,000',\n"," 551: 'Tire',\n"," 552: 'Zhuhai',\n"," 553: 'HyperCard',\n"," 554: 'garden',\n"," 555: 'EPA',\n"," 556: 'paneling',\n"," 557: 'Herring',\n"," 558: 'ferroelectric',\n"," 559: 'Bishkek',\n"," 560: 'scoops',\n"," 561: 'averages',\n"," 562: 'Shlenker',\n"," 563: 'colonies',\n"," 564: 'Markese',\n"," 565: 'furnishings',\n"," 566: 'anti-foreigner',\n"," 567: 'rivals',\n"," 568: 'toured',\n"," 569: 'yesterday',\n"," 570: 'quieted',\n"," 571: 'astronomy',\n"," 572: 'cigarettes',\n"," 573: 'Tillery',\n"," 574: 'reply',\n"," 575: 'inexpensively',\n"," 576: 'businesspeople',\n"," 577: '10.45',\n"," 578: 'Fengzhen',\n"," 579: 'nurtured',\n"," 580: '716',\n"," 581: '28th',\n"," 582: 'salaried',\n"," 583: 'strict',\n"," 584: 'realization',\n"," 585: 'Mingxia',\n"," 586: 'severity',\n"," 587: 'Sultan',\n"," 588: 'Literary',\n"," 589: 'Lean',\n"," 590: 'Erich',\n"," 591: 'Bradstreet',\n"," 592: 'Ark',\n"," 593: 'fauna',\n"," 594: 'liberals',\n"," 595: 'joblessness',\n"," 596: 'sub-station',\n"," 597: 'accuses',\n"," 598: 'Principles',\n"," 599: 'Bebear',\n"," 600: 'accelerates',\n"," 601: 'Museum',\n"," 602: 'confirmation',\n"," 603: 'genetically',\n"," 604: 'reality',\n"," 605: 'Military',\n"," 606: 'occupancy',\n"," 607: 'Barnard',\n"," 608: 'restated',\n"," 609: 'SOYBEANS',\n"," 610: '2.85',\n"," 611: 'Christians',\n"," 612: 'retiree',\n"," 613: 'boxes',\n"," 614: 'movie',\n"," 615: 'Gill',\n"," 616: 'Immunex',\n"," 617: 'key',\n"," 618: 'benefits',\n"," 619: 'impetus',\n"," 620: 'disdaining',\n"," 621: '1.09',\n"," 622: 'meteorological',\n"," 623: 'salesparson',\n"," 624: 'Boulder',\n"," 625: 'OTIS',\n"," 626: 'plurality',\n"," 627: 'anti-outsider',\n"," 628: 'bluebloods',\n"," 629: '46.8',\n"," 630: 'artists',\n"," 631: 'Published',\n"," 632: 'Clean',\n"," 633: '875',\n"," 634: 'debugged',\n"," 635: 'Lu',\n"," 636: 'Father',\n"," 637: 'Lavoro',\n"," 638: 'performance',\n"," 639: 'crimes',\n"," 640: 'infuse',\n"," 641: 'poohbah',\n"," 642: '94,543',\n"," 643: 'bartered',\n"," 644: 'hurtling',\n"," 645: 'arena',\n"," 646: 'unification',\n"," 647: 'Stephen',\n"," 648: 'direction',\n"," 649: 'Likewise',\n"," 650: 'Kiko',\n"," 651: 'asses',\n"," 652: 'bloc',\n"," 653: 'real',\n"," 654: 'Minwax',\n"," 655: 'stimuli',\n"," 656: 'caricatures',\n"," 657: 'Broderick',\n"," 658: 'Handoger',\n"," 659: 'worthier',\n"," 660: 'Nashville',\n"," 661: 'baseline',\n"," 662: 'arteries',\n"," 663: 'flatout',\n"," 664: 'Louisiana',\n"," 665: 'murdered',\n"," 666: 'offend',\n"," 667: 'updated',\n"," 668: 'sought',\n"," 669: '5',\n"," 670: 'Treaty',\n"," 671: 'Naguib',\n"," 672: 'Sharfman',\n"," 673: 'Mochida',\n"," 674: 'Vt',\n"," 675: 'Gotlieb',\n"," 676: '28.3',\n"," 677: 'ethical',\n"," 678: 'preventing',\n"," 679: 'tower',\n"," 680: 'milk',\n"," 681: 'Bolling',\n"," 682: 'partnerships',\n"," 683: 'bitch',\n"," 684: 'commemoration',\n"," 685: 'bookings',\n"," 686: 'Harbin',\n"," 687: 'Sudan',\n"," 688: 'Combined',\n"," 689: 'outgoing',\n"," 690: 'miscreant',\n"," 691: 'Jewish',\n"," 692: 'art',\n"," 693: 'Garland',\n"," 694: 'imposed',\n"," 695: 'Youhao',\n"," 696: 'miscalculated',\n"," 697: 'pens',\n"," 698: 'superiority',\n"," 699: 'GDR',\n"," 700: 'offerings',\n"," 701: 'paradox',\n"," 702: 'e',\n"," 703: 'matryoshka',\n"," 704: 'Operations',\n"," 705: 'dimension',\n"," 706: 'reassured',\n"," 707: 'Wiesenthal',\n"," 708: 'glacial',\n"," 709: 'splinter',\n"," 710: 'swimming',\n"," 711: 'softening',\n"," 712: 'enactment',\n"," 713: 'Siemienas',\n"," 714: 'outbreaks',\n"," 715: 'Taiwanese',\n"," 716: 'warehousing',\n"," 717: 'streets',\n"," 718: 'Manufacturing',\n"," 719: 'charging',\n"," 720: 'Scrap',\n"," 721: 'placid',\n"," 722: 'bitter',\n"," 723: '52',\n"," 724: 'EC',\n"," 725: 'Tories',\n"," 726: 'Wildlife',\n"," 727: '58.97',\n"," 728: 'horse',\n"," 729: 'Ciporkin',\n"," 730: '1,770',\n"," 731: 'gains',\n"," 732: 'Gary',\n"," 733: 'flavors',\n"," 734: 'flair',\n"," 735: 'picking',\n"," 736: 'assistant',\n"," 737: 'whiskery',\n"," 738: 'traveler',\n"," 739: 'Principals',\n"," 740: 'FDIC',\n"," 741: 'accelerated',\n"," 742: 'forerunner',\n"," 743: 'Ames',\n"," 744: 'San',\n"," 745: 'Dec.',\n"," 746: 'paced',\n"," 747: 'transplant',\n"," 748: 'Non-Proliferation',\n"," 749: 'G.',\n"," 750: 'Indiana',\n"," 751: 'telescopes',\n"," 752: 'Flamply',\n"," 753: 'friend',\n"," 754: 'her',\n"," 755: 'Chevrolet',\n"," 756: 'merely',\n"," 757: 'employs',\n"," 758: 'LAMBERT',\n"," 759: 'loading',\n"," 760: 'capacities',\n"," 761: 'Michigan',\n"," 762: 'irritates',\n"," 763: 'centenary',\n"," 764: 'Sasha',\n"," 765: 'disclosed',\n"," 766: 'polled',\n"," 767: 'Qu',\n"," 768: 'Quality',\n"," 769: 'buoy',\n"," 770: 'president',\n"," 771: 'subsidy',\n"," 772: 'appease',\n"," 773: 'piglet',\n"," 774: 'squashed',\n"," 775: 'matched',\n"," 776: 'provided',\n"," 777: 'instructor',\n"," 778: 'room',\n"," 779: 'Riepe',\n"," 780: 'unpopular',\n"," 781: 'stabilizes',\n"," 782: 'boundary',\n"," 783: 'products',\n"," 784: 'Aviacion',\n"," 785: 'Baghdad',\n"," 786: 'fingered',\n"," 787: 'indoctrinated',\n"," 788: '31st',\n"," 789: 'fanatic',\n"," 790: 'colliding',\n"," 791: 'Breeden',\n"," 792: 'Ningguo',\n"," 793: 'boosters',\n"," 794: 'Aldus',\n"," 795: 'Now',\n"," 796: 'fights',\n"," 797: 'orbital',\n"," 798: 'exporter',\n"," 799: 'Tiantong',\n"," 800: 'dropping',\n"," 801: 'van',\n"," 802: 'Medicare',\n"," 803: 'can',\n"," 804: 'remains',\n"," 805: 'Companies',\n"," 806: 'Cote',\n"," 807: 'scorecard',\n"," 808: '238.15',\n"," 809: 'Americans',\n"," 810: 'ranking',\n"," 811: 'Repertory',\n"," 812: 'repercussions',\n"," 813: 'Hutchinson',\n"," 814: '1080',\n"," 815: 'Hubei',\n"," 816: 'wildlife',\n"," 817: 'united',\n"," 818: 'extremists',\n"," 819: 'Sixth',\n"," 820: 'yuppie',\n"," 821: 'Khieu',\n"," 822: '72',\n"," 823: 'concrete',\n"," 824: 'Particularly',\n"," 825: 'request',\n"," 826: 'financing',\n"," 827: 'exceeds',\n"," 828: '1,859',\n"," 829: 'Nasser',\n"," 830: 'Politburo',\n"," 831: 'Gamble',\n"," 832: 'unexpectedly',\n"," 833: 'Sam',\n"," 834: 'portions',\n"," 835: '147',\n"," 836: '37,820',\n"," 837: 'Somali',\n"," 838: 'bode',\n"," 839: 'allow',\n"," 840: 'Lawrenson',\n"," 841: 'clutter',\n"," 842: 'unplanned',\n"," 843: '770',\n"," 844: 'allows',\n"," 845: 'Ladenburg',\n"," 846: 'seed',\n"," 847: 'eligible',\n"," 848: 'Eskenazi',\n"," 849: 'sells',\n"," 850: 'Earlier',\n"," 851: 'conceal',\n"," 852: 'Kean',\n"," 853: 'judgment',\n"," 854: 'sniped',\n"," 855: 'GTE',\n"," 856: 'gripped',\n"," 857: 'Fishkill',\n"," 858: 'Herbig',\n"," 859: 'Taking',\n"," 860: 'ennumerated',\n"," 861: '7.60',\n"," 862: '9',\n"," 863: 'regulators',\n"," 864: 'Adds',\n"," 865: 'freshness',\n"," 866: 'rape',\n"," 867: 'how',\n"," 868: 'shattered',\n"," 869: 'withdrawn',\n"," 870: 'Have',\n"," 871: 'exceed',\n"," 872: '137.6',\n"," 873: 'Klein',\n"," 874: '144.584',\n"," 875: 'underworld',\n"," 876: 'Spy',\n"," 877: 'exhibits',\n"," 878: 'Charles',\n"," 879: 'sits',\n"," 880: 'Suo',\n"," 881: 'Tribe',\n"," 882: '1,828,000',\n"," 883: 'student',\n"," 884: 'Ling',\n"," 885: 'Handholding',\n"," 886: 'jurors',\n"," 887: '82,000',\n"," 888: 'Vegas',\n"," 889: 'fluid',\n"," 890: 'Times',\n"," 891: 'coat',\n"," 892: 'Backer',\n"," 893: 'redeem',\n"," 894: 'Dan',\n"," 895: 'damped',\n"," 896: 'Ventspils',\n"," 897: 'sleep',\n"," 898: 'income',\n"," 899: 'Braeuer',\n"," 900: 'niche',\n"," 901: 'Against',\n"," 902: 'symbol',\n"," 903: 'malls',\n"," 904: 'reigning',\n"," 905: '230',\n"," 906: 'Leumi',\n"," 907: 'eluding',\n"," 908: 'necessary',\n"," 909: 'Issuing',\n"," 910: 'pressuring',\n"," 911: '1,200',\n"," 912: 'preparation',\n"," 913: 'Barcelona',\n"," 914: 'Nakamura',\n"," 915: 'Boston',\n"," 916: 'Pfizer',\n"," 917: 'NavforJapan',\n"," 918: 'quit',\n"," 919: 'worked',\n"," 920: 'Increased',\n"," 921: 'trained',\n"," 922: 'but',\n"," 923: '4th',\n"," 924: '664',\n"," 925: 'Yangzhou',\n"," 926: 'brigades',\n"," 927: 'them',\n"," 928: 'programmatic',\n"," 929: 'Erasing',\n"," 930: 'depleted',\n"," 931: 'payouts',\n"," 932: '1.78',\n"," 933: 'topics',\n"," 934: 'encouraging',\n"," 935: '27.2',\n"," 936: 'artifical',\n"," 937: '7.51',\n"," 938: 'famously',\n"," 939: 'No.',\n"," 940: 'confuse',\n"," 941: 'BRACED',\n"," 942: 'reckless',\n"," 943: 'contrast',\n"," 944: 'Chen',\n"," 945: 'Thai',\n"," 946: 'aided',\n"," 947: 'stifling',\n"," 948: 'reeled',\n"," 949: 'undoubtedly',\n"," 950: 'fanfare',\n"," 951: 'Spectrum',\n"," 952: 'pigsty',\n"," 953: 'seacoast',\n"," 954: 'testify',\n"," 955: 'prominent',\n"," 956: 'physics',\n"," 957: 'Bundesbank',\n"," 958: 'Faberge',\n"," 959: 'descended',\n"," 960: 'fooled',\n"," 961: '6,000',\n"," 962: 'Two',\n"," 963: 'revved',\n"," 964: 'Uniroyal',\n"," 965: 'peril',\n"," 966: 'Weekend',\n"," 967: 'NEW',\n"," 968: 'Feldman',\n"," 969: '1,534',\n"," 970: '61.98',\n"," 971: 'honed',\n"," 972: 'non-State-owned',\n"," 973: 'Fridays',\n"," 974: 'frequent',\n"," 975: 'cleared',\n"," 976: 'yanked',\n"," 977: 'ensure',\n"," 978: 'Fatalities',\n"," 979: 'refers',\n"," 980: 'kingpins',\n"," 981: 'Until',\n"," 982: 'proving',\n"," 983: 'birthday',\n"," 984: 'opponent',\n"," 985: 'disposable',\n"," 986: 'teachers',\n"," 987: 'transferred',\n"," 988: 'fibers',\n"," 989: 'listed',\n"," 990: '9,360',\n"," 991: 'Banc',\n"," 992: 'Renzhi',\n"," 993: 'knocking',\n"," 994: 'vs.',\n"," 995: 'rented',\n"," 996: 'USSR',\n"," 997: 'Changcai',\n"," 998: 'Passport',\n"," 999: 'elements',\n"," ...}"]},"metadata":{},"execution_count":223}]},{"cell_type":"markdown","source":["To build the word embeddings we could make an own Word2Vec Model (Distributed Vectorization Method) based on this dataset or it is even possible to use a Discrete Vectorization Methods like TF-IDF based on this dataset. However, the pretrained models, e.g. Glove are optimized and trained on a huge dataset. Therefore it will be favorized for this exerise. In a first step a \"pre\" Word embedding matrix is created."],"metadata":{"id":"KdGepue7Xzho"}},{"cell_type":"code","source":["!wget https://nlp.stanford.edu/data/glove.6B.zip"],"metadata":{"id":"pEmnuuc3Ttl-","executionInfo":{"status":"ok","timestamp":1673195306671,"user_tz":-60,"elapsed":160994,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"98f14f4e-eb70-46e4-c0bd-f39ffaaac592"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-01-08 16:25:44--  https://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2023-01-08 16:25:44--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: glove.6B.zip.3\n","\n","glove.6B.zip.3      100%[===================>] 822.24M  5.13MB/s    in 2m 40s  \n","\n","2023-01-08 16:28:25 (5.15 MB/s) - glove.6B.zip.3 saved [862182613/862182613]\n","\n"]}]},{"cell_type":"code","source":["!unzip glove.6B.zip"],"metadata":{"id":"6UrWc4oUV3rd","executionInfo":{"status":"ok","timestamp":1673195648079,"user_tz":-60,"elapsed":341411,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8fe74193-0d79-40e6-e2d9-74d5a875d424"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  glove.6B.zip\n","replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","  inflating: glove.6B.50d.txt        \n","  inflating: glove.6B.100d.txt       \n","  inflating: glove.6B.200d.txt       \n","  inflating: glove.6B.300d.txt       \n"]}]},{"cell_type":"code","source":["# Variable input dimension\n","WORD_DIM = 100\n","\n","# Glove\n","_ = glove2word2vec('glove.6B.100d.txt', 'glove.6B.100d_w2v.txt')\n","word2vec = KeyedVectors.load_word2vec_format('glove.6B.100d_w2v.txt', binary=False)"],"metadata":{"id":"ZANy1OQrV6NG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_"],"metadata":{"id":"lao5bDupeCNe","executionInfo":{"status":"ok","timestamp":1673195670433,"user_tz":-60,"elapsed":14,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0dbc236a-f733-44dc-a65f-9450ae629a67"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(400000, 100)"]},"metadata":{},"execution_count":227}]},{"cell_type":"markdown","source":["_ is the inital size of the word2vec based on the 'glove.6B.100d.txt'. Note: The size will be reduced soon to 25505 because this is the size I have in the dataset."],"metadata":{"id":"SNusv8ptpnvw"}},{"cell_type":"code","source":["# Test the Word2Vec Model with the most_similar function\n","word2vec.most_similar(\"pizza\")"],"metadata":{"id":"_NrPZrw5eiHb","executionInfo":{"status":"ok","timestamp":1673195670433,"user_tz":-60,"elapsed":12,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5cd8ad92-95f5-434b-98df-950e4a7db229"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('sandwich', 0.7488481402397156),\n"," ('sandwiches', 0.7221847176551819),\n"," ('bread', 0.7006676197052002),\n"," ('pizzas', 0.7004501819610596),\n"," ('burger', 0.6977596282958984),\n"," ('snack', 0.6840100288391113),\n"," ('taco', 0.678828239440918),\n"," ('pie', 0.6776915788650513),\n"," ('chicken', 0.6714670658111572),\n"," ('burgers', 0.6690315008163452)]"]},"metadata":{},"execution_count":228}]},{"cell_type":"markdown","source":["Ok, great it works!"],"metadata":{"id":"Zkxz2iJ2plOe"}},{"cell_type":"markdown","source":["In the next chunk the final word embedding matrix is created. It is based on a random set of selected indices of the Ontonotes5 dataset and the copy from word2vec embeddings of Glove!"],"metadata":{"id":"2c4NUjOKdpy1"}},{"cell_type":"code","source":["# Initialization of the word embedding matrix, with a given Word Dimension and based on randomly selected indices of the Ontonotes5 dataset\n","# With the len (word2idx) we get exactly the vocab size\n","\n","word_embeddings = np.random.rand(len(word2idx), WORD_DIM)\n","\n","# Set the values to 0 for padding. \n","word_embeddings[word2idx['_PAD_']] = np.zeros(WORD_DIM)\n","\n","# Copy from word2vec\n","for word in vocabulary:\n","  if word in word2vec: #only add to the final word embedding matrix when word has an entry in the glove word2vec model \n","    #print(word)\n","    #print(word2idx[word])\n","    #print(len(word2vec[word]))\n","    word_embeddings[word2idx[word], :] = word2vec[word] #copy word embeddings to our word embeddings matrix --> all 100 values of the word2vec are selected with the : to one word2idx\n","    #print(word_embeddings)"],"metadata":{"id":"zPScmsLyV9MJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(word_embeddings)\n","word_embeddings.shape"],"metadata":{"id":"nFWTzz_ketKj","executionInfo":{"status":"ok","timestamp":1673195670434,"user_tz":-60,"elapsed":8,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"03e8aff6-9f15-4c6b-93ac-aee651614ca8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.          0.          0.         ...  0.          0.\n","   0.        ]\n"," [ 0.03142919  0.63641041  0.31435598 ...  0.89711026  0.88708642\n","   0.77987555]\n"," [ 0.090393    0.60966003  0.67360002 ... -0.49860001 -0.045213\n","   0.73347002]\n"," ...\n"," [-0.33869001 -0.42300001  1.43350005 ... -0.04752    -0.15391999\n","  -0.0058618 ]\n"," [ 0.058737    0.60421997 -0.55057001 ... -0.54679     0.76375002\n","  -0.031475  ]\n"," [-0.059148    0.093715    0.072975   ... -0.24614     0.12647\n","   0.58368999]]\n"]},{"output_type":"execute_result","data":{"text/plain":["(25505, 100)"]},"metadata":{},"execution_count":230}]},{"cell_type":"markdown","source":["The Shape is: The complete vocabulary (25503+2) and the Word Dimension based on the variable input. The +2 comes from the these two candidates: *{'_PAD_': 0, '_UNK_': 1}*. "],"metadata":{"id":"EnrHUUiTe3F8"}},{"cell_type":"markdown","source":["## Process the Data for the Model"],"metadata":{"id":"9Xzk-Jx3yT-3"}},{"cell_type":"markdown","source":["The word2idx which are the word embedding indeces are added to the existing tokens of the dataset. This must be done in order that the model can be fed and compute the NER."],"metadata":{"id":"G0KMNrzYm5a1"}},{"cell_type":"code","source":["# Looping through each dataset\n","for split_data in [train_data.data, val_data.data, test_data.data]: \n","  for sample in split_data: #looping each row for each splits\n","    sample['word_idx'] = [] #initialisation of an empty list for a new index! The word_idx.\n","    for token in sample['tokens']:\n","      # If a word is not in our vocabulary, we put the UNK token instead # If a word is in the vocabulary set the index of the token is taken \n","      sample['word_idx'].append(word2idx[token] if token in word2idx else word2idx['_UNK_'])"],"metadata":{"id":"kjDVApnbyd7O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max(len(sample['tokens']) for sample in train_data.data), \\\n","max(len(sample['tokens']) for sample in val_data.data), \\\n","max(len(sample['tokens']) for sample in test_data.data)"],"metadata":{"id":"NQ6W5ETNf7cx","executionInfo":{"status":"ok","timestamp":1673195670918,"user_tz":-60,"elapsed":3,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6645e1d9-ee2c-4cda-bbe0-21615bc1dbdd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(210, 186, 151)"]},"metadata":{},"execution_count":232}]},{"cell_type":"markdown","source":["The last step is to adding extra padding tokens to the input data to make it the same length as the desired input size. As it can be seen the train data set has the largest possible token size of 210 for one sample/row."],"metadata":{"id":"C2QwEzbPjAeq"}},{"cell_type":"code","source":["PAD_LENGTH = 210\n","\n","for split_data in [train_data.data, val_data.data, test_data.data]:\n","  for sample in split_data:\n","    while len(sample['word_idx']) < PAD_LENGTH:\n","      sample['word_idx'].append(word2idx['_PAD_'])\n","    \n","\n","      # Because we are padding our inputs, we also have to pad the output! \n","      # Therefore adding \"_PAD_\" would compute the prediction for it.\n","      # A special value like -100 must be added to the output .\n","      sample['y_ners'].append(-100)\n","      sample['ners'].append(-100)\n","\n","    # Sanity check \n","\n","    # From the lecturer: \n","    #assert len(sample['word_idx']) == PAD_LENGTH\n","    # Assert is used to check if a certain condition is met. If the condition is met, the code continues to run as normal. If the condition is not met, an AssertionError is raised and the code execution is stopped\n","\n","    # It can be rewritten to (clearer to understand for me)\n","    if len(sample['word_idx']) != PAD_LENGTH:\n","      raise AssertionError(\"The length of the word index list is not equal to the padding length.\")"],"metadata":{"id":"zMx0GlWmf9eT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Models"],"metadata":{"id":"jS3Iz_nfyfY6"}},{"cell_type":"markdown","source":["### RNN"],"metadata":{"id":"gJN-MajBnMls"}},{"cell_type":"markdown","source":["Define the first model. A RNN:"],"metadata":{"id":"Rtz-ZI0fLpmC"}},{"cell_type":"code","source":["class MyNERModel(nn.Module):\n","    def __init__(self, dropout, hidden_dim, classes_num, words_num, word_dim):\n","        super(MyNERModel, self).__init__()\n","\n","        self.word_embedding = nn.Embedding(num_embeddings=words_num, embedding_dim=word_dim) #word embedding layer (object)\n","        \n","        # main component\n","        self.word_rnn = nn.RNN(input_size=word_dim,\n","                               hidden_size=hidden_dim,\n","                               num_layers=1,\n","                               batch_first=True,\n","                               dropout=0, # No dropout; it is complicated for RNNs. \n","                               bidirectional=False)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = nn.Tanh()\n","\n","        # The last layer to compute the probabilities for the output classes\n","        self.final_layer = nn.Linear(in_features=hidden_dim, out_features=classes_num)\n","        \n","        \n","    def forward(self, x):\n","        x_words = self.word_embedding(x['word_idx']) # Convert into word embeddings\n","                \n","        x_words = self.dropout(x_words)\n","        \n","        # Documentation https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n","        # hidden will be the final hidden state (BxH) \n","        # whereas output contains the values of the hidden states for each time step (BxLxH)\n","        output, last_hidden_state = self.word_rnn(x_words)\n","        \n","        output = self.activation(output)\n","        output = self.dropout(output)\n","\n","        # Compute the log probabilities. We do not compute the probabilities with Softmax because depending the loss function, we might require unnormalized or probabilities.\n","        # Worst case, we can always apply F.softmax(output, dim=-1) later.\n","        logits = self.final_layer(output) #projections to the classifaction layer --> output distribution / probabilities for all possible labels\n","        return logits"],"metadata":{"id":"ETSyr1-Ayt_s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Testing:"],"metadata":{"id":"NVzT2UhnrPfv"}},{"cell_type":"code","source":["# Example of a batch=1 and 8 word indeces\n","input = {'word_idx': torch.tensor([[0,1,2,3,4,5,6,7]])}\n","input"],"metadata":{"id":"pos4qJKauu4q","executionInfo":{"status":"ok","timestamp":1673195673541,"user_tz":-60,"elapsed":11,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3cb6c5fd-80a5-4765-a94a-795920cc1b16"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'word_idx': tensor([[0, 1, 2, 3, 4, 5, 6, 7]])}"]},"metadata":{},"execution_count":235}]},{"cell_type":"code","source":["ner = MyNERModel(dropout=0.3, hidden_dim=50, classes_num=3, words_num=8, word_dim=10)\n","logits = ner(input) #give logits of NER Model based on input size (6 indices)\n","logits, logits.size()"],"metadata":{"id":"2kfF6EpIuvbR","executionInfo":{"status":"ok","timestamp":1673195673542,"user_tz":-60,"elapsed":11,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e10f42d2-39a5-4d9d-82fb-0d94fd37f4c3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[ 0.1515, -0.0144,  0.1631],\n","          [ 0.4820, -0.0824, -0.4073],\n","          [ 0.0260, -0.2630, -0.0012],\n","          [ 0.3422,  0.2419,  0.2124],\n","          [ 0.4627, -0.0209,  0.0192],\n","          [ 0.2996, -0.3788, -0.1090],\n","          [ 0.0466, -0.0693,  0.2355],\n","          [ 0.3668, -0.2152, -0.2589]]], grad_fn=<ViewBackward0>),\n"," torch.Size([1, 8, 3]))"]},"metadata":{},"execution_count":236}]},{"cell_type":"markdown","source":["The model is running without errors."],"metadata":{"id":"srnMDNjQu2K5"}},{"cell_type":"markdown","source":["Define a metric for later: F1 score is suitable for evaluating the performance of a classifaction model, which a Named Entity Recogntion is."],"metadata":{"id":"Sf2ffRyTrR4f"}},{"cell_type":"code","source":["# Metric\n","def compute_f1(preds, golds):\n","  return f1_score(preds, golds, average='macro')"],"metadata":{"id":"x1-N7QlvwTP1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The F1 score is a metric that combines precision and recall to measure the model's performance in terms of its ability to correctly predict the named entity labels in the data. "],"metadata":{"id":"UZs6pVHvxNEu"}},{"cell_type":"markdown","source":["### Transfer Learning Model"],"metadata":{"id":"IMr4rwZIoIvV"}},{"cell_type":"markdown","source":["Next I show two different Approaches for this Method. Both Ideas wont work, but I wanted to show that I tried it at least."],"metadata":{"id":"6oXvbDqfEAuB"}},{"cell_type":"markdown","source":["Idea 1:"],"metadata":{"id":"a1ftpkDRC2-a"}},{"cell_type":"code","source":["# Load a pre-trained model\n","Transfer_Model1 = transformers.BertModel.from_pretrained('bert-base-uncased')"],"metadata":{"id":"YyQZeL56t_kX","executionInfo":{"status":"ok","timestamp":1673195675509,"user_tz":-60,"elapsed":1974,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"439026ea-86e0-4947-e070-6d147e3e850c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["# Freeze the model weights (so that they are not updated during training --> no finetuning)\n","for param in Transfer_Model1.parameters():\n","    param.requires_grad = False\n","\n","# Replace the classifier layer with a new one\n","num_labels = len(Ontonotes5Dataset.MAPPING_Y_NER_LABELS) # length of NER labels\n","Transfer_Model1.classifier = nn.Linear(Transfer_Model1.config.hidden_size, num_labels)\n","print(type(Transfer_Model1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZOMpptvV7gI4","executionInfo":{"status":"ok","timestamp":1673195675509,"user_tz":-60,"elapsed":13,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"869f1da8-e2af-41f5-e511-49664e9e77b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'transformers.models.bert.modeling_bert.BertModel'>\n"]}]},{"cell_type":"code","source":["Transfer_Model1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPE7hY3zBLsZ","executionInfo":{"status":"ok","timestamp":1673195675510,"user_tz":-60,"elapsed":10,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"048e8b78-69fc-4b2c-8421-9fcd4f1cf94c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n","  (classifier): Linear(in_features=768, out_features=37, bias=True)\n",")"]},"metadata":{},"execution_count":240}]},{"cell_type":"markdown","source":["Idea 2:"],"metadata":{"id":"X5FkrcttC02b"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForTokenClassification\n","from transformers import pipeline\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n","Transfer_Model2 = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n","\n","nlp = pipeline(\"ner\", model=Transfer_Model2, tokenizer=tokenizer)"],"metadata":{"id":"R-kO2lkAuvzY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Transfer_Model2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VedMs0U9GWn_","executionInfo":{"status":"ok","timestamp":1673195677166,"user_tz":-60,"elapsed":28,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"f1f73444-b76d-495b-d74c-7ff1c3ac5824"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",")"]},"metadata":{},"execution_count":242}]},{"cell_type":"markdown","source":["## Training and Evaluation of the Models"],"metadata":{"id":"A36CYJy2oFI3"}},{"cell_type":"markdown","source":["### RNN"],"metadata":{"id":"GJ8leSHeoQ-f"}},{"cell_type":"code","source":["BATCH_SIZE = 256\n","\n","# Initizalitaion of the Model\n","model = MyNERModel(dropout=0.3, \n","                   hidden_dim=128,  #The hidden_dim parameter specifies the size of the hidden layer in the model.\n","                   classes_num=len(train_data.MAPPING_Y_NER_LABELS), \n","                   words_num=len(word2idx), \n","                   word_dim=WORD_DIM)\n","\n","# Get the Word embedding matrix, which was pretrained\n","model.word_embedding.weight.data = torch.from_numpy(word_embeddings).float()\n","model.word_embedding.weight.requires_grad = False # We do NOT want to fine-tune the word embedding"],"metadata":{"id":"Zu3jlglzoTvp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T7HM6zRVWM59","executionInfo":{"status":"ok","timestamp":1673197605165,"user_tz":-60,"elapsed":4,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"b9abd933-0784-427e-d24a-9dc7be899e65"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MyNERModel(\n","  (word_embedding): Embedding(25505, 100)\n","  (word_rnn): RNN(100, 128, batch_first=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (activation): Tanh()\n","  (final_layer): Linear(in_features=128, out_features=37, bias=True)\n",")"]},"metadata":{},"execution_count":294}]},{"cell_type":"markdown","source":["The **model.word_embedding.weight.data** is a matrix of size words_num x word_dim where words_num is the number of unique words in the vocabulary and word_dim is the size of the word embedding vector. Each row of the matrix corresponds to the word embedding of a unique word in the vocabulary. By copying the word embedding matrix to the model's word_embedding layer, the model is able to use these pre-trained word embeddings to map the words in the dataset to their corresponding word embeddings.\n","\n","The **model.word_embedding.weight.requires_grad**  is set to False because the word embedding matrix should not be updated during the training process."],"metadata":{"id":"9AiJ8uL0yOnf"}},{"cell_type":"code","source":["# We can load our dataset using a dataloader which will take the data in batches, use a shuffle, and several other options\n","train_loader = DataLoader(\n","        train_data,\n","        batch_size=BATCH_SIZE, #256\n","        shuffle=True, # Pay attention that we can shuffle the samples for training --> Shuffle data means: Each epoch order of samples is not the same\n","        num_workers=0, # And specify how many working we want. \n","        #0 means that the data loading process will be done in the main thread and will not be parallelized. \n","        # The value of num_workers can be set to a higher number by using multiple worker threads to load the data, which can be useful for large datasets and to speed up the data loading process.\n","        drop_last=False) # Finally, it is possible to drop the last batch if its size is smaller than args.batch_size. In some applications, it is easier to ignore it instead of handling it.\n","\n","val_loader = DataLoader(\n","        val_data,\n","        batch_size=BATCH_SIZE,\n","        shuffle=False, # Pay attention here that the data is not shuffled.\n","        num_workers=0, \n","        drop_last=False)\n","\n","test_loader = DataLoader(\n","        test_data,\n","        batch_size=BATCH_SIZE,\n","        shuffle=False, # Pay attention here that the data is not shuffled.\n","        num_workers=0, \n","        drop_last=False)"],"metadata":{"id":"M3SLn-mYwjID"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ensure the train_loader has right type\n","print(type(train_loader))"],"metadata":{"id":"4O3ZiWSdEyXZ","executionInfo":{"status":"ok","timestamp":1673195677167,"user_tz":-60,"elapsed":25,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"99ace683-f84d-46ff-e8a5-377a8a0a9f2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.utils.data.dataloader.DataLoader'>\n"]}]},{"cell_type":"code","source":["# Example\n","print(train_loader.dataset.data[0])"],"metadata":{"id":"IMNl1keOBvaM","executionInfo":{"status":"ok","timestamp":1673195677168,"user_tz":-60,"elapsed":20,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b5bb68e6-fd12-46ae-89e7-cb4a2a6925f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'tokens': ['People', 'start', 'their', 'own', 'businesses', 'for', 'many', 'reasons', '.'], 'ners': [0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100], 'idx': 0, 'y_ners': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100], 'word_idx': [21794, 16020, 18194, 154, 23134, 2537, 8252, 2649, 4665, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"]}]},{"cell_type":"code","source":["# Check the lengths\n","print(train_loader.dataset.data[0][\"ners\"])\n","print(len(train_loader.dataset.data[0][\"ners\"]))\n","print(train_loader.dataset.data[0][\"y_ners\"])\n","print(len(train_loader.dataset.data[0][\"y_ners\"]))\n","print(train_loader.dataset.data[0][\"word_idx\"])\n","print(len(train_loader.dataset.data[0][\"word_idx\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EsobcuQ7ib2G","executionInfo":{"status":"ok","timestamp":1673195677168,"user_tz":-60,"elapsed":16,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"427c78d4-f5ed-419e-ef12-702ecc64a897"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n","210\n","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n","210\n","[21794, 16020, 18194, 154, 23134, 2537, 8252, 2649, 4665, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","210\n"]}]},{"cell_type":"code","source":["# Optimizier in order to update the weights of the model --> lr = learning rate and weight_decay\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-8) "],"metadata":{"id":"Sl6PztgOwiFg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- The Learning  Rate:\n","The learning rate determines the step size at which the optimizer makes updates to the model weights. sSmaller learning rate means that the optimizer takes smaller steps and may require more epochs to converge. A larger learning rate means that the optimizer takes larger steps and may require fewer epochs to converge.\n","\n","\n","- The Weight Decay:\n","Controls the amount of regularization applied to the model weights"],"metadata":{"id":"8o8IrYT7yM6w"}},{"cell_type":"code","source":["# Loss function\n","criterion = nn.CrossEntropyLoss(reduction='mean', ignore_index=-100)"],"metadata":{"id":"_pP96y2Ux7WJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The CrossEntropyLoss is calculated asthe negative log likelihood of the true labels given the predicted probabilities. "],"metadata":{"id":"bnh8r5ld_itO"}},{"cell_type":"code","source":["# Move the model to the device (CPU or GPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)"],"metadata":{"id":"YW3SWJ8xx6xG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The purpose of the loop is to train the model on the training data, evaluate its performance on the validation data, and test its performance on the test data.\n","\n","The training loop iterates over a range of epochs (250 in this case). During each epoch, the model is set to training mode, and the model's parameters are updated based on the training data using an optimizer and a loss function, which are defined above. The training loss is computed and stored for each batch of data. \n","\n","After training, the model is set to evaluation mode and the performance on the validation and test data is evaluated by computing the loss and F1 score for each batch of data. The loop keeps track of the best epoch based on the validation performance, and stores the test performance for the best epoch."],"metadata":{"id":"jdPwd1qcxlRp"}},{"cell_type":"code","source":["# Initial Setup to start the Training Loop\n","\n","best_epoch = 0\n","best_val_so_far = 0\n","test_perf = 0\n","\n","\n","# TRAINING LOOP\n","for epoch in range(250):\n","  print('------------------------------------------------------------------------')\n","  print('Epoch: {}'.format(epoch))\n","\n","  # TRAIN\n","  # We set the model in train mode. It will store information to compute the gradients\n","  model.train()\n","\n","  train_losses = []\n","  for batch in tqdm.tqdm(enumerate(train_loader), desc='Training'):\n","    # move them to GPU\n","    #print(batch[1]['word_idx'])\n","    batch[1]['word_idx'] = batch[1]['word_idx'].to(device)\n","    #print(batch[1]['ners'])\n","    batch[1]['ners'] = batch[1]['ners'].to(device)\n","\n","    # Compute the model output and the loss\n","    y_logits = model(batch[1]) #BxLxC (17)\n","    # We have to \"flatten\" the predictions because CE only handle tensors like BxC and B\n","    loss = criterion(y_logits.view(-1, len(train_data.MAPPING_Y_NER_LABELS)), batch[1]['ners'].view(-1))\n","\n","    # Update model parameters\n","    optimizer.zero_grad() # This is very important! By default, gradients are cumulated in tensors.\n","    loss.backward() # Now that gradients have been empties, we compute the new ones using the loss.\n","    optimizer.step() # We do gradient update with our optimization function (i.e., the weights of the model are updated).\n","  \n","    train_losses.append(loss.item())\n","  \n","  \n","  # VAL + TEST\n","  val_test_losses = {'val': [], 'test': []}\n","  val_test_f1 = {'val': [], 'test': []}\n","  \n","  # Unlike before, we set the model in eval mode to compute correctly dropout, batchnorm etc\n","  model.eval()\n","\n","  # We do not store information relative to gradients as we do not update the model.\n","  # That's the reason why inference requires less memory and is faster.\n","  with torch.no_grad():\n","    for split_data, data in [('val', val_loader), ('test', test_loader)]:\n","      # Pay attention how the data loading become easiers!\n","      for batch in tqdm.tqdm(enumerate(data), desc=split_data.capitalize()):\n","\n","        # move them to GPU\n","        batch[1]['word_idx'] = batch[1]['word_idx'].to(device)\n","        batch[1]['ners'] = batch[1]['ners'].to(device)\n","\n","\n","        # Compute the model output and the loss\n","        y_logits = model(batch[1]) #BxLxC (17)\n","        # We have to \"flatten\" the predictions because CE only handle tensors like BxC and B\n","        loss = criterion(y_logits.view(-1, len(train_data.MAPPING_Y_NER_LABELS)), batch[1]['ners'].view(-1))\n","\n","        val_test_losses[split_data].append(loss.item())\n","\n","        # Compute the macro f1 to evaluate our model\n","        y_probs = F.softmax(y_logits, dim=-1)\n","        y_pred = torch.argmax(y_logits, dim=-1)\n","\n","        f1 = compute_f1(y_pred.view(-1).cpu().numpy(), batch[1]['ners'].view(-1).cpu().numpy())\n","        val_test_f1[split_data].append(f1)\n","  \n","  # Monitoring\n","  print('Train loss: {:.4f}'.format(np.mean(train_losses)))\n","  print('Val   loss: {:.4f}'.format(np.mean(val_test_losses['val'])))\n","  print('Test  loss: {:.4f}'.format(np.mean(val_test_losses['test'])))\n","  print()\n","\n","  val_f1 = np.mean(val_test_f1['val'])\n","  test_f1 = np.mean(val_test_f1['test'])\n","  print('Val   Macro F1: {:.4f}'.format(val_f1))\n","  print('Test  Macro F1: {:.4f}'.format(test_f1))\n","  print()\n","\n","  if best_val_so_far < val_f1:\n","    best_val_so_far = val_f1\n","    test_perf = test_f1\n","    best_epoch = epoch\n","  \n","  print('Best Epoch: {}, best val macro F1: {:.4f}, test macro F1: {:.4f}'.format(best_epoch, best_val_so_far, test_perf))\n","  print()\n","  print()"],"metadata":{"id":"b7iVAL5pwyTA","executionInfo":{"status":"ok","timestamp":1673196275774,"user_tz":-60,"elapsed":598617,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fcd26de5-0077-4e77-d7d4-90eeb8b69ad0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------\n","Epoch: 0\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:01, 58.20it/s]\n","Val: 34it [00:00, 42.34it/s]\n","Test: 33it [00:00, 45.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 1.2844\n","Val   loss: 0.6927\n","Test  loss: 0.7098\n","\n","Val   Macro F1: 0.0049\n","Test  Macro F1: 0.0052\n","\n","Best Epoch: 0, best val macro F1: 0.0049, test macro F1: 0.0052\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 1\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.10it/s]\n","Val: 34it [00:00, 46.03it/s]\n","Test: 33it [00:00, 45.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.7967\n","Val   loss: 0.6064\n","Test  loss: 0.6228\n","\n","Val   Macro F1: 0.0060\n","Test  Macro F1: 0.0065\n","\n","Best Epoch: 1, best val macro F1: 0.0060, test macro F1: 0.0065\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 2\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.67it/s]\n","Val: 34it [00:00, 45.52it/s]\n","Test: 33it [00:00, 45.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.6872\n","Val   loss: 0.5439\n","Test  loss: 0.5559\n","\n","Val   Macro F1: 0.0226\n","Test  Macro F1: 0.0264\n","\n","Best Epoch: 2, best val macro F1: 0.0226, test macro F1: 0.0264\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 3\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.07it/s]\n","Val: 34it [00:00, 44.93it/s]\n","Test: 33it [00:00, 45.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.6120\n","Val   loss: 0.5072\n","Test  loss: 0.5173\n","\n","Val   Macro F1: 0.0500\n","Test  Macro F1: 0.0582\n","\n","Best Epoch: 3, best val macro F1: 0.0500, test macro F1: 0.0582\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 4\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 66.58it/s]\n","Val: 34it [00:00, 43.51it/s]\n","Test: 33it [00:00, 44.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.5679\n","Val   loss: 0.4860\n","Test  loss: 0.4946\n","\n","Val   Macro F1: 0.0693\n","Test  Macro F1: 0.0786\n","\n","Best Epoch: 4, best val macro F1: 0.0693, test macro F1: 0.0786\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 5\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 64.91it/s]\n","Val: 34it [00:00, 42.35it/s]\n","Test: 33it [00:00, 44.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.5405\n","Val   loss: 0.4744\n","Test  loss: 0.4821\n","\n","Val   Macro F1: 0.0810\n","Test  Macro F1: 0.0880\n","\n","Best Epoch: 5, best val macro F1: 0.0810, test macro F1: 0.0880\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 6\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.64it/s]\n","Val: 34it [00:00, 44.08it/s]\n","Test: 33it [00:00, 44.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.5208\n","Val   loss: 0.4715\n","Test  loss: 0.4800\n","\n","Val   Macro F1: 0.0837\n","Test  Macro F1: 0.0921\n","\n","Best Epoch: 6, best val macro F1: 0.0837, test macro F1: 0.0921\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 7\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.69it/s]\n","Val: 34it [00:00, 44.48it/s]\n","Test: 33it [00:00, 44.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.5054\n","Val   loss: 0.4652\n","Test  loss: 0.4721\n","\n","Val   Macro F1: 0.0906\n","Test  Macro F1: 0.1010\n","\n","Best Epoch: 7, best val macro F1: 0.0906, test macro F1: 0.1010\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 8\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.11it/s]\n","Val: 34it [00:00, 44.84it/s]\n","Test: 33it [00:00, 45.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4943\n","Val   loss: 0.4579\n","Test  loss: 0.4654\n","\n","Val   Macro F1: 0.0937\n","Test  Macro F1: 0.1055\n","\n","Best Epoch: 8, best val macro F1: 0.0937, test macro F1: 0.1055\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 9\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.14it/s]\n","Val: 34it [00:00, 45.30it/s]\n","Test: 33it [00:00, 45.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4834\n","Val   loss: 0.4665\n","Test  loss: 0.4730\n","\n","Val   Macro F1: 0.0992\n","Test  Macro F1: 0.1097\n","\n","Best Epoch: 9, best val macro F1: 0.0992, test macro F1: 0.1097\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 10\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.93it/s]\n","Val: 34it [00:00, 45.33it/s]\n","Test: 33it [00:00, 44.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4758\n","Val   loss: 0.4561\n","Test  loss: 0.4632\n","\n","Val   Macro F1: 0.1046\n","Test  Macro F1: 0.1145\n","\n","Best Epoch: 10, best val macro F1: 0.1046, test macro F1: 0.1145\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 11\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.64it/s]\n","Val: 34it [00:00, 45.07it/s]\n","Test: 33it [00:00, 45.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4678\n","Val   loss: 0.4550\n","Test  loss: 0.4612\n","\n","Val   Macro F1: 0.1159\n","Test  Macro F1: 0.1287\n","\n","Best Epoch: 11, best val macro F1: 0.1159, test macro F1: 0.1287\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 12\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.96it/s]\n","Val: 34it [00:00, 45.16it/s]\n","Test: 33it [00:00, 45.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4608\n","Val   loss: 0.4491\n","Test  loss: 0.4573\n","\n","Val   Macro F1: 0.1199\n","Test  Macro F1: 0.1341\n","\n","Best Epoch: 12, best val macro F1: 0.1199, test macro F1: 0.1341\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 13\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.15it/s]\n","Val: 34it [00:00, 45.11it/s]\n","Test: 33it [00:00, 45.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4549\n","Val   loss: 0.4488\n","Test  loss: 0.4556\n","\n","Val   Macro F1: 0.1349\n","Test  Macro F1: 0.1472\n","\n","Best Epoch: 13, best val macro F1: 0.1349, test macro F1: 0.1472\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 14\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.72it/s]\n","Val: 34it [00:00, 44.62it/s]\n","Test: 33it [00:00, 44.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4504\n","Val   loss: 0.4429\n","Test  loss: 0.4508\n","\n","Val   Macro F1: 0.1454\n","Test  Macro F1: 0.1566\n","\n","Best Epoch: 14, best val macro F1: 0.1454, test macro F1: 0.1566\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 15\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.63it/s]\n","Val: 34it [00:00, 44.99it/s]\n","Test: 33it [00:00, 44.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4447\n","Val   loss: 0.4412\n","Test  loss: 0.4485\n","\n","Val   Macro F1: 0.1476\n","Test  Macro F1: 0.1628\n","\n","Best Epoch: 15, best val macro F1: 0.1476, test macro F1: 0.1628\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 16\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.91it/s]\n","Val: 34it [00:00, 44.93it/s]\n","Test: 33it [00:00, 44.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4412\n","Val   loss: 0.4447\n","Test  loss: 0.4512\n","\n","Val   Macro F1: 0.1491\n","Test  Macro F1: 0.1610\n","\n","Best Epoch: 16, best val macro F1: 0.1491, test macro F1: 0.1610\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 17\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.18it/s]\n","Val: 34it [00:00, 45.03it/s]\n","Test: 33it [00:00, 45.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4379\n","Val   loss: 0.4579\n","Test  loss: 0.4627\n","\n","Val   Macro F1: 0.1529\n","Test  Macro F1: 0.1697\n","\n","Best Epoch: 17, best val macro F1: 0.1529, test macro F1: 0.1697\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 18\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.00it/s]\n","Val: 34it [00:00, 45.26it/s]\n","Test: 33it [00:00, 45.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4339\n","Val   loss: 0.4370\n","Test  loss: 0.4447\n","\n","Val   Macro F1: 0.1604\n","Test  Macro F1: 0.1718\n","\n","Best Epoch: 18, best val macro F1: 0.1604, test macro F1: 0.1718\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 19\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.96it/s]\n","Val: 34it [00:00, 45.34it/s]\n","Test: 33it [00:00, 45.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4310\n","Val   loss: 0.4321\n","Test  loss: 0.4396\n","\n","Val   Macro F1: 0.1683\n","Test  Macro F1: 0.1852\n","\n","Best Epoch: 19, best val macro F1: 0.1683, test macro F1: 0.1852\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 20\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.14it/s]\n","Val: 34it [00:00, 45.15it/s]\n","Test: 33it [00:00, 45.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4279\n","Val   loss: 0.4306\n","Test  loss: 0.4382\n","\n","Val   Macro F1: 0.1727\n","Test  Macro F1: 0.1889\n","\n","Best Epoch: 20, best val macro F1: 0.1727, test macro F1: 0.1889\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 21\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.35it/s]\n","Val: 34it [00:00, 44.97it/s]\n","Test: 33it [00:00, 45.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4275\n","Val   loss: 0.4272\n","Test  loss: 0.4359\n","\n","Val   Macro F1: 0.1751\n","Test  Macro F1: 0.1888\n","\n","Best Epoch: 21, best val macro F1: 0.1751, test macro F1: 0.1888\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 22\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.31it/s]\n","Val: 34it [00:00, 44.30it/s]\n","Test: 33it [00:00, 44.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4240\n","Val   loss: 0.4216\n","Test  loss: 0.4306\n","\n","Val   Macro F1: 0.1807\n","Test  Macro F1: 0.1964\n","\n","Best Epoch: 22, best val macro F1: 0.1807, test macro F1: 0.1964\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 23\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 66.95it/s]\n","Val: 34it [00:00, 43.26it/s]\n","Test: 33it [00:00, 41.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4200\n","Val   loss: 0.4439\n","Test  loss: 0.4511\n","\n","Val   Macro F1: 0.1783\n","Test  Macro F1: 0.1886\n","\n","Best Epoch: 22, best val macro F1: 0.1807, test macro F1: 0.1964\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 24\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.37it/s]\n","Val: 34it [00:00, 41.89it/s]\n","Test: 33it [00:00, 44.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4196\n","Val   loss: 0.4349\n","Test  loss: 0.4437\n","\n","Val   Macro F1: 0.1814\n","Test  Macro F1: 0.1931\n","\n","Best Epoch: 24, best val macro F1: 0.1814, test macro F1: 0.1931\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 25\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.20it/s]\n","Val: 34it [00:01, 25.39it/s]\n","Test: 33it [00:00, 45.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4164\n","Val   loss: 0.4291\n","Test  loss: 0.4369\n","\n","Val   Macro F1: 0.1899\n","Test  Macro F1: 0.2027\n","\n","Best Epoch: 25, best val macro F1: 0.1899, test macro F1: 0.2027\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 26\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.93it/s]\n","Val: 34it [00:00, 45.35it/s]\n","Test: 33it [00:00, 45.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4160\n","Val   loss: 0.4236\n","Test  loss: 0.4325\n","\n","Val   Macro F1: 0.1816\n","Test  Macro F1: 0.1986\n","\n","Best Epoch: 25, best val macro F1: 0.1899, test macro F1: 0.2027\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 27\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.98it/s]\n","Val: 34it [00:00, 44.60it/s]\n","Test: 33it [00:00, 44.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4120\n","Val   loss: 0.4208\n","Test  loss: 0.4292\n","\n","Val   Macro F1: 0.1874\n","Test  Macro F1: 0.2070\n","\n","Best Epoch: 25, best val macro F1: 0.1899, test macro F1: 0.2027\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 28\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.57it/s]\n","Val: 34it [00:00, 44.19it/s]\n","Test: 33it [00:00, 44.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4120\n","Val   loss: 0.4251\n","Test  loss: 0.4322\n","\n","Val   Macro F1: 0.1955\n","Test  Macro F1: 0.2068\n","\n","Best Epoch: 28, best val macro F1: 0.1955, test macro F1: 0.2068\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 29\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.90it/s]\n","Val: 34it [00:00, 44.25it/s]\n","Test: 33it [00:00, 44.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4102\n","Val   loss: 0.4399\n","Test  loss: 0.4460\n","\n","Val   Macro F1: 0.1867\n","Test  Macro F1: 0.2022\n","\n","Best Epoch: 28, best val macro F1: 0.1955, test macro F1: 0.2068\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 30\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.21it/s]\n","Val: 34it [00:00, 44.55it/s]\n","Test: 33it [00:00, 44.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4076\n","Val   loss: 0.4162\n","Test  loss: 0.4234\n","\n","Val   Macro F1: 0.1957\n","Test  Macro F1: 0.2105\n","\n","Best Epoch: 30, best val macro F1: 0.1957, test macro F1: 0.2105\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 31\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.12it/s]\n","Val: 34it [00:00, 44.28it/s]\n","Test: 33it [00:00, 43.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4067\n","Val   loss: 0.4129\n","Test  loss: 0.4205\n","\n","Val   Macro F1: 0.1957\n","Test  Macro F1: 0.2141\n","\n","Best Epoch: 31, best val macro F1: 0.1957, test macro F1: 0.2141\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 32\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.08it/s]\n","Val: 34it [00:00, 44.35it/s]\n","Test: 33it [00:00, 44.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4043\n","Val   loss: 0.4217\n","Test  loss: 0.4296\n","\n","Val   Macro F1: 0.1983\n","Test  Macro F1: 0.2117\n","\n","Best Epoch: 32, best val macro F1: 0.1983, test macro F1: 0.2117\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 33\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 66.97it/s]\n","Val: 34it [00:00, 45.07it/s]\n","Test: 33it [00:00, 45.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4026\n","Val   loss: 0.4240\n","Test  loss: 0.4318\n","\n","Val   Macro F1: 0.1946\n","Test  Macro F1: 0.2098\n","\n","Best Epoch: 32, best val macro F1: 0.1983, test macro F1: 0.2117\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 34\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.43it/s]\n","Val: 34it [00:00, 45.23it/s]\n","Test: 33it [00:00, 44.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4027\n","Val   loss: 0.4192\n","Test  loss: 0.4271\n","\n","Val   Macro F1: 0.1964\n","Test  Macro F1: 0.2156\n","\n","Best Epoch: 32, best val macro F1: 0.1983, test macro F1: 0.2117\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 35\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.10it/s]\n","Val: 34it [00:00, 44.63it/s]\n","Test: 33it [00:00, 44.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.4005\n","Val   loss: 0.4369\n","Test  loss: 0.4442\n","\n","Val   Macro F1: 0.1957\n","Test  Macro F1: 0.2088\n","\n","Best Epoch: 32, best val macro F1: 0.1983, test macro F1: 0.2117\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 36\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.66it/s]\n","Val: 34it [00:00, 44.75it/s]\n","Test: 33it [00:00, 45.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3987\n","Val   loss: 0.4231\n","Test  loss: 0.4300\n","\n","Val   Macro F1: 0.2028\n","Test  Macro F1: 0.2196\n","\n","Best Epoch: 36, best val macro F1: 0.2028, test macro F1: 0.2196\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 37\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.57it/s]\n","Val: 34it [00:00, 44.71it/s]\n","Test: 33it [00:00, 44.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3972\n","Val   loss: 0.4225\n","Test  loss: 0.4298\n","\n","Val   Macro F1: 0.1984\n","Test  Macro F1: 0.2153\n","\n","Best Epoch: 36, best val macro F1: 0.2028, test macro F1: 0.2196\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 38\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.37it/s]\n","Val: 34it [00:00, 43.77it/s]\n","Test: 33it [00:00, 44.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3977\n","Val   loss: 0.4114\n","Test  loss: 0.4193\n","\n","Val   Macro F1: 0.2016\n","Test  Macro F1: 0.2167\n","\n","Best Epoch: 36, best val macro F1: 0.2028, test macro F1: 0.2196\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 39\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.03it/s]\n","Val: 34it [00:00, 44.49it/s]\n","Test: 33it [00:00, 44.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3957\n","Val   loss: 0.4239\n","Test  loss: 0.4310\n","\n","Val   Macro F1: 0.2020\n","Test  Macro F1: 0.2198\n","\n","Best Epoch: 36, best val macro F1: 0.2028, test macro F1: 0.2196\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 40\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.32it/s]\n","Val: 34it [00:00, 45.01it/s]\n","Test: 33it [00:00, 44.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3943\n","Val   loss: 0.4225\n","Test  loss: 0.4303\n","\n","Val   Macro F1: 0.2048\n","Test  Macro F1: 0.2191\n","\n","Best Epoch: 40, best val macro F1: 0.2048, test macro F1: 0.2191\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 41\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.06it/s]\n","Val: 34it [00:00, 45.10it/s]\n","Test: 33it [00:00, 45.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3937\n","Val   loss: 0.4188\n","Test  loss: 0.4269\n","\n","Val   Macro F1: 0.2049\n","Test  Macro F1: 0.2224\n","\n","Best Epoch: 41, best val macro F1: 0.2049, test macro F1: 0.2224\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 42\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.83it/s]\n","Val: 34it [00:00, 45.21it/s]\n","Test: 33it [00:00, 45.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3938\n","Val   loss: 0.4339\n","Test  loss: 0.4389\n","\n","Val   Macro F1: 0.2067\n","Test  Macro F1: 0.2222\n","\n","Best Epoch: 42, best val macro F1: 0.2067, test macro F1: 0.2222\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 43\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.47it/s]\n","Val: 34it [00:00, 44.45it/s]\n","Test: 33it [00:00, 43.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3911\n","Val   loss: 0.4140\n","Test  loss: 0.4234\n","\n","Val   Macro F1: 0.1992\n","Test  Macro F1: 0.2206\n","\n","Best Epoch: 42, best val macro F1: 0.2067, test macro F1: 0.2222\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 44\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.37it/s]\n","Val: 34it [00:00, 43.95it/s]\n","Test: 33it [00:00, 43.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3914\n","Val   loss: 0.4122\n","Test  loss: 0.4216\n","\n","Val   Macro F1: 0.2009\n","Test  Macro F1: 0.2201\n","\n","Best Epoch: 42, best val macro F1: 0.2067, test macro F1: 0.2222\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 45\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.14it/s]\n","Val: 34it [00:00, 35.80it/s]\n","Test: 33it [00:00, 42.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3896\n","Val   loss: 0.4143\n","Test  loss: 0.4214\n","\n","Val   Macro F1: 0.2089\n","Test  Macro F1: 0.2261\n","\n","Best Epoch: 45, best val macro F1: 0.2089, test macro F1: 0.2261\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 46\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.01it/s]\n","Val: 34it [00:00, 43.59it/s]\n","Test: 33it [00:00, 43.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3888\n","Val   loss: 0.4058\n","Test  loss: 0.4143\n","\n","Val   Macro F1: 0.2098\n","Test  Macro F1: 0.2265\n","\n","Best Epoch: 46, best val macro F1: 0.2098, test macro F1: 0.2265\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 47\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.35it/s]\n","Val: 34it [00:00, 43.70it/s]\n","Test: 33it [00:00, 44.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3894\n","Val   loss: 0.4173\n","Test  loss: 0.4267\n","\n","Val   Macro F1: 0.2088\n","Test  Macro F1: 0.2222\n","\n","Best Epoch: 46, best val macro F1: 0.2098, test macro F1: 0.2265\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 48\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.67it/s]\n","Val: 34it [00:00, 43.04it/s]\n","Test: 33it [00:00, 44.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3863\n","Val   loss: 0.4141\n","Test  loss: 0.4230\n","\n","Val   Macro F1: 0.2094\n","Test  Macro F1: 0.2255\n","\n","Best Epoch: 46, best val macro F1: 0.2098, test macro F1: 0.2265\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 49\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.75it/s]\n","Val: 34it [00:00, 44.95it/s]\n","Test: 33it [00:00, 45.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3852\n","Val   loss: 0.4187\n","Test  loss: 0.4262\n","\n","Val   Macro F1: 0.2081\n","Test  Macro F1: 0.2237\n","\n","Best Epoch: 46, best val macro F1: 0.2098, test macro F1: 0.2265\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 50\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.33it/s]\n","Val: 34it [00:00, 45.07it/s]\n","Test: 33it [00:00, 45.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3858\n","Val   loss: 0.4252\n","Test  loss: 0.4317\n","\n","Val   Macro F1: 0.2089\n","Test  Macro F1: 0.2231\n","\n","Best Epoch: 46, best val macro F1: 0.2098, test macro F1: 0.2265\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 51\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.91it/s]\n","Val: 34it [00:00, 45.00it/s]\n","Test: 33it [00:00, 44.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3847\n","Val   loss: 0.4153\n","Test  loss: 0.4226\n","\n","Val   Macro F1: 0.2081\n","Test  Macro F1: 0.2250\n","\n","Best Epoch: 46, best val macro F1: 0.2098, test macro F1: 0.2265\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 52\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.32it/s]\n","Val: 34it [00:00, 44.73it/s]\n","Test: 33it [00:00, 43.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3843\n","Val   loss: 0.4196\n","Test  loss: 0.4282\n","\n","Val   Macro F1: 0.2081\n","Test  Macro F1: 0.2173\n","\n","Best Epoch: 46, best val macro F1: 0.2098, test macro F1: 0.2265\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 53\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.49it/s]\n","Val: 34it [00:00, 43.99it/s]\n","Test: 33it [00:00, 42.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3814\n","Val   loss: 0.4039\n","Test  loss: 0.4136\n","\n","Val   Macro F1: 0.2128\n","Test  Macro F1: 0.2273\n","\n","Best Epoch: 53, best val macro F1: 0.2128, test macro F1: 0.2273\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 54\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.86it/s]\n","Val: 34it [00:00, 44.64it/s]\n","Test: 33it [00:00, 44.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3819\n","Val   loss: 0.4142\n","Test  loss: 0.4213\n","\n","Val   Macro F1: 0.2118\n","Test  Macro F1: 0.2265\n","\n","Best Epoch: 53, best val macro F1: 0.2128, test macro F1: 0.2273\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 55\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 66.08it/s]\n","Val: 34it [00:00, 42.80it/s]\n","Test: 33it [00:00, 44.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3805\n","Val   loss: 0.4194\n","Test  loss: 0.4269\n","\n","Val   Macro F1: 0.2126\n","Test  Macro F1: 0.2285\n","\n","Best Epoch: 53, best val macro F1: 0.2128, test macro F1: 0.2273\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 56\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.26it/s]\n","Val: 34it [00:00, 44.13it/s]\n","Test: 33it [00:00, 43.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3816\n","Val   loss: 0.4059\n","Test  loss: 0.4137\n","\n","Val   Macro F1: 0.2183\n","Test  Macro F1: 0.2352\n","\n","Best Epoch: 56, best val macro F1: 0.2183, test macro F1: 0.2352\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 57\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.13it/s]\n","Val: 34it [00:00, 44.44it/s]\n","Test: 33it [00:00, 44.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3794\n","Val   loss: 0.4228\n","Test  loss: 0.4293\n","\n","Val   Macro F1: 0.2130\n","Test  Macro F1: 0.2272\n","\n","Best Epoch: 56, best val macro F1: 0.2183, test macro F1: 0.2352\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 58\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.89it/s]\n","Val: 34it [00:00, 44.44it/s]\n","Test: 33it [00:00, 44.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3797\n","Val   loss: 0.4282\n","Test  loss: 0.4334\n","\n","Val   Macro F1: 0.2131\n","Test  Macro F1: 0.2314\n","\n","Best Epoch: 56, best val macro F1: 0.2183, test macro F1: 0.2352\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 59\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.60it/s]\n","Val: 34it [00:00, 43.74it/s]\n","Test: 33it [00:00, 44.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3783\n","Val   loss: 0.4031\n","Test  loss: 0.4112\n","\n","Val   Macro F1: 0.2184\n","Test  Macro F1: 0.2326\n","\n","Best Epoch: 59, best val macro F1: 0.2184, test macro F1: 0.2326\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 60\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.10it/s]\n","Val: 34it [00:00, 44.79it/s]\n","Test: 33it [00:00, 43.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3789\n","Val   loss: 0.4130\n","Test  loss: 0.4205\n","\n","Val   Macro F1: 0.2197\n","Test  Macro F1: 0.2340\n","\n","Best Epoch: 60, best val macro F1: 0.2197, test macro F1: 0.2340\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 61\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.50it/s]\n","Val: 34it [00:00, 44.84it/s]\n","Test: 33it [00:00, 43.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3759\n","Val   loss: 0.4105\n","Test  loss: 0.4183\n","\n","Val   Macro F1: 0.2187\n","Test  Macro F1: 0.2332\n","\n","Best Epoch: 60, best val macro F1: 0.2197, test macro F1: 0.2340\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 62\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.12it/s]\n","Val: 34it [00:00, 44.14it/s]\n","Test: 33it [00:00, 44.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3766\n","Val   loss: 0.4046\n","Test  loss: 0.4135\n","\n","Val   Macro F1: 0.2181\n","Test  Macro F1: 0.2339\n","\n","Best Epoch: 60, best val macro F1: 0.2197, test macro F1: 0.2340\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 63\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.81it/s]\n","Val: 34it [00:00, 44.55it/s]\n","Test: 33it [00:00, 44.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3765\n","Val   loss: 0.4128\n","Test  loss: 0.4205\n","\n","Val   Macro F1: 0.2177\n","Test  Macro F1: 0.2337\n","\n","Best Epoch: 60, best val macro F1: 0.2197, test macro F1: 0.2340\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 64\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.38it/s]\n","Val: 34it [00:00, 44.73it/s]\n","Test: 33it [00:00, 45.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3753\n","Val   loss: 0.4246\n","Test  loss: 0.4306\n","\n","Val   Macro F1: 0.2167\n","Test  Macro F1: 0.2345\n","\n","Best Epoch: 60, best val macro F1: 0.2197, test macro F1: 0.2340\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 65\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.80it/s]\n","Val: 34it [00:00, 44.44it/s]\n","Test: 33it [00:00, 44.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3735\n","Val   loss: 0.4038\n","Test  loss: 0.4116\n","\n","Val   Macro F1: 0.2186\n","Test  Macro F1: 0.2364\n","\n","Best Epoch: 60, best val macro F1: 0.2197, test macro F1: 0.2340\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 66\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.23it/s]\n","Val: 34it [00:00, 44.96it/s]\n","Test: 33it [00:00, 44.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3738\n","Val   loss: 0.4009\n","Test  loss: 0.4110\n","\n","Val   Macro F1: 0.2185\n","Test  Macro F1: 0.2314\n","\n","Best Epoch: 60, best val macro F1: 0.2197, test macro F1: 0.2340\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 67\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.27it/s]\n","Val: 34it [00:01, 25.65it/s]\n","Test: 33it [00:00, 44.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3733\n","Val   loss: 0.4026\n","Test  loss: 0.4124\n","\n","Val   Macro F1: 0.2208\n","Test  Macro F1: 0.2329\n","\n","Best Epoch: 67, best val macro F1: 0.2208, test macro F1: 0.2329\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 68\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.21it/s]\n","Val: 34it [00:00, 44.50it/s]\n","Test: 33it [00:00, 44.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3728\n","Val   loss: 0.4149\n","Test  loss: 0.4233\n","\n","Val   Macro F1: 0.2168\n","Test  Macro F1: 0.2306\n","\n","Best Epoch: 67, best val macro F1: 0.2208, test macro F1: 0.2329\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 69\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.65it/s]\n","Val: 34it [00:00, 44.35it/s]\n","Test: 33it [00:00, 44.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3736\n","Val   loss: 0.4079\n","Test  loss: 0.4160\n","\n","Val   Macro F1: 0.2216\n","Test  Macro F1: 0.2385\n","\n","Best Epoch: 69, best val macro F1: 0.2216, test macro F1: 0.2385\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 70\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.73it/s]\n","Val: 34it [00:00, 44.77it/s]\n","Test: 33it [00:00, 44.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3726\n","Val   loss: 0.4110\n","Test  loss: 0.4197\n","\n","Val   Macro F1: 0.2186\n","Test  Macro F1: 0.2382\n","\n","Best Epoch: 69, best val macro F1: 0.2216, test macro F1: 0.2385\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 71\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.79it/s]\n","Val: 34it [00:00, 41.96it/s]\n","Test: 33it [00:00, 44.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3723\n","Val   loss: 0.4123\n","Test  loss: 0.4192\n","\n","Val   Macro F1: 0.2253\n","Test  Macro F1: 0.2406\n","\n","Best Epoch: 71, best val macro F1: 0.2253, test macro F1: 0.2406\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 72\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.89it/s]\n","Val: 34it [00:00, 44.67it/s]\n","Test: 33it [00:00, 44.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3713\n","Val   loss: 0.4125\n","Test  loss: 0.4195\n","\n","Val   Macro F1: 0.2190\n","Test  Macro F1: 0.2344\n","\n","Best Epoch: 71, best val macro F1: 0.2253, test macro F1: 0.2406\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 73\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.95it/s]\n","Val: 34it [00:00, 45.35it/s]\n","Test: 33it [00:00, 44.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3706\n","Val   loss: 0.4141\n","Test  loss: 0.4204\n","\n","Val   Macro F1: 0.2187\n","Test  Macro F1: 0.2365\n","\n","Best Epoch: 71, best val macro F1: 0.2253, test macro F1: 0.2406\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 74\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.02it/s]\n","Val: 34it [00:00, 45.11it/s]\n","Test: 33it [00:00, 45.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3697\n","Val   loss: 0.4038\n","Test  loss: 0.4130\n","\n","Val   Macro F1: 0.2187\n","Test  Macro F1: 0.2374\n","\n","Best Epoch: 71, best val macro F1: 0.2253, test macro F1: 0.2406\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 75\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.88it/s]\n","Val: 34it [00:00, 44.88it/s]\n","Test: 33it [00:00, 45.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3686\n","Val   loss: 0.4132\n","Test  loss: 0.4192\n","\n","Val   Macro F1: 0.2265\n","Test  Macro F1: 0.2411\n","\n","Best Epoch: 75, best val macro F1: 0.2265, test macro F1: 0.2411\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 76\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.71it/s]\n","Val: 34it [00:00, 44.62it/s]\n","Test: 33it [00:00, 44.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3683\n","Val   loss: 0.4026\n","Test  loss: 0.4100\n","\n","Val   Macro F1: 0.2216\n","Test  Macro F1: 0.2391\n","\n","Best Epoch: 75, best val macro F1: 0.2265, test macro F1: 0.2411\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 77\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.86it/s]\n","Val: 34it [00:00, 45.10it/s]\n","Test: 33it [00:00, 45.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3677\n","Val   loss: 0.4041\n","Test  loss: 0.4128\n","\n","Val   Macro F1: 0.2246\n","Test  Macro F1: 0.2399\n","\n","Best Epoch: 75, best val macro F1: 0.2265, test macro F1: 0.2411\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 78\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.78it/s]\n","Val: 34it [00:00, 44.63it/s]\n","Test: 33it [00:00, 44.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3691\n","Val   loss: 0.4015\n","Test  loss: 0.4084\n","\n","Val   Macro F1: 0.2294\n","Test  Macro F1: 0.2449\n","\n","Best Epoch: 78, best val macro F1: 0.2294, test macro F1: 0.2449\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 79\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.95it/s]\n","Val: 34it [00:00, 44.83it/s]\n","Test: 33it [00:00, 45.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3685\n","Val   loss: 0.4198\n","Test  loss: 0.4248\n","\n","Val   Macro F1: 0.2227\n","Test  Macro F1: 0.2429\n","\n","Best Epoch: 78, best val macro F1: 0.2294, test macro F1: 0.2449\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 80\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.40it/s]\n","Val: 34it [00:00, 44.99it/s]\n","Test: 33it [00:00, 44.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3681\n","Val   loss: 0.4141\n","Test  loss: 0.4195\n","\n","Val   Macro F1: 0.2203\n","Test  Macro F1: 0.2369\n","\n","Best Epoch: 78, best val macro F1: 0.2294, test macro F1: 0.2449\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 81\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.29it/s]\n","Val: 34it [00:00, 45.06it/s]\n","Test: 33it [00:00, 44.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3671\n","Val   loss: 0.4202\n","Test  loss: 0.4259\n","\n","Val   Macro F1: 0.2223\n","Test  Macro F1: 0.2376\n","\n","Best Epoch: 78, best val macro F1: 0.2294, test macro F1: 0.2449\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 82\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.63it/s]\n","Val: 34it [00:00, 45.09it/s]\n","Test: 33it [00:00, 44.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3680\n","Val   loss: 0.4097\n","Test  loss: 0.4148\n","\n","Val   Macro F1: 0.2262\n","Test  Macro F1: 0.2437\n","\n","Best Epoch: 78, best val macro F1: 0.2294, test macro F1: 0.2449\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 83\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.82it/s]\n","Val: 34it [00:00, 44.41it/s]\n","Test: 33it [00:00, 44.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3667\n","Val   loss: 0.4031\n","Test  loss: 0.4114\n","\n","Val   Macro F1: 0.2268\n","Test  Macro F1: 0.2422\n","\n","Best Epoch: 78, best val macro F1: 0.2294, test macro F1: 0.2449\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 84\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.34it/s]\n","Val: 34it [00:00, 44.62it/s]\n","Test: 33it [00:00, 44.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3660\n","Val   loss: 0.4054\n","Test  loss: 0.4115\n","\n","Val   Macro F1: 0.2273\n","Test  Macro F1: 0.2432\n","\n","Best Epoch: 78, best val macro F1: 0.2294, test macro F1: 0.2449\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 85\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.93it/s]\n","Val: 34it [00:00, 44.31it/s]\n","Test: 33it [00:00, 44.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3649\n","Val   loss: 0.4172\n","Test  loss: 0.4222\n","\n","Val   Macro F1: 0.2273\n","Test  Macro F1: 0.2403\n","\n","Best Epoch: 78, best val macro F1: 0.2294, test macro F1: 0.2449\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 86\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.48it/s]\n","Val: 34it [00:00, 44.58it/s]\n","Test: 33it [00:00, 44.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3654\n","Val   loss: 0.4119\n","Test  loss: 0.4186\n","\n","Val   Macro F1: 0.2193\n","Test  Macro F1: 0.2376\n","\n","Best Epoch: 78, best val macro F1: 0.2294, test macro F1: 0.2449\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 87\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.96it/s]\n","Val: 34it [00:00, 44.39it/s]\n","Test: 33it [00:00, 45.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3653\n","Val   loss: 0.3975\n","Test  loss: 0.4043\n","\n","Val   Macro F1: 0.2308\n","Test  Macro F1: 0.2480\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 88\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.04it/s]\n","Val: 34it [00:00, 45.00it/s]\n","Test: 33it [00:00, 45.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3645\n","Val   loss: 0.4068\n","Test  loss: 0.4142\n","\n","Val   Macro F1: 0.2252\n","Test  Macro F1: 0.2439\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 89\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.97it/s]\n","Val: 34it [00:00, 44.98it/s]\n","Test: 33it [00:00, 45.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3628\n","Val   loss: 0.4174\n","Test  loss: 0.4227\n","\n","Val   Macro F1: 0.2184\n","Test  Macro F1: 0.2379\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 90\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.65it/s]\n","Val: 34it [00:00, 44.85it/s]\n","Test: 33it [00:00, 45.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3617\n","Val   loss: 0.4148\n","Test  loss: 0.4208\n","\n","Val   Macro F1: 0.2266\n","Test  Macro F1: 0.2441\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 91\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.99it/s]\n","Val: 34it [00:00, 45.11it/s]\n","Test: 33it [00:00, 45.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3621\n","Val   loss: 0.4136\n","Test  loss: 0.4199\n","\n","Val   Macro F1: 0.2203\n","Test  Macro F1: 0.2385\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 92\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.18it/s]\n","Val: 34it [00:00, 44.83it/s]\n","Test: 33it [00:00, 45.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3622\n","Val   loss: 0.4108\n","Test  loss: 0.4183\n","\n","Val   Macro F1: 0.2235\n","Test  Macro F1: 0.2412\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 93\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.20it/s]\n","Val: 34it [00:00, 44.90it/s]\n","Test: 33it [00:00, 44.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3641\n","Val   loss: 0.3952\n","Test  loss: 0.4041\n","\n","Val   Macro F1: 0.2237\n","Test  Macro F1: 0.2388\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 94\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.70it/s]\n","Val: 34it [00:00, 45.26it/s]\n","Test: 33it [00:00, 45.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3633\n","Val   loss: 0.4065\n","Test  loss: 0.4146\n","\n","Val   Macro F1: 0.2247\n","Test  Macro F1: 0.2392\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 95\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.13it/s]\n","Val: 34it [00:00, 45.05it/s]\n","Test: 33it [00:00, 44.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3611\n","Val   loss: 0.4101\n","Test  loss: 0.4156\n","\n","Val   Macro F1: 0.2259\n","Test  Macro F1: 0.2450\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 96\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.90it/s]\n","Val: 34it [00:00, 45.37it/s]\n","Test: 33it [00:00, 45.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3627\n","Val   loss: 0.4118\n","Test  loss: 0.4185\n","\n","Val   Macro F1: 0.2288\n","Test  Macro F1: 0.2440\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 97\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.61it/s]\n","Val: 34it [00:00, 44.99it/s]\n","Test: 33it [00:00, 45.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3611\n","Val   loss: 0.4043\n","Test  loss: 0.4107\n","\n","Val   Macro F1: 0.2269\n","Test  Macro F1: 0.2431\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 98\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.57it/s]\n","Val: 34it [00:00, 44.78it/s]\n","Test: 33it [00:00, 45.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3599\n","Val   loss: 0.4078\n","Test  loss: 0.4143\n","\n","Val   Macro F1: 0.2257\n","Test  Macro F1: 0.2387\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 99\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.85it/s]\n","Val: 34it [00:00, 44.88it/s]\n","Test: 33it [00:00, 44.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3603\n","Val   loss: 0.4173\n","Test  loss: 0.4243\n","\n","Val   Macro F1: 0.2233\n","Test  Macro F1: 0.2380\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 100\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.86it/s]\n","Val: 34it [00:00, 45.13it/s]\n","Test: 33it [00:00, 45.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3596\n","Val   loss: 0.4024\n","Test  loss: 0.4092\n","\n","Val   Macro F1: 0.2284\n","Test  Macro F1: 0.2472\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 101\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.55it/s]\n","Val: 34it [00:00, 44.74it/s]\n","Test: 33it [00:00, 44.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3608\n","Val   loss: 0.3927\n","Test  loss: 0.4023\n","\n","Val   Macro F1: 0.2256\n","Test  Macro F1: 0.2436\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 102\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.79it/s]\n","Val: 34it [00:00, 45.17it/s]\n","Test: 33it [00:00, 45.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3591\n","Val   loss: 0.3992\n","Test  loss: 0.4069\n","\n","Val   Macro F1: 0.2285\n","Test  Macro F1: 0.2451\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 103\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.93it/s]\n","Val: 34it [00:00, 44.72it/s]\n","Test: 33it [00:00, 44.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3581\n","Val   loss: 0.4078\n","Test  loss: 0.4164\n","\n","Val   Macro F1: 0.2193\n","Test  Macro F1: 0.2331\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 104\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.24it/s]\n","Val: 34it [00:00, 44.85it/s]\n","Test: 33it [00:00, 44.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3593\n","Val   loss: 0.4211\n","Test  loss: 0.4251\n","\n","Val   Macro F1: 0.2284\n","Test  Macro F1: 0.2463\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 105\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.85it/s]\n","Val: 34it [00:00, 45.29it/s]\n","Test: 33it [00:00, 45.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3575\n","Val   loss: 0.4103\n","Test  loss: 0.4170\n","\n","Val   Macro F1: 0.2248\n","Test  Macro F1: 0.2365\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 106\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.49it/s]\n","Val: 34it [00:00, 45.19it/s]\n","Test: 33it [00:00, 44.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3571\n","Val   loss: 0.4342\n","Test  loss: 0.4380\n","\n","Val   Macro F1: 0.2213\n","Test  Macro F1: 0.2401\n","\n","Best Epoch: 87, best val macro F1: 0.2308, test macro F1: 0.2480\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 107\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.70it/s]\n","Val: 34it [00:00, 44.68it/s]\n","Test: 33it [00:00, 45.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3578\n","Val   loss: 0.4145\n","Test  loss: 0.4201\n","\n","Val   Macro F1: 0.2310\n","Test  Macro F1: 0.2462\n","\n","Best Epoch: 107, best val macro F1: 0.2310, test macro F1: 0.2462\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 108\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.46it/s]\n","Val: 34it [00:00, 44.92it/s]\n","Test: 33it [00:00, 44.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3552\n","Val   loss: 0.4064\n","Test  loss: 0.4124\n","\n","Val   Macro F1: 0.2260\n","Test  Macro F1: 0.2424\n","\n","Best Epoch: 107, best val macro F1: 0.2310, test macro F1: 0.2462\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 109\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.64it/s]\n","Val: 34it [00:01, 25.59it/s]\n","Test: 33it [00:00, 44.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3543\n","Val   loss: 0.4129\n","Test  loss: 0.4186\n","\n","Val   Macro F1: 0.2238\n","Test  Macro F1: 0.2410\n","\n","Best Epoch: 107, best val macro F1: 0.2310, test macro F1: 0.2462\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 110\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.42it/s]\n","Val: 34it [00:00, 44.84it/s]\n","Test: 33it [00:00, 44.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3551\n","Val   loss: 0.3966\n","Test  loss: 0.4043\n","\n","Val   Macro F1: 0.2273\n","Test  Macro F1: 0.2446\n","\n","Best Epoch: 107, best val macro F1: 0.2310, test macro F1: 0.2462\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 111\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.91it/s]\n","Val: 34it [00:00, 45.03it/s]\n","Test: 33it [00:00, 44.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3558\n","Val   loss: 0.4025\n","Test  loss: 0.4087\n","\n","Val   Macro F1: 0.2330\n","Test  Macro F1: 0.2497\n","\n","Best Epoch: 111, best val macro F1: 0.2330, test macro F1: 0.2497\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 112\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.52it/s]\n","Val: 34it [00:00, 44.81it/s]\n","Test: 33it [00:00, 44.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3554\n","Val   loss: 0.3955\n","Test  loss: 0.4045\n","\n","Val   Macro F1: 0.2291\n","Test  Macro F1: 0.2412\n","\n","Best Epoch: 111, best val macro F1: 0.2330, test macro F1: 0.2497\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 113\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.98it/s]\n","Val: 34it [00:00, 44.88it/s]\n","Test: 33it [00:00, 44.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3558\n","Val   loss: 0.3888\n","Test  loss: 0.3967\n","\n","Val   Macro F1: 0.2343\n","Test  Macro F1: 0.2487\n","\n","Best Epoch: 113, best val macro F1: 0.2343, test macro F1: 0.2487\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 114\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.85it/s]\n","Val: 34it [00:00, 45.15it/s]\n","Test: 33it [00:00, 44.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3550\n","Val   loss: 0.4091\n","Test  loss: 0.4149\n","\n","Val   Macro F1: 0.2318\n","Test  Macro F1: 0.2449\n","\n","Best Epoch: 113, best val macro F1: 0.2343, test macro F1: 0.2487\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 115\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.17it/s]\n","Val: 34it [00:00, 44.77it/s]\n","Test: 33it [00:00, 43.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3544\n","Val   loss: 0.4037\n","Test  loss: 0.4086\n","\n","Val   Macro F1: 0.2332\n","Test  Macro F1: 0.2482\n","\n","Best Epoch: 113, best val macro F1: 0.2343, test macro F1: 0.2487\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 116\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.90it/s]\n","Val: 34it [00:00, 45.20it/s]\n","Test: 33it [00:00, 45.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3563\n","Val   loss: 0.4095\n","Test  loss: 0.4146\n","\n","Val   Macro F1: 0.2329\n","Test  Macro F1: 0.2461\n","\n","Best Epoch: 113, best val macro F1: 0.2343, test macro F1: 0.2487\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 117\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.52it/s]\n","Val: 34it [00:00, 45.08it/s]\n","Test: 33it [00:00, 45.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3546\n","Val   loss: 0.3994\n","Test  loss: 0.4064\n","\n","Val   Macro F1: 0.2286\n","Test  Macro F1: 0.2435\n","\n","Best Epoch: 113, best val macro F1: 0.2343, test macro F1: 0.2487\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 118\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.81it/s]\n","Val: 34it [00:00, 44.55it/s]\n","Test: 33it [00:00, 43.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3529\n","Val   loss: 0.4032\n","Test  loss: 0.4096\n","\n","Val   Macro F1: 0.2295\n","Test  Macro F1: 0.2448\n","\n","Best Epoch: 113, best val macro F1: 0.2343, test macro F1: 0.2487\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 119\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.14it/s]\n","Val: 34it [00:00, 44.17it/s]\n","Test: 33it [00:00, 44.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3524\n","Val   loss: 0.4153\n","Test  loss: 0.4209\n","\n","Val   Macro F1: 0.2236\n","Test  Macro F1: 0.2395\n","\n","Best Epoch: 113, best val macro F1: 0.2343, test macro F1: 0.2487\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 120\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 66.57it/s]\n","Val: 34it [00:00, 43.00it/s]\n","Test: 33it [00:00, 45.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3524\n","Val   loss: 0.4091\n","Test  loss: 0.4147\n","\n","Val   Macro F1: 0.2292\n","Test  Macro F1: 0.2447\n","\n","Best Epoch: 113, best val macro F1: 0.2343, test macro F1: 0.2487\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 121\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.21it/s]\n","Val: 34it [00:00, 45.05it/s]\n","Test: 33it [00:00, 45.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3526\n","Val   loss: 0.3992\n","Test  loss: 0.4072\n","\n","Val   Macro F1: 0.2330\n","Test  Macro F1: 0.2465\n","\n","Best Epoch: 113, best val macro F1: 0.2343, test macro F1: 0.2487\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 122\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.15it/s]\n","Val: 34it [00:00, 44.94it/s]\n","Test: 33it [00:00, 44.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3537\n","Val   loss: 0.4074\n","Test  loss: 0.4131\n","\n","Val   Macro F1: 0.2282\n","Test  Macro F1: 0.2489\n","\n","Best Epoch: 113, best val macro F1: 0.2343, test macro F1: 0.2487\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 123\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.77it/s]\n","Val: 34it [00:00, 44.71it/s]\n","Test: 33it [00:00, 44.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3525\n","Val   loss: 0.4129\n","Test  loss: 0.4181\n","\n","Val   Macro F1: 0.2293\n","Test  Macro F1: 0.2453\n","\n","Best Epoch: 113, best val macro F1: 0.2343, test macro F1: 0.2487\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 124\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.79it/s]\n","Val: 34it [00:00, 45.07it/s]\n","Test: 33it [00:00, 45.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3512\n","Val   loss: 0.4034\n","Test  loss: 0.4100\n","\n","Val   Macro F1: 0.2321\n","Test  Macro F1: 0.2446\n","\n","Best Epoch: 113, best val macro F1: 0.2343, test macro F1: 0.2487\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 125\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.64it/s]\n","Val: 34it [00:00, 44.89it/s]\n","Test: 33it [00:00, 44.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3510\n","Val   loss: 0.4045\n","Test  loss: 0.4097\n","\n","Val   Macro F1: 0.2324\n","Test  Macro F1: 0.2495\n","\n","Best Epoch: 113, best val macro F1: 0.2343, test macro F1: 0.2487\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 126\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.96it/s]\n","Val: 34it [00:00, 44.70it/s]\n","Test: 33it [00:00, 42.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3502\n","Val   loss: 0.3989\n","Test  loss: 0.4055\n","\n","Val   Macro F1: 0.2346\n","Test  Macro F1: 0.2496\n","\n","Best Epoch: 126, best val macro F1: 0.2346, test macro F1: 0.2496\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 127\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.46it/s]\n","Val: 34it [00:00, 43.96it/s]\n","Test: 33it [00:00, 43.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3491\n","Val   loss: 0.3996\n","Test  loss: 0.4071\n","\n","Val   Macro F1: 0.2337\n","Test  Macro F1: 0.2449\n","\n","Best Epoch: 126, best val macro F1: 0.2346, test macro F1: 0.2496\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 128\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 66.00it/s]\n","Val: 34it [00:00, 45.05it/s]\n","Test: 33it [00:00, 44.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3502\n","Val   loss: 0.3945\n","Test  loss: 0.4018\n","\n","Val   Macro F1: 0.2353\n","Test  Macro F1: 0.2466\n","\n","Best Epoch: 128, best val macro F1: 0.2353, test macro F1: 0.2466\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 129\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.02it/s]\n","Val: 34it [00:00, 45.25it/s]\n","Test: 33it [00:00, 44.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3512\n","Val   loss: 0.3920\n","Test  loss: 0.3981\n","\n","Val   Macro F1: 0.2320\n","Test  Macro F1: 0.2487\n","\n","Best Epoch: 128, best val macro F1: 0.2353, test macro F1: 0.2466\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 130\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.22it/s]\n","Val: 34it [00:00, 44.45it/s]\n","Test: 33it [00:00, 44.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3515\n","Val   loss: 0.3969\n","Test  loss: 0.4029\n","\n","Val   Macro F1: 0.2323\n","Test  Macro F1: 0.2495\n","\n","Best Epoch: 128, best val macro F1: 0.2353, test macro F1: 0.2466\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 131\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.00it/s]\n","Val: 34it [00:00, 44.80it/s]\n","Test: 33it [00:00, 44.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3478\n","Val   loss: 0.4086\n","Test  loss: 0.4145\n","\n","Val   Macro F1: 0.2331\n","Test  Macro F1: 0.2460\n","\n","Best Epoch: 128, best val macro F1: 0.2353, test macro F1: 0.2466\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 132\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.80it/s]\n","Val: 34it [00:00, 44.59it/s]\n","Test: 33it [00:00, 44.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3514\n","Val   loss: 0.4143\n","Test  loss: 0.4190\n","\n","Val   Macro F1: 0.2317\n","Test  Macro F1: 0.2484\n","\n","Best Epoch: 128, best val macro F1: 0.2353, test macro F1: 0.2466\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 133\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.03it/s]\n","Val: 34it [00:00, 45.21it/s]\n","Test: 33it [00:00, 44.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3505\n","Val   loss: 0.3886\n","Test  loss: 0.3962\n","\n","Val   Macro F1: 0.2323\n","Test  Macro F1: 0.2476\n","\n","Best Epoch: 128, best val macro F1: 0.2353, test macro F1: 0.2466\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 134\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.80it/s]\n","Val: 34it [00:00, 44.81it/s]\n","Test: 33it [00:00, 44.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3497\n","Val   loss: 0.4018\n","Test  loss: 0.4080\n","\n","Val   Macro F1: 0.2318\n","Test  Macro F1: 0.2476\n","\n","Best Epoch: 128, best val macro F1: 0.2353, test macro F1: 0.2466\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 135\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.62it/s]\n","Val: 34it [00:00, 44.95it/s]\n","Test: 33it [00:00, 44.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3474\n","Val   loss: 0.4001\n","Test  loss: 0.4067\n","\n","Val   Macro F1: 0.2316\n","Test  Macro F1: 0.2499\n","\n","Best Epoch: 128, best val macro F1: 0.2353, test macro F1: 0.2466\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 136\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.57it/s]\n","Val: 34it [00:00, 44.95it/s]\n","Test: 33it [00:00, 45.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3471\n","Val   loss: 0.3988\n","Test  loss: 0.4047\n","\n","Val   Macro F1: 0.2345\n","Test  Macro F1: 0.2490\n","\n","Best Epoch: 128, best val macro F1: 0.2353, test macro F1: 0.2466\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 137\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.28it/s]\n","Val: 34it [00:00, 44.78it/s]\n","Test: 33it [00:00, 45.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3481\n","Val   loss: 0.3839\n","Test  loss: 0.3898\n","\n","Val   Macro F1: 0.2355\n","Test  Macro F1: 0.2496\n","\n","Best Epoch: 137, best val macro F1: 0.2355, test macro F1: 0.2496\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 138\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.83it/s]\n","Val: 34it [00:00, 44.80it/s]\n","Test: 33it [00:00, 44.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3469\n","Val   loss: 0.4127\n","Test  loss: 0.4180\n","\n","Val   Macro F1: 0.2334\n","Test  Macro F1: 0.2492\n","\n","Best Epoch: 137, best val macro F1: 0.2355, test macro F1: 0.2496\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 139\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.55it/s]\n","Val: 34it [00:00, 45.25it/s]\n","Test: 33it [00:00, 44.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3481\n","Val   loss: 0.4024\n","Test  loss: 0.4072\n","\n","Val   Macro F1: 0.2368\n","Test  Macro F1: 0.2512\n","\n","Best Epoch: 139, best val macro F1: 0.2368, test macro F1: 0.2512\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 140\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.40it/s]\n","Val: 34it [00:00, 45.28it/s]\n","Test: 33it [00:00, 45.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3466\n","Val   loss: 0.4121\n","Test  loss: 0.4170\n","\n","Val   Macro F1: 0.2336\n","Test  Macro F1: 0.2494\n","\n","Best Epoch: 139, best val macro F1: 0.2368, test macro F1: 0.2512\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 141\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.06it/s]\n","Val: 34it [00:00, 45.03it/s]\n","Test: 33it [00:00, 44.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3491\n","Val   loss: 0.3916\n","Test  loss: 0.3983\n","\n","Val   Macro F1: 0.2347\n","Test  Macro F1: 0.2515\n","\n","Best Epoch: 139, best val macro F1: 0.2368, test macro F1: 0.2512\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 142\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.95it/s]\n","Val: 34it [00:00, 44.94it/s]\n","Test: 33it [00:00, 45.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3482\n","Val   loss: 0.4015\n","Test  loss: 0.4069\n","\n","Val   Macro F1: 0.2391\n","Test  Macro F1: 0.2513\n","\n","Best Epoch: 142, best val macro F1: 0.2391, test macro F1: 0.2513\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 143\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.40it/s]\n","Val: 34it [00:00, 44.10it/s]\n","Test: 33it [00:00, 44.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3486\n","Val   loss: 0.3876\n","Test  loss: 0.3956\n","\n","Val   Macro F1: 0.2383\n","Test  Macro F1: 0.2509\n","\n","Best Epoch: 142, best val macro F1: 0.2391, test macro F1: 0.2513\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 144\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.36it/s]\n","Val: 34it [00:00, 44.88it/s]\n","Test: 33it [00:00, 44.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3458\n","Val   loss: 0.4064\n","Test  loss: 0.4096\n","\n","Val   Macro F1: 0.2332\n","Test  Macro F1: 0.2529\n","\n","Best Epoch: 142, best val macro F1: 0.2391, test macro F1: 0.2513\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 145\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.15it/s]\n","Val: 34it [00:00, 44.93it/s]\n","Test: 33it [00:00, 45.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3477\n","Val   loss: 0.3934\n","Test  loss: 0.3984\n","\n","Val   Macro F1: 0.2375\n","Test  Macro F1: 0.2532\n","\n","Best Epoch: 142, best val macro F1: 0.2391, test macro F1: 0.2513\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 146\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.42it/s]\n","Val: 34it [00:00, 45.25it/s]\n","Test: 33it [00:00, 45.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3428\n","Val   loss: 0.3987\n","Test  loss: 0.4038\n","\n","Val   Macro F1: 0.2347\n","Test  Macro F1: 0.2494\n","\n","Best Epoch: 142, best val macro F1: 0.2391, test macro F1: 0.2513\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 147\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.64it/s]\n","Val: 34it [00:00, 45.11it/s]\n","Test: 33it [00:00, 44.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3455\n","Val   loss: 0.3913\n","Test  loss: 0.3965\n","\n","Val   Macro F1: 0.2394\n","Test  Macro F1: 0.2520\n","\n","Best Epoch: 147, best val macro F1: 0.2394, test macro F1: 0.2520\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 148\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.62it/s]\n","Val: 34it [00:00, 44.93it/s]\n","Test: 33it [00:00, 44.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3445\n","Val   loss: 0.3971\n","Test  loss: 0.4015\n","\n","Val   Macro F1: 0.2388\n","Test  Macro F1: 0.2549\n","\n","Best Epoch: 147, best val macro F1: 0.2394, test macro F1: 0.2520\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 149\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.73it/s]\n","Val: 34it [00:00, 45.23it/s]\n","Test: 33it [00:00, 44.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3449\n","Val   loss: 0.4156\n","Test  loss: 0.4191\n","\n","Val   Macro F1: 0.2337\n","Test  Macro F1: 0.2483\n","\n","Best Epoch: 147, best val macro F1: 0.2394, test macro F1: 0.2520\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 150\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.52it/s]\n","Val: 34it [00:00, 44.94it/s]\n","Test: 33it [00:00, 44.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3456\n","Val   loss: 0.3871\n","Test  loss: 0.3920\n","\n","Val   Macro F1: 0.2370\n","Test  Macro F1: 0.2534\n","\n","Best Epoch: 147, best val macro F1: 0.2394, test macro F1: 0.2520\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 151\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.17it/s]\n","Val: 34it [00:01, 25.76it/s]\n","Test: 33it [00:00, 44.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3449\n","Val   loss: 0.4114\n","Test  loss: 0.4142\n","\n","Val   Macro F1: 0.2366\n","Test  Macro F1: 0.2515\n","\n","Best Epoch: 147, best val macro F1: 0.2394, test macro F1: 0.2520\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 152\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.17it/s]\n","Val: 34it [00:00, 45.02it/s]\n","Test: 33it [00:00, 44.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3446\n","Val   loss: 0.3903\n","Test  loss: 0.3957\n","\n","Val   Macro F1: 0.2405\n","Test  Macro F1: 0.2513\n","\n","Best Epoch: 152, best val macro F1: 0.2405, test macro F1: 0.2513\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 153\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.77it/s]\n","Val: 34it [00:00, 44.91it/s]\n","Test: 33it [00:00, 44.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3438\n","Val   loss: 0.3887\n","Test  loss: 0.3964\n","\n","Val   Macro F1: 0.2344\n","Test  Macro F1: 0.2509\n","\n","Best Epoch: 152, best val macro F1: 0.2405, test macro F1: 0.2513\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 154\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.48it/s]\n","Val: 34it [00:00, 44.83it/s]\n","Test: 33it [00:00, 45.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3437\n","Val   loss: 0.3945\n","Test  loss: 0.4017\n","\n","Val   Macro F1: 0.2371\n","Test  Macro F1: 0.2509\n","\n","Best Epoch: 152, best val macro F1: 0.2405, test macro F1: 0.2513\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 155\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.10it/s]\n","Val: 34it [00:00, 45.09it/s]\n","Test: 33it [00:00, 44.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3439\n","Val   loss: 0.4068\n","Test  loss: 0.4099\n","\n","Val   Macro F1: 0.2345\n","Test  Macro F1: 0.2501\n","\n","Best Epoch: 152, best val macro F1: 0.2405, test macro F1: 0.2513\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 156\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.97it/s]\n","Val: 34it [00:00, 44.84it/s]\n","Test: 33it [00:00, 45.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3453\n","Val   loss: 0.4001\n","Test  loss: 0.4055\n","\n","Val   Macro F1: 0.2389\n","Test  Macro F1: 0.2501\n","\n","Best Epoch: 152, best val macro F1: 0.2405, test macro F1: 0.2513\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 157\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.93it/s]\n","Val: 34it [00:00, 43.96it/s]\n","Test: 33it [00:00, 45.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3442\n","Val   loss: 0.4072\n","Test  loss: 0.4112\n","\n","Val   Macro F1: 0.2359\n","Test  Macro F1: 0.2496\n","\n","Best Epoch: 152, best val macro F1: 0.2405, test macro F1: 0.2513\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 158\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.64it/s]\n","Val: 34it [00:00, 45.07it/s]\n","Test: 33it [00:00, 44.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3438\n","Val   loss: 0.4030\n","Test  loss: 0.4067\n","\n","Val   Macro F1: 0.2359\n","Test  Macro F1: 0.2501\n","\n","Best Epoch: 152, best val macro F1: 0.2405, test macro F1: 0.2513\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 159\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.58it/s]\n","Val: 34it [00:00, 45.03it/s]\n","Test: 33it [00:00, 45.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3427\n","Val   loss: 0.3992\n","Test  loss: 0.4029\n","\n","Val   Macro F1: 0.2374\n","Test  Macro F1: 0.2515\n","\n","Best Epoch: 152, best val macro F1: 0.2405, test macro F1: 0.2513\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 160\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.16it/s]\n","Val: 34it [00:00, 44.97it/s]\n","Test: 33it [00:00, 45.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3432\n","Val   loss: 0.4103\n","Test  loss: 0.4147\n","\n","Val   Macro F1: 0.2350\n","Test  Macro F1: 0.2499\n","\n","Best Epoch: 152, best val macro F1: 0.2405, test macro F1: 0.2513\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 161\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.00it/s]\n","Val: 34it [00:00, 44.92it/s]\n","Test: 33it [00:00, 44.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3416\n","Val   loss: 0.4050\n","Test  loss: 0.4094\n","\n","Val   Macro F1: 0.2338\n","Test  Macro F1: 0.2486\n","\n","Best Epoch: 152, best val macro F1: 0.2405, test macro F1: 0.2513\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 162\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.65it/s]\n","Val: 34it [00:00, 44.59it/s]\n","Test: 33it [00:00, 44.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3426\n","Val   loss: 0.3973\n","Test  loss: 0.4023\n","\n","Val   Macro F1: 0.2396\n","Test  Macro F1: 0.2531\n","\n","Best Epoch: 152, best val macro F1: 0.2405, test macro F1: 0.2513\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 163\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.59it/s]\n","Val: 34it [00:00, 44.84it/s]\n","Test: 33it [00:00, 44.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3423\n","Val   loss: 0.4020\n","Test  loss: 0.4072\n","\n","Val   Macro F1: 0.2356\n","Test  Macro F1: 0.2529\n","\n","Best Epoch: 152, best val macro F1: 0.2405, test macro F1: 0.2513\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 164\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.97it/s]\n","Val: 34it [00:00, 45.14it/s]\n","Test: 33it [00:00, 44.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3415\n","Val   loss: 0.3874\n","Test  loss: 0.3936\n","\n","Val   Macro F1: 0.2421\n","Test  Macro F1: 0.2538\n","\n","Best Epoch: 164, best val macro F1: 0.2421, test macro F1: 0.2538\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 165\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.55it/s]\n","Val: 34it [00:00, 44.72it/s]\n","Test: 33it [00:00, 44.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3407\n","Val   loss: 0.3822\n","Test  loss: 0.3900\n","\n","Val   Macro F1: 0.2406\n","Test  Macro F1: 0.2545\n","\n","Best Epoch: 164, best val macro F1: 0.2421, test macro F1: 0.2538\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 166\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.11it/s]\n","Val: 34it [00:00, 44.69it/s]\n","Test: 33it [00:00, 44.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3434\n","Val   loss: 0.4118\n","Test  loss: 0.4162\n","\n","Val   Macro F1: 0.2346\n","Test  Macro F1: 0.2485\n","\n","Best Epoch: 164, best val macro F1: 0.2421, test macro F1: 0.2538\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 167\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.40it/s]\n","Val: 34it [00:00, 44.80it/s]\n","Test: 33it [00:00, 45.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3433\n","Val   loss: 0.3929\n","Test  loss: 0.3975\n","\n","Val   Macro F1: 0.2419\n","Test  Macro F1: 0.2566\n","\n","Best Epoch: 164, best val macro F1: 0.2421, test macro F1: 0.2538\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 168\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.02it/s]\n","Val: 34it [00:00, 45.44it/s]\n","Test: 33it [00:00, 44.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3444\n","Val   loss: 0.3902\n","Test  loss: 0.3963\n","\n","Val   Macro F1: 0.2388\n","Test  Macro F1: 0.2557\n","\n","Best Epoch: 164, best val macro F1: 0.2421, test macro F1: 0.2538\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 169\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.05it/s]\n","Val: 34it [00:00, 45.29it/s]\n","Test: 33it [00:00, 44.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3402\n","Val   loss: 0.3949\n","Test  loss: 0.3998\n","\n","Val   Macro F1: 0.2388\n","Test  Macro F1: 0.2520\n","\n","Best Epoch: 164, best val macro F1: 0.2421, test macro F1: 0.2538\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 170\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.15it/s]\n","Val: 34it [00:00, 45.18it/s]\n","Test: 33it [00:00, 44.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3403\n","Val   loss: 0.4147\n","Test  loss: 0.4191\n","\n","Val   Macro F1: 0.2355\n","Test  Macro F1: 0.2529\n","\n","Best Epoch: 164, best val macro F1: 0.2421, test macro F1: 0.2538\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 171\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.08it/s]\n","Val: 34it [00:00, 45.15it/s]\n","Test: 33it [00:00, 44.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3407\n","Val   loss: 0.4020\n","Test  loss: 0.4081\n","\n","Val   Macro F1: 0.2331\n","Test  Macro F1: 0.2539\n","\n","Best Epoch: 164, best val macro F1: 0.2421, test macro F1: 0.2538\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 172\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.43it/s]\n","Val: 34it [00:00, 44.79it/s]\n","Test: 33it [00:00, 44.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3416\n","Val   loss: 0.3998\n","Test  loss: 0.4048\n","\n","Val   Macro F1: 0.2402\n","Test  Macro F1: 0.2543\n","\n","Best Epoch: 164, best val macro F1: 0.2421, test macro F1: 0.2538\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 173\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.05it/s]\n","Val: 34it [00:00, 44.87it/s]\n","Test: 33it [00:00, 45.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3398\n","Val   loss: 0.4018\n","Test  loss: 0.4077\n","\n","Val   Macro F1: 0.2373\n","Test  Macro F1: 0.2527\n","\n","Best Epoch: 164, best val macro F1: 0.2421, test macro F1: 0.2538\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 174\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.98it/s]\n","Val: 34it [00:00, 45.23it/s]\n","Test: 33it [00:00, 44.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3400\n","Val   loss: 0.3840\n","Test  loss: 0.3900\n","\n","Val   Macro F1: 0.2378\n","Test  Macro F1: 0.2546\n","\n","Best Epoch: 164, best val macro F1: 0.2421, test macro F1: 0.2538\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 175\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.18it/s]\n","Val: 34it [00:00, 45.03it/s]\n","Test: 33it [00:00, 44.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3400\n","Val   loss: 0.3947\n","Test  loss: 0.4001\n","\n","Val   Macro F1: 0.2346\n","Test  Macro F1: 0.2517\n","\n","Best Epoch: 164, best val macro F1: 0.2421, test macro F1: 0.2538\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 176\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.47it/s]\n","Val: 34it [00:00, 45.02it/s]\n","Test: 33it [00:00, 44.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3389\n","Val   loss: 0.4007\n","Test  loss: 0.4061\n","\n","Val   Macro F1: 0.2399\n","Test  Macro F1: 0.2506\n","\n","Best Epoch: 164, best val macro F1: 0.2421, test macro F1: 0.2538\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 177\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.44it/s]\n","Val: 34it [00:00, 44.44it/s]\n","Test: 33it [00:00, 44.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3395\n","Val   loss: 0.3898\n","Test  loss: 0.3957\n","\n","Val   Macro F1: 0.2360\n","Test  Macro F1: 0.2512\n","\n","Best Epoch: 164, best val macro F1: 0.2421, test macro F1: 0.2538\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 178\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.60it/s]\n","Val: 34it [00:00, 43.81it/s]\n","Test: 33it [00:00, 44.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3433\n","Val   loss: 0.3948\n","Test  loss: 0.4004\n","\n","Val   Macro F1: 0.2385\n","Test  Macro F1: 0.2536\n","\n","Best Epoch: 164, best val macro F1: 0.2421, test macro F1: 0.2538\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 179\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.62it/s]\n","Val: 34it [00:00, 44.93it/s]\n","Test: 33it [00:00, 44.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3394\n","Val   loss: 0.4001\n","Test  loss: 0.4045\n","\n","Val   Macro F1: 0.2378\n","Test  Macro F1: 0.2545\n","\n","Best Epoch: 164, best val macro F1: 0.2421, test macro F1: 0.2538\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 180\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.00it/s]\n","Val: 34it [00:00, 44.77it/s]\n","Test: 33it [00:00, 45.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3387\n","Val   loss: 0.3871\n","Test  loss: 0.3948\n","\n","Val   Macro F1: 0.2399\n","Test  Macro F1: 0.2549\n","\n","Best Epoch: 164, best val macro F1: 0.2421, test macro F1: 0.2538\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 181\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.07it/s]\n","Val: 34it [00:00, 44.83it/s]\n","Test: 33it [00:00, 45.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3410\n","Val   loss: 0.3942\n","Test  loss: 0.3994\n","\n","Val   Macro F1: 0.2428\n","Test  Macro F1: 0.2528\n","\n","Best Epoch: 181, best val macro F1: 0.2428, test macro F1: 0.2528\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 182\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.66it/s]\n","Val: 34it [00:00, 45.18it/s]\n","Test: 33it [00:00, 44.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3391\n","Val   loss: 0.3856\n","Test  loss: 0.3930\n","\n","Val   Macro F1: 0.2395\n","Test  Macro F1: 0.2555\n","\n","Best Epoch: 181, best val macro F1: 0.2428, test macro F1: 0.2528\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 183\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.58it/s]\n","Val: 34it [00:00, 44.93it/s]\n","Test: 33it [00:00, 44.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3392\n","Val   loss: 0.3937\n","Test  loss: 0.3998\n","\n","Val   Macro F1: 0.2397\n","Test  Macro F1: 0.2581\n","\n","Best Epoch: 181, best val macro F1: 0.2428, test macro F1: 0.2528\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 184\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.96it/s]\n","Val: 34it [00:00, 44.92it/s]\n","Test: 33it [00:00, 44.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3377\n","Val   loss: 0.4027\n","Test  loss: 0.4091\n","\n","Val   Macro F1: 0.2379\n","Test  Macro F1: 0.2516\n","\n","Best Epoch: 181, best val macro F1: 0.2428, test macro F1: 0.2528\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 185\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.54it/s]\n","Val: 34it [00:00, 44.11it/s]\n","Test: 33it [00:00, 44.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3394\n","Val   loss: 0.3921\n","Test  loss: 0.3977\n","\n","Val   Macro F1: 0.2400\n","Test  Macro F1: 0.2541\n","\n","Best Epoch: 181, best val macro F1: 0.2428, test macro F1: 0.2528\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 186\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.56it/s]\n","Val: 34it [00:00, 44.91it/s]\n","Test: 33it [00:00, 45.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3386\n","Val   loss: 0.3845\n","Test  loss: 0.3912\n","\n","Val   Macro F1: 0.2404\n","Test  Macro F1: 0.2565\n","\n","Best Epoch: 181, best val macro F1: 0.2428, test macro F1: 0.2528\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 187\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.85it/s]\n","Val: 34it [00:00, 44.66it/s]\n","Test: 33it [00:00, 44.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3385\n","Val   loss: 0.4009\n","Test  loss: 0.4064\n","\n","Val   Macro F1: 0.2337\n","Test  Macro F1: 0.2529\n","\n","Best Epoch: 181, best val macro F1: 0.2428, test macro F1: 0.2528\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 188\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.80it/s]\n","Val: 34it [00:00, 44.95it/s]\n","Test: 33it [00:00, 45.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3377\n","Val   loss: 0.4054\n","Test  loss: 0.4098\n","\n","Val   Macro F1: 0.2376\n","Test  Macro F1: 0.2540\n","\n","Best Epoch: 181, best val macro F1: 0.2428, test macro F1: 0.2528\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 189\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.12it/s]\n","Val: 34it [00:00, 44.85it/s]\n","Test: 33it [00:00, 44.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3377\n","Val   loss: 0.3992\n","Test  loss: 0.4029\n","\n","Val   Macro F1: 0.2400\n","Test  Macro F1: 0.2563\n","\n","Best Epoch: 181, best val macro F1: 0.2428, test macro F1: 0.2528\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 190\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.52it/s]\n","Val: 34it [00:00, 44.68it/s]\n","Test: 33it [00:00, 45.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3383\n","Val   loss: 0.4007\n","Test  loss: 0.4053\n","\n","Val   Macro F1: 0.2427\n","Test  Macro F1: 0.2557\n","\n","Best Epoch: 181, best val macro F1: 0.2428, test macro F1: 0.2528\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 191\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.32it/s]\n","Val: 34it [00:00, 44.99it/s]\n","Test: 33it [00:00, 45.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3384\n","Val   loss: 0.4013\n","Test  loss: 0.4072\n","\n","Val   Macro F1: 0.2367\n","Test  Macro F1: 0.2540\n","\n","Best Epoch: 181, best val macro F1: 0.2428, test macro F1: 0.2528\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 192\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.99it/s]\n","Val: 34it [00:00, 45.27it/s]\n","Test: 33it [00:00, 44.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3383\n","Val   loss: 0.3934\n","Test  loss: 0.3989\n","\n","Val   Macro F1: 0.2407\n","Test  Macro F1: 0.2559\n","\n","Best Epoch: 181, best val macro F1: 0.2428, test macro F1: 0.2528\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 193\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:01, 41.49it/s]\n","Val: 34it [00:00, 44.99it/s]\n","Test: 33it [00:00, 44.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3364\n","Val   loss: 0.4010\n","Test  loss: 0.4056\n","\n","Val   Macro F1: 0.2376\n","Test  Macro F1: 0.2518\n","\n","Best Epoch: 181, best val macro F1: 0.2428, test macro F1: 0.2528\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 194\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.71it/s]\n","Val: 34it [00:00, 44.73it/s]\n","Test: 33it [00:00, 44.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3390\n","Val   loss: 0.3877\n","Test  loss: 0.3948\n","\n","Val   Macro F1: 0.2400\n","Test  Macro F1: 0.2565\n","\n","Best Epoch: 181, best val macro F1: 0.2428, test macro F1: 0.2528\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 195\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.14it/s]\n","Val: 34it [00:00, 44.97it/s]\n","Test: 33it [00:00, 44.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3356\n","Val   loss: 0.3872\n","Test  loss: 0.3934\n","\n","Val   Macro F1: 0.2381\n","Test  Macro F1: 0.2550\n","\n","Best Epoch: 181, best val macro F1: 0.2428, test macro F1: 0.2528\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 196\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.44it/s]\n","Val: 34it [00:00, 44.76it/s]\n","Test: 33it [00:00, 44.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3374\n","Val   loss: 0.3968\n","Test  loss: 0.4016\n","\n","Val   Macro F1: 0.2414\n","Test  Macro F1: 0.2546\n","\n","Best Epoch: 181, best val macro F1: 0.2428, test macro F1: 0.2528\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 197\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.25it/s]\n","Val: 34it [00:00, 44.65it/s]\n","Test: 33it [00:00, 45.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3380\n","Val   loss: 0.3944\n","Test  loss: 0.4013\n","\n","Val   Macro F1: 0.2396\n","Test  Macro F1: 0.2515\n","\n","Best Epoch: 181, best val macro F1: 0.2428, test macro F1: 0.2528\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 198\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.10it/s]\n","Val: 34it [00:00, 44.95it/s]\n","Test: 33it [00:00, 44.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3361\n","Val   loss: 0.3929\n","Test  loss: 0.3980\n","\n","Val   Macro F1: 0.2449\n","Test  Macro F1: 0.2559\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 199\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.57it/s]\n","Val: 34it [00:00, 44.01it/s]\n","Test: 33it [00:00, 45.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3351\n","Val   loss: 0.3983\n","Test  loss: 0.4024\n","\n","Val   Macro F1: 0.2408\n","Test  Macro F1: 0.2544\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 200\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.64it/s]\n","Val: 34it [00:00, 44.22it/s]\n","Test: 33it [00:00, 44.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3365\n","Val   loss: 0.3895\n","Test  loss: 0.3965\n","\n","Val   Macro F1: 0.2377\n","Test  Macro F1: 0.2525\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 201\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.61it/s]\n","Val: 34it [00:00, 44.81it/s]\n","Test: 33it [00:00, 44.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3375\n","Val   loss: 0.3901\n","Test  loss: 0.3964\n","\n","Val   Macro F1: 0.2409\n","Test  Macro F1: 0.2561\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 202\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.77it/s]\n","Val: 34it [00:00, 44.49it/s]\n","Test: 33it [00:00, 44.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3363\n","Val   loss: 0.3947\n","Test  loss: 0.4002\n","\n","Val   Macro F1: 0.2393\n","Test  Macro F1: 0.2562\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 203\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.49it/s]\n","Val: 34it [00:00, 45.17it/s]\n","Test: 33it [00:00, 44.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3361\n","Val   loss: 0.3934\n","Test  loss: 0.4002\n","\n","Val   Macro F1: 0.2381\n","Test  Macro F1: 0.2571\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 204\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.71it/s]\n","Val: 34it [00:00, 44.87it/s]\n","Test: 33it [00:00, 45.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3369\n","Val   loss: 0.3875\n","Test  loss: 0.3928\n","\n","Val   Macro F1: 0.2435\n","Test  Macro F1: 0.2571\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 205\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.97it/s]\n","Val: 34it [00:00, 45.10it/s]\n","Test: 33it [00:00, 44.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3347\n","Val   loss: 0.3983\n","Test  loss: 0.4027\n","\n","Val   Macro F1: 0.2415\n","Test  Macro F1: 0.2547\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 206\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.14it/s]\n","Val: 34it [00:00, 45.04it/s]\n","Test: 33it [00:00, 45.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3348\n","Val   loss: 0.4064\n","Test  loss: 0.4110\n","\n","Val   Macro F1: 0.2395\n","Test  Macro F1: 0.2550\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 207\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.89it/s]\n","Val: 34it [00:00, 44.97it/s]\n","Test: 33it [00:00, 44.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3571\n","Val   loss: 0.4448\n","Test  loss: 0.4482\n","\n","Val   Macro F1: 0.1812\n","Test  Macro F1: 0.1910\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 208\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.63it/s]\n","Val: 34it [00:00, 45.26it/s]\n","Test: 33it [00:00, 45.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3924\n","Val   loss: 0.4052\n","Test  loss: 0.4104\n","\n","Val   Macro F1: 0.2189\n","Test  Macro F1: 0.2388\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 209\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.95it/s]\n","Val: 34it [00:00, 44.74it/s]\n","Test: 33it [00:00, 44.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3631\n","Val   loss: 0.4087\n","Test  loss: 0.4138\n","\n","Val   Macro F1: 0.2206\n","Test  Macro F1: 0.2413\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 210\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.48it/s]\n","Val: 34it [00:00, 44.96it/s]\n","Test: 33it [00:00, 44.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3548\n","Val   loss: 0.4052\n","Test  loss: 0.4099\n","\n","Val   Macro F1: 0.2286\n","Test  Macro F1: 0.2469\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 211\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.48it/s]\n","Val: 34it [00:00, 44.62it/s]\n","Test: 33it [00:00, 44.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3517\n","Val   loss: 0.3992\n","Test  loss: 0.4043\n","\n","Val   Macro F1: 0.2283\n","Test  Macro F1: 0.2498\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 212\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.26it/s]\n","Val: 34it [00:00, 44.07it/s]\n","Test: 33it [00:00, 43.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3468\n","Val   loss: 0.3895\n","Test  loss: 0.3958\n","\n","Val   Macro F1: 0.2358\n","Test  Macro F1: 0.2521\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 213\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.79it/s]\n","Val: 34it [00:00, 43.38it/s]\n","Test: 33it [00:00, 42.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3447\n","Val   loss: 0.3965\n","Test  loss: 0.4021\n","\n","Val   Macro F1: 0.2327\n","Test  Macro F1: 0.2534\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 214\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 66.94it/s]\n","Val: 34it [00:00, 43.63it/s]\n","Test: 33it [00:00, 44.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3399\n","Val   loss: 0.3956\n","Test  loss: 0.4002\n","\n","Val   Macro F1: 0.2442\n","Test  Macro F1: 0.2555\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 215\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.26it/s]\n","Val: 34it [00:00, 44.08it/s]\n","Test: 33it [00:00, 45.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3386\n","Val   loss: 0.3970\n","Test  loss: 0.4016\n","\n","Val   Macro F1: 0.2388\n","Test  Macro F1: 0.2527\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 216\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.26it/s]\n","Val: 34it [00:00, 45.00it/s]\n","Test: 33it [00:00, 44.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3376\n","Val   loss: 0.3957\n","Test  loss: 0.4000\n","\n","Val   Macro F1: 0.2407\n","Test  Macro F1: 0.2558\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 217\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.42it/s]\n","Val: 34it [00:00, 44.70it/s]\n","Test: 33it [00:00, 45.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3367\n","Val   loss: 0.3928\n","Test  loss: 0.3976\n","\n","Val   Macro F1: 0.2428\n","Test  Macro F1: 0.2577\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 218\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.61it/s]\n","Val: 34it [00:00, 44.68it/s]\n","Test: 33it [00:00, 44.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3363\n","Val   loss: 0.3882\n","Test  loss: 0.3937\n","\n","Val   Macro F1: 0.2417\n","Test  Macro F1: 0.2608\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 219\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.69it/s]\n","Val: 34it [00:00, 44.86it/s]\n","Test: 33it [00:00, 45.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3348\n","Val   loss: 0.3953\n","Test  loss: 0.3996\n","\n","Val   Macro F1: 0.2418\n","Test  Macro F1: 0.2600\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 220\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.54it/s]\n","Val: 34it [00:00, 44.87it/s]\n","Test: 33it [00:00, 45.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3358\n","Val   loss: 0.3925\n","Test  loss: 0.3972\n","\n","Val   Macro F1: 0.2422\n","Test  Macro F1: 0.2589\n","\n","Best Epoch: 198, best val macro F1: 0.2449, test macro F1: 0.2559\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 221\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.59it/s]\n","Val: 34it [00:00, 44.97it/s]\n","Test: 33it [00:00, 44.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3346\n","Val   loss: 0.3980\n","Test  loss: 0.4032\n","\n","Val   Macro F1: 0.2460\n","Test  Macro F1: 0.2587\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 222\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.94it/s]\n","Val: 34it [00:00, 45.16it/s]\n","Test: 33it [00:00, 45.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3353\n","Val   loss: 0.3925\n","Test  loss: 0.3981\n","\n","Val   Macro F1: 0.2429\n","Test  Macro F1: 0.2566\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 223\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.45it/s]\n","Val: 34it [00:00, 45.10it/s]\n","Test: 33it [00:00, 44.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3343\n","Val   loss: 0.3899\n","Test  loss: 0.3955\n","\n","Val   Macro F1: 0.2445\n","Test  Macro F1: 0.2580\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 224\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.03it/s]\n","Val: 34it [00:00, 44.83it/s]\n","Test: 33it [00:00, 45.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3329\n","Val   loss: 0.3927\n","Test  loss: 0.3988\n","\n","Val   Macro F1: 0.2391\n","Test  Macro F1: 0.2555\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 225\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.40it/s]\n","Val: 34it [00:00, 45.32it/s]\n","Test: 33it [00:00, 45.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3340\n","Val   loss: 0.4001\n","Test  loss: 0.4048\n","\n","Val   Macro F1: 0.2431\n","Test  Macro F1: 0.2567\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 226\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.97it/s]\n","Val: 34it [00:00, 45.11it/s]\n","Test: 33it [00:00, 45.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3326\n","Val   loss: 0.3966\n","Test  loss: 0.4010\n","\n","Val   Macro F1: 0.2391\n","Test  Macro F1: 0.2571\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 227\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.05it/s]\n","Val: 34it [00:00, 44.15it/s]\n","Test: 33it [00:00, 44.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3323\n","Val   loss: 0.3977\n","Test  loss: 0.4019\n","\n","Val   Macro F1: 0.2439\n","Test  Macro F1: 0.2577\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 228\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.71it/s]\n","Val: 34it [00:00, 45.22it/s]\n","Test: 33it [00:00, 45.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3335\n","Val   loss: 0.3943\n","Test  loss: 0.3999\n","\n","Val   Macro F1: 0.2360\n","Test  Macro F1: 0.2523\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 229\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.94it/s]\n","Val: 34it [00:00, 44.88it/s]\n","Test: 33it [00:00, 43.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3360\n","Val   loss: 0.3932\n","Test  loss: 0.3974\n","\n","Val   Macro F1: 0.2404\n","Test  Macro F1: 0.2589\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 230\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.00it/s]\n","Val: 34it [00:00, 45.06it/s]\n","Test: 33it [00:00, 45.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3318\n","Val   loss: 0.3942\n","Test  loss: 0.3998\n","\n","Val   Macro F1: 0.2372\n","Test  Macro F1: 0.2547\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 231\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.87it/s]\n","Val: 34it [00:00, 45.08it/s]\n","Test: 33it [00:00, 44.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3358\n","Val   loss: 0.3929\n","Test  loss: 0.3998\n","\n","Val   Macro F1: 0.2374\n","Test  Macro F1: 0.2559\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 232\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.25it/s]\n","Val: 34it [00:00, 44.96it/s]\n","Test: 33it [00:00, 44.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3371\n","Val   loss: 0.3885\n","Test  loss: 0.3950\n","\n","Val   Macro F1: 0.2428\n","Test  Macro F1: 0.2577\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 233\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.69it/s]\n","Val: 34it [00:00, 44.72it/s]\n","Test: 33it [00:00, 44.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3329\n","Val   loss: 0.3846\n","Test  loss: 0.3930\n","\n","Val   Macro F1: 0.2404\n","Test  Macro F1: 0.2559\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 234\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.88it/s]\n","Val: 34it [00:00, 45.38it/s]\n","Test: 33it [00:00, 45.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3328\n","Val   loss: 0.4040\n","Test  loss: 0.4105\n","\n","Val   Macro F1: 0.2355\n","Test  Macro F1: 0.2522\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 235\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:01, 41.09it/s]\n","Val: 34it [00:00, 45.09it/s]\n","Test: 33it [00:00, 44.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3442\n","Val   loss: 0.3924\n","Test  loss: 0.3994\n","\n","Val   Macro F1: 0.2458\n","Test  Macro F1: 0.2580\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 236\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.93it/s]\n","Val: 34it [00:00, 45.26it/s]\n","Test: 33it [00:00, 45.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3338\n","Val   loss: 0.3886\n","Test  loss: 0.3956\n","\n","Val   Macro F1: 0.2413\n","Test  Macro F1: 0.2575\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 237\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.64it/s]\n","Val: 34it [00:00, 44.81it/s]\n","Test: 33it [00:00, 44.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3320\n","Val   loss: 0.3849\n","Test  loss: 0.3920\n","\n","Val   Macro F1: 0.2422\n","Test  Macro F1: 0.2580\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 238\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.68it/s]\n","Val: 34it [00:00, 44.94it/s]\n","Test: 33it [00:00, 44.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3331\n","Val   loss: 0.4013\n","Test  loss: 0.4051\n","\n","Val   Macro F1: 0.2440\n","Test  Macro F1: 0.2592\n","\n","Best Epoch: 221, best val macro F1: 0.2460, test macro F1: 0.2587\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 239\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 69.14it/s]\n","Val: 34it [00:00, 45.19it/s]\n","Test: 33it [00:00, 45.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3317\n","Val   loss: 0.3942\n","Test  loss: 0.3989\n","\n","Val   Macro F1: 0.2461\n","Test  Macro F1: 0.2618\n","\n","Best Epoch: 239, best val macro F1: 0.2461, test macro F1: 0.2618\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 240\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.80it/s]\n","Val: 34it [00:00, 45.10it/s]\n","Test: 33it [00:00, 44.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3329\n","Val   loss: 0.3901\n","Test  loss: 0.3958\n","\n","Val   Macro F1: 0.2433\n","Test  Macro F1: 0.2585\n","\n","Best Epoch: 239, best val macro F1: 0.2461, test macro F1: 0.2618\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 241\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.21it/s]\n","Val: 34it [00:00, 44.44it/s]\n","Test: 33it [00:00, 44.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3311\n","Val   loss: 0.3929\n","Test  loss: 0.3984\n","\n","Val   Macro F1: 0.2430\n","Test  Macro F1: 0.2593\n","\n","Best Epoch: 239, best val macro F1: 0.2461, test macro F1: 0.2618\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 242\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.89it/s]\n","Val: 34it [00:00, 44.80it/s]\n","Test: 33it [00:00, 44.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3311\n","Val   loss: 0.3877\n","Test  loss: 0.3928\n","\n","Val   Macro F1: 0.2447\n","Test  Macro F1: 0.2598\n","\n","Best Epoch: 239, best val macro F1: 0.2461, test macro F1: 0.2618\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 243\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.50it/s]\n","Val: 34it [00:00, 43.33it/s]\n","Test: 33it [00:00, 43.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3321\n","Val   loss: 0.3906\n","Test  loss: 0.3956\n","\n","Val   Macro F1: 0.2401\n","Test  Macro F1: 0.2570\n","\n","Best Epoch: 239, best val macro F1: 0.2461, test macro F1: 0.2618\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 244\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 67.86it/s]\n","Val: 34it [00:00, 44.64it/s]\n","Test: 33it [00:00, 44.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3312\n","Val   loss: 0.3979\n","Test  loss: 0.4020\n","\n","Val   Macro F1: 0.2399\n","Test  Macro F1: 0.2572\n","\n","Best Epoch: 239, best val macro F1: 0.2461, test macro F1: 0.2618\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 245\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 68.20it/s]\n","Val: 34it [00:00, 43.21it/s]\n","Test: 33it [00:00, 43.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3350\n","Val   loss: 0.3939\n","Test  loss: 0.3996\n","\n","Val   Macro F1: 0.2381\n","Test  Macro F1: 0.2566\n","\n","Best Epoch: 239, best val macro F1: 0.2461, test macro F1: 0.2618\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 246\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 65.17it/s]\n","Val: 34it [00:00, 43.72it/s]\n","Test: 33it [00:00, 41.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3328\n","Val   loss: 0.3797\n","Test  loss: 0.3858\n","\n","Val   Macro F1: 0.2429\n","Test  Macro F1: 0.2619\n","\n","Best Epoch: 239, best val macro F1: 0.2461, test macro F1: 0.2618\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 247\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 66.91it/s]\n","Val: 34it [00:00, 43.55it/s]\n","Test: 33it [00:00, 43.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3303\n","Val   loss: 0.3837\n","Test  loss: 0.3898\n","\n","Val   Macro F1: 0.2445\n","Test  Macro F1: 0.2611\n","\n","Best Epoch: 239, best val macro F1: 0.2461, test macro F1: 0.2618\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 248\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 65.48it/s]\n","Val: 34it [00:00, 42.16it/s]\n","Test: 33it [00:00, 42.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3306\n","Val   loss: 0.3973\n","Test  loss: 0.4017\n","\n","Val   Macro F1: 0.2415\n","Test  Macro F1: 0.2563\n","\n","Best Epoch: 239, best val macro F1: 0.2461, test macro F1: 0.2618\n","\n","\n","------------------------------------------------------------------------\n","Epoch: 249\n"]},{"output_type":"stream","name":"stderr","text":["Training: 59it [00:00, 64.83it/s]\n","Val: 34it [00:00, 42.26it/s]\n","Test: 33it [00:00, 41.92it/s]"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.3283\n","Val   loss: 0.3887\n","Test  loss: 0.3955\n","\n","Val   Macro F1: 0.2445\n","Test  Macro F1: 0.2589\n","\n","Best Epoch: 239, best val macro F1: 0.2461, test macro F1: 0.2618\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["In general it can be seen that the model doesnt achieve more better results after an epoch of 239. Therefore the learning can be stopped after the epoch of 239.\n","This can help prevent overfitting, as the model will not be trained for too long on the training data."],"metadata":{"id":"izErttSWHi4w"}},{"cell_type":"markdown","source":["A Macro F1 score of 0.2461 on the validation data means that the model had a relatively low overall F1 score. This could mean that the model is not accurately predicting many of the entities or that there is a large amount of entities imbalance.\n","\n","A Macro F1 score of 0.2618 on the test data suggests that the model's performance on the test set is slightly better than on the validation set, but still not ideal.\n","\n","If the Loss is close to zero it is good. It means that the probability of the prediction matching the train data is close to 1. "],"metadata":{"id":"oW4psOTaTWUG"}},{"cell_type":"markdown","source":["### Transfer Learning Model"],"metadata":{"id":"S2y5hTCuoUws"}},{"cell_type":"markdown","source":["Different Approaches for this Method. Both ideas do not work."],"metadata":{"id":"mQhyOJT_CV35"}},{"cell_type":"markdown","source":["Idea 1:"],"metadata":{"id":"8MH9WslqDDKc"}},{"cell_type":"code","source":["Transfer_Model1.embeddings.word_embeddings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SPF8JYOtVQEE","executionInfo":{"status":"ok","timestamp":1673197326927,"user_tz":-60,"elapsed":536,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"ed32418e-6e26-42dc-8dbc-5292c0fa430b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(30522, 768, padding_idx=0)"]},"metadata":{},"execution_count":279}]},{"cell_type":"code","source":["word_embeddings.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0xR4rogVS91","executionInfo":{"status":"ok","timestamp":1673197352705,"user_tz":-60,"elapsed":3,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"131fab2b-de8f-4076-9f82-138b28c5657d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(25505, 100)"]},"metadata":{},"execution_count":282}]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QdcKeRRSWbDT","executionInfo":{"status":"ok","timestamp":1673197631453,"user_tz":-60,"elapsed":542,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"44bac2f0-52bf-4e79-c2a9-86df4e1d957a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MyNERModel(\n","  (word_embedding): Embedding(25505, 100)\n","  (word_rnn): RNN(100, 128, batch_first=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (activation): Tanh()\n","  (final_layer): Linear(in_features=128, out_features=37, bias=True)\n",")"]},"metadata":{},"execution_count":295}]},{"cell_type":"markdown","source":["Transfer_Model1 has to be adapted to the word_embeddings"],"metadata":{"id":"_39ULD-pVYc0"}},{"cell_type":"code","source":["#Transfer_Model1.embeddings.word_embeddings = nn.Embedding(len(word2idx))\n","Transfer_Model1.embeddings.word_embeddings = nn.Embedding(25505, 100, padding_idx=0)\n","Transfer_Model1.num_labels = len(train_data.MAPPING_Y_NER_LABELS)\n","\n","# Get the Word embedding matrix, which was pretrained\n","Transfer_Model1.embeddings.word_embeddings.weight.data = torch.from_numpy(word_embeddings).float()\n","Transfer_Model1.embeddings.word_embeddings.weight.requires_grad = False # We do NOT want to fine-tune the word embedding"],"metadata":{"id":"nyWYaSsP9ri2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Transfer_Model1.embeddings.word_embeddings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fFDdDzl7VqNu","executionInfo":{"status":"ok","timestamp":1673197970232,"user_tz":-60,"elapsed":551,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"703f9b41-3cc5-49d0-fbd5-88cbe490a799"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(25505, 100, padding_idx=0)"]},"metadata":{},"execution_count":309}]},{"cell_type":"code","source":["Transfer_Model1.embeddings.token_type_embeddings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ql40Gl6aZ2_f","executionInfo":{"status":"ok","timestamp":1673198545349,"user_tz":-60,"elapsed":429,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"bda67f2b-75fc-4f66-d796-6a214a5ad7bb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(2, 768)"]},"metadata":{},"execution_count":328}]},{"cell_type":"markdown","source":["Okay word embeddings and size is correct now!\n"],"metadata":{"id":"AqgdKvE9ZZ9b"}},{"cell_type":"markdown","source":["The Dataloader is the same as for RNN. I want to use the same data on the same word embeddings just based on a different model."],"metadata":{"id":"lsa8WGtH-gif"}},{"cell_type":"code","source":["BATCH_SIZE = 256\n","\n","train_loader = DataLoader(\n","        train_data,\n","        batch_size=BATCH_SIZE, #256\n","        shuffle=True,\n","        num_workers=0, \n","        drop_last=False) \n","\n","val_loader = DataLoader(\n","        val_data,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True, \n","        num_workers=0, \n","        drop_last=False)\n","\n","test_loader = DataLoader(\n","        test_data,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True, \n","        num_workers=0, \n","        drop_last=False)"],"metadata":{"id":"zXiKsQTe-cgf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the lengths\n","print(train_loader.dataset.data[0][\"ners\"])\n","print(len(train_loader.dataset.data[0][\"ners\"]))\n","print(train_loader.dataset.data[0][\"y_ners\"])\n","print(len(train_loader.dataset.data[0][\"y_ners\"]))\n","print(train_loader.dataset.data[0][\"word_idx\"])\n","print(len(train_loader.dataset.data[0][\"word_idx\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I7qENaMY-hUz","executionInfo":{"status":"ok","timestamp":1673197974081,"user_tz":-60,"elapsed":3,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"8691d0b5-befc-4629-9297-2a73b7905cd4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n","210\n","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n","210\n","[21794, 16020, 18194, 154, 23134, 2537, 8252, 2649, 4665, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","210\n"]}]},{"cell_type":"code","source":["# Optimizier\n","optimizer = torch.optim.Adam(Transfer_Model1.parameters(), lr=1e-3, weight_decay=1e-8) "],"metadata":{"id":"wamDr326-nVI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Take the same Optimizer as for the RNN"],"metadata":{"id":"WeyF0sHI-5Np"}},{"cell_type":"code","source":["# Loss function\n","criterion = nn.CrossEntropyLoss(reduction='mean', ignore_index=-100)"],"metadata":{"id":"2Ed2UlHx-qeV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Take the same Optimizer as for the RNN"],"metadata":{"id":"zS3Ojljb-7U9"}},{"cell_type":"code","source":["# Move the model to the device (CPU or GPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","Transfer_Model1 = Transfer_Model1.to(device)"],"metadata":{"id":"SLCsajx_-tCs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Training and Evaluation Loop:"],"metadata":{"id":"rxi_H1nKEAOt"}},{"cell_type":"code","source":["# Initial Setup to start the Training Loop\n","\n","best_epoch = 0\n","best_val_so_far = 0\n","test_perf = 0\n","\n","\n","# TRAINING LOOP\n","for epoch in range(250):\n","  print('------------------------------------------------------------------------')\n","  print('Epoch: {}'.format(epoch))\n","\n","  # TRAIN\n","  # We set the model in train mode. It will store information to compute the gradients\n","  Transfer_Model1.train()\n","\n","  train_losses = []\n","  for batch in tqdm.tqdm(enumerate(train_loader), desc='Training'):\n","    # move them to GPU\n","    input = batch[1]['word_idx'].to(device)\n","    print(input.shape)\n","    label= batch[1]['ners'].to(device)\n","    print(label.shape)\n","\n","\n","    # Compute the model output and the loss\n","    y_logits = Transfer_Model1(input) #BxLxC (17)\n","    # We have to \"flatten\" the predictions because CE only handle tensors like BxC and B\n","    loss = criterion(y_logits.view(-1, len(train_data.MAPPING_Y_NER_LABELS)), label.view(-1))\n","\n","    # Update model parameters\n","    optimizer.zero_grad() \n","    loss.backward() \n","    optimizer.step()\n","  \n","    train_losses.append(loss.item())\n","  \n","  # VAL + TEST\n","  val_test_losses = {'val': [], 'test': []}\n","  val_test_f1 = {'val': [], 'test': []}\n","  \n","  # Unlike before, we set the model in eval mode to compute correctly dropout, batchnorm etc\n","  Transfer_Model1.eval()\n","\n","  # We do not store information relative to gradients as we do not update the model.\n","  # That's the reason why inference requires less memory and is faster.\n","  with torch.no_grad():\n","    for split_data, data in [('val', val_loader), ('test', test_loader)]:\n","      # Pay attention how the data loading become easiers!\n","      for batch in tqdm.tqdm(enumerate(data), desc=split_data.capitalize()):\n","\n","        # move them to GPU\n","        batch[1]['word_idx'] = batch[1]['word_idx'].to(device)\n","        batch[1]['ners'] = batch[1]['ners'].to(device)\n","\n","\n","        # Compute the model output and the loss\n","        y_logits = Transfer_Model1(batch[1]) #BxLxC (17)\n","        # We have to \"flatten\" the predictions because CE only handle tensors like BxC and B\n","        loss = criterion(y_logits.view(-1, len(train_data.MAPPING_Y_NER_LABELS)), batch[1]['ners'].view(-1))\n","\n","        val_test_losses[split_data].append(loss.item())\n","\n","        # Compute the macro f1 to evaluate our model\n","        y_probs = F.softmax(y_logits, dim=-1)\n","        y_pred = torch.argmax(y_logits, dim=-1)\n","\n","        f1 = compute_f1(y_pred.view(-1).cpu().numpy(), batch[1]['ners'].view(-1).cpu().numpy())\n","        val_test_f1[split_data].append(f1)\n","  \n","  # Monitoring\n","  print('Train loss: {:.4f}'.format(np.mean(train_losses)))\n","  print('Val   loss: {:.4f}'.format(np.mean(val_test_losses['val'])))\n","  print('Test  loss: {:.4f}'.format(np.mean(val_test_losses['test'])))\n","  print()\n","\n","  val_f1 = np.mean(val_test_f1['val'])\n","  test_f1 = np.mean(val_test_f1['test'])\n","  print('Val   Macro F1: {:.4f}'.format(val_f1))\n","  print('Test  Macro F1: {:.4f}'.format(test_f1))\n","  print()\n","\n","  if best_val_so_far < val_f1:\n","    best_val_so_far = val_f1\n","    test_perf = test_f1\n","    best_epoch = epoch\n","  \n","  print('Best Epoch: {}, best val macro F1: {:.4f}, test macro F1: {:.4f}'.format(best_epoch, best_val_so_far, test_perf))\n","  print()\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":486},"id":"7XNj9GyUYCjl","executionInfo":{"status":"error","timestamp":1673198287471,"user_tz":-60,"elapsed":7,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"2c67ec84-5a12-4d59-e118-b087a0919469"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------\n","Epoch: 0\n"]},{"output_type":"stream","name":"stderr","text":["Training: 0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([256, 210])\n","torch.Size([256, 210])\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-325-46a9eb6a2733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Compute the model output and the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0my_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransfer_Model1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#BxLxC (17)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m# We have to \"flatten\" the predictions because CE only handle tensors like BxC and B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAPPING_Y_NER_LABELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (768) at non-singleton dimension 2"]}]},{"cell_type":"markdown","source":["Okay this doesnt work. I dont know why - but it doesnt."],"metadata":{"id":"gzu56GKsaYqp"}},{"cell_type":"markdown","source":["Another try:"],"metadata":{"id":"hPLVfHu0ZGBj"}},{"cell_type":"code","source":["for epoch in range(250):\n","\n","  # Training Loop\n","  for batch in tqdm.tqdm(enumerate(train_loader), desc='Training'):\n","\n","    # Move the input and label tensors to the GPU\n","    inputs = batch[1]['word_idx'].to(device)\n","    labels = batch[1]['ners'].to(device)\n","\n","\n","    # Clear the gradients\n","    optimizer.zero_grad()\n","\n","    # Forward pass\n","    print(inputs[0])\n","    logits = Transfer_Model1(inputs)[0]\n","    loss = criterion(logits.view(-1, num_labels), labels.view(-1))\n","\n","    # Backward pass\n","    loss.backward()\n","    optimizer.step()\n","\n","  # Validation Loop\n","\n","  # Initialize F1 score metric\n","  f1 = F1()\n","\n","  # Validation Loop\n","  for batch in val_loader:\n","    # move them to GPU\n","    inputs = batch['word_idx'].to(device)\n","    labels = batch['ners'].to(device)\n","\n","    # Forward pass\n","    logits = Transfer_Model1(inputs)[0]\n","    loss = criterion(logits.view(-1, num_labels), labels.view(-1))\n","\n","    # Update F1 score\n","    f1.update(logits.view(-1, num_labels), labels.view(-1))\n","\n","    # Print F1 score at the end of each epoch\n","    print(\"Validation F1:\", f1.get_score())\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":798},"id":"toGJ9IdQElxI","executionInfo":{"status":"error","timestamp":1673197982968,"user_tz":-60,"elapsed":537,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"c6feb491-d522-4084-81ad-8d4d556b82c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Training: 0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor([ 9647, 25493, 25205,  4247, 15047, 11571, 20080, 24998,  9625, 16202,\n","         1149,   321,  4247, 15031, 24179,  4247, 24179,  8647, 10591, 13921,\n","        20154,  5322,  8456,  9978, 22464,  4665,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","       device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-315-e82f3ca57230>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransfer_Model1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (768) at non-singleton dimension 2"]}]},{"cell_type":"markdown","source":["Again Error message. Ok lets try another model. Maybe this pretrained model is buggy."],"metadata":{"id":"FNLAXoNXacbe"}},{"cell_type":"markdown","source":["--------------------------------"],"metadata":{"id":"Fky3bj-u6uV4"}},{"cell_type":"markdown","source":["Idea 2:"],"metadata":{"id":"AGPS7eIhET4T"}},{"cell_type":"code","source":["Transfer_Model2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HFWCRFoNG35U","executionInfo":{"status":"ok","timestamp":1673196333920,"user_tz":-60,"elapsed":17,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"75f2d00c-47db-4c8a-8884-8ba19ea23f1a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",")"]},"metadata":{},"execution_count":260}]},{"cell_type":"code","source":["torch.backends.cudnn.max_split_size_mb = 512\n","\n","import os\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\"\n","\n","!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0UThRHAEFcCG","executionInfo":{"status":"ok","timestamp":1673196333920,"user_tz":-60,"elapsed":14,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"1a9c8f5b-d983-403c-d1ed-b9b823c44a47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Jan  8 16:45:32 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0   314W / 400W |  40458MiB / 40536MiB |    100%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["# Move the model to the device (CPU or GPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","Transfer_Model2 = Transfer_Model2.to(device)"],"metadata":{"id":"BY_-1kU05CzM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the batch size\n","BATCH_SIZE = 256\n","\n","# Define the number of labels in the OntoNotes5 dataset\n","num_labels = len(train_data.MAPPING_Y_NER_LABELS)\n","\n","# Define the data loaders for the training, validation, and test sets\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n","\n","# Define the loss function and the optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(Transfer_Model2.parameters())\n","\n","# Training Loop\n","for epoch in range(250):\n","  print('------------------------------------------------------------------------')\n","  print('Epoch: {}'.format(epoch))\n","\n","  # Training Loop\n","  for batch in tqdm.tqdm(enumerate(train_loader), desc='Training'):\n","    # Move the input and label tensors to the GPU\n","    inputs = batch[1]['word_idx'].unsqueeze(2).to(device)  # add an additional dimension to the inputs tensor this was based on debuggin the code\n","    labels = batch[1]['ners'].to(device)\n","\n","    print(inputs)\n","\n","    print(labels)\n","    # Clear the gradients\n","    optimizer.zero_grad()\n","\n","    # Forward pass\n","    logits = Transfer_Model2(inputs)[0]\n","    loss = criterion(logits.view(-1, num_labels), labels.view(-1))\n","\n","    # Backward pass\n","    loss.backward()\n","    optimizer.step()\n","\n","  # Validation Loop\n","\n","  # Initialize F1 score metric\n","  f1 = F1()\n","\n","  # Validation Loop\n","  for batch in val_loader:\n","    # move them to GPU\n","    inputs = batch['word_idx'].to(device)\n","    labels = batch['ners'].to(device)\n","\n","    # Forward pass\n","    logits = Transfer_Model2(inputs)[0]\n","    loss = criterion(logits.view(-1, num_labels), labels.view(-1))\n","\n","    # Update F1 score\n","    f1.update(logits.view(-1, num_labels), labels.view(-1))\n","\n","    # Print F1 score at the end of each epoch\n","    print(\"Validation F1:\", f1.get_score())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"tWXsv7Xk3s2A","executionInfo":{"status":"error","timestamp":1673198353374,"user_tz":-60,"elapsed":9,"user":{"displayName":"Daniel Podolecki","userId":"06614390752201781663"}},"outputId":"d43809c1-9714-40ea-f47d-83093a882bbb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------------------------------------------------\n","Epoch: 0\n"]},{"output_type":"stream","name":"stderr","text":["Training: 0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor([[[ 9393],\n","         [ 5312],\n","         [13731],\n","         ...,\n","         [    0],\n","         [    0],\n","         [    0]],\n","\n","        [[ 3387],\n","         [22171],\n","         [12510],\n","         ...,\n","         [    0],\n","         [    0],\n","         [    0]],\n","\n","        [[19413],\n","         [ 4247],\n","         [14563],\n","         ...,\n","         [    0],\n","         [    0],\n","         [    0]],\n","\n","        ...,\n","\n","        [[22199],\n","         [16618],\n","         [ 6068],\n","         ...,\n","         [    0],\n","         [    0],\n","         [    0]],\n","\n","        [[ 3387],\n","         [17339],\n","         [16202],\n","         ...,\n","         [    0],\n","         [    0],\n","         [    0]],\n","\n","        [[20998],\n","         [22805],\n","         [18098],\n","         ...,\n","         [    0],\n","         [    0],\n","         [    0]]], device='cuda:0')\n","tensor([[   4,    5,    0,  ..., -100, -100, -100],\n","        [   0,    0,    0,  ..., -100, -100, -100],\n","        [   0,    0,    0,  ..., -100, -100, -100],\n","        ...,\n","        [   0,    0,    0,  ..., -100, -100, -100],\n","        [   0,    0,    0,  ..., -100, -100, -100],\n","        [   7,    0,    0,  ..., -100, -100, -100]], device='cuda:0')\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-326-a93de65430ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransfer_Model2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1763\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1765\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1766\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to specify either input_ids or inputs_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}]},{"cell_type":"markdown","source":["Again not successful."],"metadata":{"id":"7GLcx5sRahl2"}},{"cell_type":"markdown","source":["## Summary"],"metadata":{"id":"HaMuQLOUym6i"}},{"cell_type":"markdown","source":["**RNN**\n","\n","The creation of the RNN on the Ontonotes5 dataset was sucessful.\n","\n","A Macro F1 score of 0.2461 on the validation data was achieved. That means the model had a relatively low overall F1 score. This could mean that the model is not accurately predicting many of the entities or that there is a large amount of entities imbalance. Since Hyperparameter Tuning was not conducted to achieve a higher score there is still potential for improvement. \n","\n","A Macro F1 score of 0.2618 on the test data suggests that the model's performance on the test set is slightly better than on the validation set, but still not ideal.\n","\n","For the loss a value of was achieved. Generally speaking a loss has to be as low as possible. The closer to 0 the better it is. \n","\n","A common way to measure the performance of a model is to compare the loss of the model on the training set to the loss of the model on a validation or test set. If the loss on the training set is significantly lower than the loss on the validation or test set, it may indicate that the model is overfitting to the training data. In this case the loss from test to validate can not be considered as too low.\n","\n","\n","\n","It means that the probability of the prediction matching the train data is close to 1.\n","\n","\n","**Transfer Learning Model**\n","\n","The creation of the Transfer Learning Model on the Ontonotes5 dataset was not sucessful. \n","\n","Therefore it was not possible for me to compare the F1 of RNN to the Transfer Learning model. Maybe if I would invest 1-2 days more I could find a way to build it successfully. \n","\n","**Reflection**\n","\n","Overall this exercise was hard and often frustrating for me. However for the RNN part I could learn a lot and it was worth the pain. For the transfer model I learned that dealing with pre-trained models is harder than with own models, because it is not clear how they are coded and how to insert the data and adapt the parameters so that the pretrained model can deal with the dataset of desire. One has to study very deep the documentation of the pretrained model in order to use it. \n","\n"],"metadata":{"id":"5JZbBEvuyvVk"}}]}